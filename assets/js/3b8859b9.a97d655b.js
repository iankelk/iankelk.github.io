"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[7233],{1323:(e,t,a)=>{a.d(t,{A:()=>s});a(6540);var i=a(1720),n=a(4848);const s=e=>{let{conversation:t,userAvatar:a,chatbotAvatar:s}=e;const{colorMode:r}=(0,i.G)(),o=e=>{let t,a;return"dark"===r?(t="user"===e?"#333":"#1a4d57",a="#fff"):(t="user"===e?"#f0f0f0":"#d1e7dd",a="#000"),{backgroundColor:t,color:a,padding:"10px 15px",borderRadius:"15px",margin:"0 10px",maxWidth:"70%"}};return(0,n.jsx)("div",{style:{fontFamily:'"Helvetica Neue", Helvetica, Arial, sans-serif',maxWidth:"90%",margin:"auto",color:"dark"===r?"var(--ifm-heading-color)":"inherit"},children:t.map(((e,t)=>(0,n.jsxs)("div",{style:{display:"flex",alignItems:"flex-end",flexDirection:"user"===e.speaker?"row":"row-reverse",marginBottom:"10px"},children:[(0,n.jsx)("img",{src:"user"===e.speaker?a:s,alt:e.speaker,style:{width:"40px",height:"40px",borderRadius:"20px"}}),(0,n.jsx)("div",{style:o(e.speaker),children:(0,n.jsx)("p",{style:{margin:"0"},children:e.text})}),e.comment&&(0,n.jsx)("div",{style:{flex:1,padding:"0 10px",fontSize:"0.8em",color:"dark"===r?"#ccc":"#555",textAlign:"user"===e.speaker?"right":"left",alignSelf:"center"},children:e.comment})]},t)))})}},2871:(e,t,a)=>{a.d(t,{A:()=>r});var i=a(6540),n=a(2214),s=a(4848);function r(e){let{image:t,alt:r,caption:o}=e;const[l,c]=(0,i.useState)({width:0,height:0}),h=o.split("\\n").map(((e,t,a)=>{const n=e.replace(/\[([^\]]+)\]\((https?:\/\/[^\s]+)\)/g,((e,t,a)=>`<a href="${a}" target="_blank" rel="noopener noreferrer">${t}</a>`));return(0,s.jsxs)(i.Fragment,{children:[(0,s.jsx)("span",{dangerouslySetInnerHTML:{__html:n}}),t<a.length-1&&(0,s.jsx)("br",{})]},t)}));return(0,i.useEffect)((()=>{const e=new Image;e.onload=()=>{c({width:e.naturalWidth,height:e.naturalHeight})},e.src=t;const i=new n.A({gallery:"#figure-gallery",children:"a",pswpModule:()=>a.e(8300).then(a.bind(a,8300))});i.init();const s=document.querySelectorAll("#figure-gallery figcaption a");return s.forEach((e=>{e.addEventListener("click",(e=>{e.stopPropagation()}))})),()=>{i.destroy(),s.forEach((e=>{e.removeEventListener("click",(e=>{e.stopPropagation()}))}))}}),[t]),(0,s.jsxs)("figure",{style:{border:"1px dashed rgba(0, 0, 0, .1)",padding:0,margin:0,marginBottom:20,borderRadius:"15px",textAlign:"right"},id:"figure-gallery",children:[(0,s.jsx)("a",{href:t,"data-pswp-width":l.width,"data-pswp-height":l.height,children:(0,s.jsx)("img",{src:t,alt:r,style:{maxWidth:"100%",height:"auto"}})}),(0,s.jsx)("hr",{style:{margin:"5px 0",backgroundColor:"rgba(0, 0, 0, .2)"}}),(0,s.jsx)("figcaption",{style:{marginTop:"0.5em",marginBottom:"0.5em",marginRight:"1em",textAlign:"right",fontSize:"0.8em"},children:h})]})}},6411:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>h,contentTitle:()=>c,default:()=>m,frontMatter:()=>l,metadata:()=>i,toc:()=>d});var i=a(857),n=a(4848),s=a(8453),r=(a(1776),a(2871)),o=(a(1323),a(7647));a(3954),a(7695),a(772),a(332),a(7026),a(8260),a(2914),a(5259),a(2331);const l={slug:"secret-chickens-tuning",title:"Secret LLM chickens II: Tuning the chicken",authors:["ikelk"],tags:["distribution","sampling","top-p","top-k","temperature","AGI","ASI","chatgpt","chat","AI","LLM","ML","chatbot","chatbots","AIExplained"],enableComments:!0,image:"https://github.com/iankelk/iankelk.github.io/blob/main/blog/2024-05-13-tuning-chickens/social-card.jpg?raw=true",hide_reading_time:!1},c=void 0,h={authorsImageUrls:[void 0]},d=[];function g(e){const t={a:"a",admonition:"admonition",annotation:"annotation",em:"em",li:"li",math:"math",mi:"mi",mrow:"mrow",p:"p",semantics:"semantics",span:"span",ul:"ul",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(t.p,{children:["When working with an LLM, sometimes it doesn't generate responses in the way you want. Maybe it's being too creative and weird when tasked with serious prompts (\"Write me a cover letter for a programming job\" ",(0,n.jsx)(t.em,{children:'"I am a coding wizard and I always min-max my character!"'}),'), or it\'s being too serious when you want to do some creative writing ("Write me a story" ',(0,n.jsx)(t.em,{children:'"You are tired and you lie down and go to sleep. The end."'}),'). This can be tweaked by making certain adjustments to the sampling mechanism\u2014aka "the chicken."']}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsxs)(t.em,{children:["This blog post continues from my previous article, ",(0,n.jsx)(t.a,{href:"/blog/secret-chickens-llm",children:"The secret chickens that run LLMs"}),', and you should read that first to understand what a "stochastic chicken" is.']})}),"\n",(0,n.jsx)(r.A,{image:o.A,alt:"Cartoon chicken winking at the camera. It is in a cluttered workspace filled with multiple computer monitors, electronics, and miscellaneous items, giving the impression of a tech-savvy or hacker chicken.",caption:"Generated with OpenAI DALL-E 3 and edited by the author."}),"\n",(0,n.jsx)(t.admonition,{title:"Some key points I'll address here are:",type:"tip",children:(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:['The "chicken" can be tuned, using ',(0,n.jsx)(t.a,{href:"/blog/secret-chickens-tuning#whats-an-inference-hyperparameter",children:"inference hyperparameters"})," like temperature, top-k, and top-p. These  serve as dials to fine-tune the randomness introduced by the stochastic process, balancing creativity and coherence in the text they generate."]}),"\n",(0,n.jsx)(t.li,{children:"Adjusting the temperature parameter can make the model's outputs more predictable and less random at lower values, or more diverse and less deterministic at higher values."}),"\n",(0,n.jsx)(t.li,{children:"Modifying the top-k and top-p parameters fine-tunes the sampling process by limiting the set of possible next words."}),"\n",(0,n.jsxs)(t.li,{children:["Top-k restricts the model to choose from the ",(0,n.jsxs)(t.span,{className:"katex",children:[(0,n.jsx)(t.span,{className:"katex-mathml",children:(0,n.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(t.semantics,{children:[(0,n.jsx)(t.mrow,{children:(0,n.jsx)(t.mi,{children:"k"})}),(0,n.jsx)(t.annotation,{encoding:"application/x-tex",children:"k"})]})})}),(0,n.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(t.span,{className:"base",children:[(0,n.jsx)(t.span,{className:"strut",style:{height:"0.6944em"}}),(0,n.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.03148em"},children:"k"})]})})]})," most likely next words, while top-p uses a probability threshold to create a dynamic set of options. These tweaks help balance creativity with coherence, allowing the LLM to better meet specific needs or experimental conditions."]}),"\n",(0,n.jsxs)(t.li,{children:["Even when using top-k, the astronomical number of possible text sequences challenges the idea of detecting originality and plagiarism. It's nearly impossible to ",(0,n.jsx)(t.em,{children:"prove"})," the source of any specific piece of text generated by these models, although LLM-generated text can be recognizable due to the language and style used."]}),"\n"]})})]})}function m(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(g,{...e})}):g(e)}},7695:(e,t,a)=>{a.d(t,{A:()=>i});const i=a.p+"assets/images/chicken-guitar-3e3d2a4dda52470fc506d03058a56202.jpg"},7026:(e,t,a)=>{a.d(t,{A:()=>i});const i=a.p+"assets/images/chicken-high-temp-f6f0bec24318e1b664bcd60c798200ca.jpg"},332:(e,t,a)=>{a.d(t,{A:()=>i});const i=a.p+"assets/images/chicken-low-temp-380b110920ae7ce9b3a56880f233c0cd.jpg"},772:(e,t,a)=>{a.d(t,{A:()=>i});const i=a.p+"assets/images/chicken-original-d7b35cc74ceb0e97b6acd0dcab8bb820.jpg"},2914:(e,t,a)=>{a.d(t,{A:()=>i});const i=a.p+"assets/images/chicken-top-k-renorm-36490445e1627df03bd73ee03b77b4e8.jpg"},8260:(e,t,a)=>{a.d(t,{A:()=>i});const i=a.p+"assets/images/chicken-top-k-e531dc254ea54a568d9c353d54829099.jpg"},2331:(e,t,a)=>{a.d(t,{A:()=>i});const i=a.p+"assets/images/chicken-top-p-renorm-880ead232fb3164cd470a8e79b168f64.jpg"},5259:(e,t,a)=>{a.d(t,{A:()=>i});const i=a.p+"assets/images/chicken-top-p-c719a8b130bb9cd427d750f98cdbf88a.jpg"},7647:(e,t,a)=>{a.d(t,{A:()=>i});const i=a.p+"assets/images/social-card-9590ee3d8c3ccad0ba104cf29246d33b.jpg"},3954:(e,t,a)=>{a.d(t,{A:()=>i});const i=a.p+"assets/images/studying-8795bbdbfb9c6d361b882a0b701486c8.jpg"},857:e=>{e.exports=JSON.parse('{"permalink":"/blog/secret-chickens-tuning","source":"@site/blog/2024-05-13-tuning-chickens/index.md","title":"Secret LLM chickens II: Tuning the chicken","description":"When working with an LLM, sometimes it doesn\'t generate responses in the way you want. Maybe it\'s being too creative and weird when tasked with serious prompts (\\"Write me a cover letter for a programming job\\" \\"I am a coding wizard and I always min-max my character!\\"), or it\'s being too serious when you want to do some creative writing (\\"Write me a story\\" \\"You are tired and you lie down and go to sleep. The end.\\"). This can be tweaked by making certain adjustments to the sampling mechanism--aka \\"the chicken.\\"","date":"2024-05-13T00:00:00.000Z","tags":[{"inline":true,"label":"distribution","permalink":"/blog/tags/distribution"},{"inline":true,"label":"sampling","permalink":"/blog/tags/sampling"},{"inline":true,"label":"top-p","permalink":"/blog/tags/top-p"},{"inline":true,"label":"top-k","permalink":"/blog/tags/top-k"},{"inline":true,"label":"temperature","permalink":"/blog/tags/temperature"},{"inline":true,"label":"AGI","permalink":"/blog/tags/agi"},{"inline":true,"label":"ASI","permalink":"/blog/tags/asi"},{"inline":true,"label":"chatgpt","permalink":"/blog/tags/chatgpt"},{"inline":true,"label":"chat","permalink":"/blog/tags/chat"},{"inline":true,"label":"AI","permalink":"/blog/tags/ai"},{"inline":true,"label":"LLM","permalink":"/blog/tags/llm"},{"inline":true,"label":"ML","permalink":"/blog/tags/ml"},{"inline":true,"label":"chatbot","permalink":"/blog/tags/chatbot"},{"inline":true,"label":"chatbots","permalink":"/blog/tags/chatbots"},{"inline":true,"label":"AIExplained","permalink":"/blog/tags/ai-explained"}],"readingTime":16.49,"hasTruncateMarker":true,"authors":[{"name":"Ian Kelk","title":"Developer Relations","url":"https://kelk.ai","socials":{"linkedin":"https://www.linkedin.com/in/iankelk/","github":"https://github.com/iankelk"},"imageURL":"https://github.com/iankelk.png","key":"ikelk","page":null}],"frontMatter":{"slug":"secret-chickens-tuning","title":"Secret LLM chickens II: Tuning the chicken","authors":["ikelk"],"tags":["distribution","sampling","top-p","top-k","temperature","AGI","ASI","chatgpt","chat","AI","LLM","ML","chatbot","chatbots","AIExplained"],"enableComments":true,"image":"https://github.com/iankelk/iankelk.github.io/blob/main/blog/2024-05-13-tuning-chickens/social-card.jpg?raw=true","hide_reading_time":false},"unlisted":false,"prevItem":{"title":"Open Source Inference at Full Throttle: Exploring TGI and vLLM","permalink":"/blog/inference-engines"},"nextItem":{"title":"The secret chickens that run LLMs","permalink":"/blog/secret-chickens-llm"}}')}}]);