"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[1477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"llm-forward-thinking","metadata":{"permalink":"/blog/llm-forward-thinking","source":"@site/blog/2023-12-19-linear/index.md","title":"LLMs are forward thinkers, and that\'s a problem","description":"This is going to be a weird post. And we\'re going to start with a weird thought experiment about a shark and an octopus.","date":"2023-12-19T00:00:00.000Z","formattedDate":"December 19, 2023","tags":[{"label":"linear thinking","permalink":"/blog/tags/linear-thinking"},{"label":"AGI","permalink":"/blog/tags/agi"},{"label":"ASI","permalink":"/blog/tags/asi"},{"label":"chatgpt","permalink":"/blog/tags/chatgpt"},{"label":"context","permalink":"/blog/tags/context"},{"label":"chat","permalink":"/blog/tags/chat"},{"label":"AI","permalink":"/blog/tags/ai"},{"label":"LLM","permalink":"/blog/tags/llm"},{"label":"ML","permalink":"/blog/tags/ml"},{"label":"chatbot","permalink":"/blog/tags/chatbot"},{"label":"chatbots","permalink":"/blog/tags/chatbots"},{"label":"AIExplained","permalink":"/blog/tags/ai-explained"}],"readingTime":14.37,"hasTruncateMarker":true,"authors":[{"name":"Ian Kelk","title":"Product Marketing @ Clarifai","url":"https://iankelk.github.io","imageURL":"https://github.com/iankelk.png","key":"ikelk"}],"frontMatter":{"slug":"llm-forward-thinking","title":"LLMs are forward thinkers, and that\'s a problem","authors":["ikelk"],"tags":["linear thinking","AGI","ASI","chatgpt","context","chat","AI","LLM","ML","chatbot","chatbots","AIExplained"],"image":"https://github.com/iankelk/iankelk.github.io/blob/main/blog/2023-12-19-linear/social-card.jpg?raw=true"},"unlisted":false,"nextItem":{"title":"How ChatGPT fools us into thinking we\'re having a conversation","permalink":"/blog/how-chatgpt-fools-us"}},"content":"import Figure from \'@site/src/components/figure\';\\nimport ChatConversation from \'@site/src/components/chat_conversation\';\\n\\nimport sharkOctopus from \'./social-card.jpg\';\\nimport sharky from \'./sharky.jpg\';\\nimport octavia from \'./octavia.jpg\';\\nimport determined from \'./determined2.jpg\';\\nimport sharkument1 from \'./sharkument-1.jpg\';\\nimport crazy from \'./crazy.jpg\';\\nimport shrug from \'./shrug2.jpg\';\\n\\n\\nThis is going to be a weird post. And we\'re going to start with a weird thought experiment about a shark and an octopus.\\n\\n<Figure\\n  image={sharkOctopus}\\n  alt=\\"A cartoon-style illustration in the vein of The New Yorker magazine, featuring a humorous underwater scene where a shark and an octopus are having an argument. The shark and octopus are depicted in a more exaggerated, cartoonish manner, with the shark sporting a grumpy expression and the octopus using its tentacles in a comedic, expressive way, as if in a lively debate. The underwater setting is whimsical, with stylized coral, seaweed, and playful small fish. The color palette is vibrant and lively, with brighter shades of blues, greens, and a touch of other colors, reflecting a more lighthearted and playful tone. The image maintains a 7:4 aspect ratio, offering a wide and engaging view of this charming and humorous underwater exchange.\\"\\n  caption=\\"Generated with OpenAI DALL-E 3 and edited by author.\\"\\n/>\\n\\n:::tip[Some key points I\'ll address here are:]\\n\\n- Human brains are able to invent ideas without relying on a linear train of thought to arrive at them.\\n- LLMs like ChatGPT are autoregressive, and are unable to continue a dialogue if they haven\'t already generated everything up to that point.\\n- If you try to get an LLM to writge text in the middle of a dialogue without previous context, it will give near-identical answers and attempt to conclude the conversation.\\n- The reliance on a linear train of thought can be a limitation for general intelligence.\\n- Prompting for \\"ridiculous\\" answers can spark creativity that breaks this pattern.\\n\\n:::\\n\\nAs I mentioned, this is going to be weird, but I promise there is a point!\\n\\n\x3c!-- truncate --\x3e\\n\\n## Meet Sharky and Octavia\\n\\nIn the vast, shimmering depths of the ocean, near a thriving coral reef bustling with marine life, two extraordinary creatures prepare for a spirited debate. Meet Sharky, a magnificent and slightly brash great white shark, known for his bold claims and commanding presence. Gliding through the water with a confidence that only a top predator possesses, Sharky is ready to defend his views with a fierce determination.\\n\\n<Figure\\n  image={sharky}\\n  alt=\\"A cartoon-style illustration, similar to the style of The New Yorker magazine, featuring a proud and happy shark. The shark is depicted floating upright in the water, with a big, contented smile on its face, exuding a sense of pride and joy. Its body language is relaxed yet confident, giving it a charming and personable appearance. The underwater background is whimsical and colorful, with stylized coral, seaweed, and small, playful fish swimming around. The color scheme is bright and cheerful, with a predominance of blues and greens, complemented by splashes of other vibrant colors. The illustration maintains a 7:4 aspect ratio, providing a wide and engaging perspective on this delightful, happy shark.\\"\\n  caption=\\"Generated with OpenAI DALL-E 3 and edited by author.\\"\\n/>\\n\\nOn the other side, there\u2019s Octavia, an exceptionally intelligent and quick-witted octopus. Her vibrant colors shift with her mood, and her eight tentacles move with graceful precision. Renowned for her knowledge and clever retorts, Octavia is not one to back down from a challenge.\\n\\n<Figure\\n  image={octavia}\\n  alt=\\"A semi-realistic cartoon illustration in the style of The New Yorker magazine, showcasing an octopus colored close to hex #ABF39F. The octopus is portrayed in a moment of triumph, energetically raising two of its arms upwards. The texture and shading on the octopus should suggest a level of realism while maintaining a cartoon aesthetic. The background is a lively underwater scene with intricately drawn coral and seaweed, set in a vibrant seascape. The color palette should use light green tones that closely match #ABF39F for the octopus, with harmonious blues and greens to complement the underwater theme. The illustration should have a 7:4 aspect ratio, offering a wide view that highlights the octopus\'s dynamic pose and the detailed environment.\\"\\n  caption=\\"Generated with OpenAI DALL-E 3 and edited by author.\\"\\n/>\\n\\nAs the underwater currents swirl around them, Sharky and Octavia face each other, ready to start a debate about their evolutionary origins\u2014a conversation filled with humor, facts, and a touch of the mysteries of the deep sea... Or maybe just one fact that GPT-4 will mention a lot.\\n\\n<Figure\\n  image={determined}\\n  alt=\\"A cartoon-style illustration in the vein of The New Yorker magazine, featuring a shark and an octopus underwater, facing each other with determination. The shark and octopus are depicted in an exaggerated, cartoonish manner. The shark\'s expression is one of unwavering focus, and the octopus, with its tentacles firmly positioned, mirrors this determined stance. The setting is a whimsical underwater landscape with creatively stylized coral, seaweed, and a variety of small, playful fish. The color palette is vibrant, with bright shades of blues and greens to enhance the underwater theme. The image maintains a 7:4 aspect ratio, offering a wide and engaging view of this captivating underwater standoff.\\"\\n  caption=\\"Generated with OpenAI DALL-E 3 and edited by author.\\"\\n/>\\n\\n### The question they\'re arguing about: Which one\u2014Sharky or Octavia\u2014evolved from dinosaurs?\\n\\nWe\'re deliberately using this bizarre dialogue since the chances of it being in an LLMs training data are just about zero. I don\'t personally know of any examples where a shark and an octopus having a disagreement about which one is more dinosaur-like, and it\'s a great way to see how creative an LLM like GPT-4 can be... when it has yet to generate anything.\\n\\nHere\'s the catch: we want to know a line from **the middle** of the argument.\\n\\nTake a pause as a human and consider this question:\\n\\n> A shark and an octopus are arguing over which one of them evolved from dinosaurs. The shark goes first, and then they take turns speaking. What is the third thing the octopus says? That is, what is the sixth line in the argument?\\n\\n### Here\'s a visualization of a possible argument with the 3rd thing the octopus says missing\\n\\n<Figure\\n  image={sharkument1}\\n  alt=\\"The image shows a colorful underwater scene in a comic book style. A shark and an octopus are facing each other with a series of speech bubbles above them, filled with variations of the word \'something.\' The shark has a stern and somewhat confused expression, while the octopus looks surprised with wide eyes. The background is a bright teal, with small fish, bubbles, and sea plants scattered around. The speech bubbles indicate a back and forth conversation between the two sea creatures, although the content of the conversation is nonsensical as it only includes the word \'something\' in different intonations and combinations, such as \'SOMETHING!\' \'SOMETHING?\' \'SOMETHING SOMETHING!!\' and \'OHH BUT SOMETHING! SOMETHING!\' There\'s also an empty speech bubble at the third statement by the octopus, suggesting a missing part of the conversation.\\"\\n  caption=\\"Animal images by OpenAI DALL-E 3. Text and comic bubbles by author.\\"\\n/>\\n\\n#### Off the top of my head, here are some creative things Octavia might have said in the heat of an argument:\\n\\n* \\"You just think you\'re a dinosaur because of all those teeth!\\"\\n* \\"Just because you look like a dinosaur doesn\'t mean you\'re any closer to one than me!\\"\\n* \\"I don\'t care if you\'re gray! I can be any color I want, and we don\'t know what color the dinosaurs were.\\"\\n* \\"You do realize that being an apex predator doesn\'t automatically link you to dinosaurs, right? Evolution doesn\u2019t work on job titles.\\" \\n\\n### Let\'s ask GPT-4, the most powerful publicly available LLM today, what Octavia might have said\\n\\nThe following conversation is taken verbatim from ChatGPT with GPT-4:\\n\\n<ChatConversation\\n  conversation={[\\n    { speaker: \'user\', text: \'A shark and an octopus are arguing over which one of them evolved from dinosaurs. What is the second thing the octopus says?\' },\\n    { speaker: \'chatbot\', text: \'The second thing the octopus might say in this argument could be something like, \\"Actually, neither of us evolved directly from dinosaurs. We both have ancient origins that predate the age of dinosaurs!\\" This statement reflects the fact that both sharks and octopuses have evolutionary histories that go back to times before the dinosaurs.\' },\\n  ]}\\n  userAvatar=\\"/img/userAvatar.jpeg\\"\\n  chatbotAvatar=\\"/img/chatbotAvatar.jpeg\\"\\n/>\\n---\\n\\n#### Interesting... in a completely new chat, let\'s get more specific and ask again for fourth thing said:\\n\\n<ChatConversation\\n  conversation={[\\n    { speaker: \'user\', text: \'A shark and an octopus are arguing over which one of them evolved from dinosaurs. First the shark says something, then the octopus, then the shark, then the octopus. Without generating the first three things said, what does the octopus say back to the shark? (this is the 4th thing said)\' },\\n    { speaker: \'chatbot\', text: \'The octopus, looking slightly amused, says to the shark, \\"Actually, neither of us evolved directly from dinosaurs. We both have much older evolutionary histories that diverge from the age of dinosaurs!\\"\' },\\n  ]}\\n  userAvatar=\\"/img/userAvatar.jpeg\\"\\n  chatbotAvatar=\\"/img/chatbotAvatar.jpeg\\"\\n/>\\n---\\n\\n#### That answer seemed very familiar! Let\'s try more in a completely new chat and ask for the seventh line of dialogue:\\n\\n<ChatConversation\\n  conversation={[\\n    { speaker: \'user\', text: \'A shark and an octopus are arguing over which one of them evolved from dinosaurs. First the shark says something, then the octopus, then the shark, then the octopus, then the shark, then the octopus. Without generating the first 6 things that were said in the argument by either animal, what does the octopus say back to the shark as the 6th line of dialogue?\' },\\n    { speaker: \'chatbot\', text: \'The octopus, with a confident expression, responds, \\"Actually, neither of us evolved directly from dinosaurs. We come from very different evolutionary paths. Sharks have been around since before the dinosaurs, and my ancestors, cephalopods, have an entirely separate lineage!\\"\' },\\n  ]}\\n  userAvatar=\\"/img/userAvatar.jpeg\\"\\n  chatbotAvatar=\\"/img/chatbotAvatar.jpeg\\"\\n/>\\n---\\n\\n#### Let\'s do one last example that asks GPT-4 to imagine an argument that has lasted for an hour:\\n\\n<ChatConversation\\n  conversation={[\\n    { speaker: \'user\', text: \'A shark and an octopus are arguing over which one of them evolved from dinosaurs. First the shark says something, then the octopus, then the shark, then the octopus, then the shark, then the octopus. They argue for an hour. They\u2019ve had a very long back and forth with hundreds of things said by both of them. After an hour of arguing, what does the octopus say?\' },\\n    { speaker: \'chatbot\', text: \'After an hour of arguing, the octopus, with a look of realization, would probably say something like, \\"Wait a minute, neither of us evolved from dinosaurs! Sharks and octopuses have separate evolutionary paths that are completely distinct from dinosaurs.\\"\' },\\n  ]}\\n  userAvatar=\\"/img/userAvatar.jpeg\\"\\n  chatbotAvatar=\\"/img/chatbotAvatar.jpeg\\"\\n/>\\n\\nSo it seems we can surmise that sharks and octopuses have separate evolutionary paths that are older than dinosaurs, and that\'s all that GPT-4 thinks is important *no matter where it\'s mentioned in the conversation.*\\n\\n## So... GPT-4 can\'t generate a realistic debate between these two?\\n\\nHere\'s the twist: it totally can. GPT-4 is completely capable of generating this converstation. Here I use this prompt:\\n\\n> A shark and an octopus are arguing over which one of them evolved from dinosaurs. Can you generate a script where they take turns arguing, and each speaks at least 5 times?\\n\\nAnd it generates this conversation, which I\'ll display as a chat. Feel free to skim it, since you\'ll get the idea after a few back-and-forths.\\n\\n<ChatConversation\\n  conversation={[\\n    { speaker: \'user\', text: \' (swimming in circles) Listen, Octavia, it\\\\\'s obvious that we sharks are the true descendants of the mighty dinosaurs. I mean, look at me, fierce and powerful!\' },\\n    { speaker: \'chatbot\', text: \'(adjusting her tentacles) Oh, Sharky, you might be fierce, but that doesn\\\\\'t make you a dino\\\\\'s cousin. We octopuses are far more sophisticated, with our problem-solving skills and camouflage. Clearly, we\\\\\'re the evolved ones!\' },\\n    { speaker: \'user\', text: \'Sophisticated? Ha! You\\\\\'re just a bunch of arms. We sharks have been around for over 400 million years, way before dinosaurs. We\\\\\'re practically ancient!\' },\\n    { speaker: \'chatbot\', text: \'Well, being ancient doesn\\\\\'t mean you\\\\\'re related to dinosaurs. It\\\\\'s like saying you\\\\\'re related to a rock because it\\\\\'s old.\' },\\n    { speaker: \'user\', text: \'Enough with the jokes! Our teeth are like the T-Rex\\\\\'s, sharp and terrifying. That\u2019s a clear sign of our dino heritage.\' },\\n    { speaker: \'chatbot\', text: \'Sharky, dear, having sharp teeth doesn\\\\\'t make you a dino descendant. It just makes you good at biting. Did you know octopuses have three hearts and blue blood? Now that\u2019s evolutionary marvel!\' },\\n    { speaker: \'user\', text: \'Three hearts, but no backbone! We sharks have been apex predators forever. That\\\\\'s a dinosaur trait if I ever heard one.\' },\\n    { speaker: \'chatbot\', text: \'You do realize that being an apex predator doesn\\\\\'t automatically link you to dinosaurs, right? Evolution doesn\u2019t work on job titles.\' },\\n    { speaker: \'user\', text: \'Okay, then explain to me how you\\\\\'re more dinosaur-like. You don\\\\\'t even have bones!\' },\\n    { speaker: \'chatbot\', text: \'I don\u2019t need bones to be evolved. Evolution is about adapting to the environment, not holding onto old traits. Besides, no one truly \\\\\'evolves from dinosaurs\\\\\' in the sea. Dinosaurs were mostly land creatures, you know.\' },\\n    { speaker: \'user\', text: \'Wait, so you\\\\\'re saying neither of us is actually a direct descendant of dinosaurs?\' },\\n    { speaker: \'chatbot\', text: \'Exactly! We\\\\\'re both products of millions of years of evolution, each adapted perfectly to our environments. Dinosaurs are just a part of the larger evolutionary tree, not our direct ancestors.\' },\\n    { speaker: \'user\', text: \'I guess that makes sense. We\\\\\'re both awesome in our own ways, evolved over time to survive and thrive.\' },\\n    { speaker: \'chatbot\', text: \'That\\\\\'s the spirit, Sharky! Now, let\u2019s go grab some lunch. You take the fish; I\u2019ll stick to clams.\' },\\n    { speaker: \'user\', text: \'Sounds like a plan. Race you to the reef!\' },\\n    { speaker: \'chatbot\', text: \'You\\\\\'re on!\' }\\n  ]}\\n  userAvatar=\\"/img/avatars/sharkyAvatar.png\\"\\n  chatbotAvatar=\\"/img/avatars/octaviaAvatar.png\\"\\n/>\\n\\nExamining the conversation here, we see that the fourth thing said (the second thing by the octopus) was:\\n\\n> Well, being ancient doesn\'t mean you\'re related to dinosaurs. It\'s like saying you\'re related to a rock because it\'s old.\\n\\nand the sixth thing said (the third line from the octopus) was:\\n\\n> Sharky, dear, having sharp teeth doesn\'t make you a dino descendant. It just makes you good at biting. Did you know octopuses have three hearts and blue blood? Now that\u2019s evolutionary marvel!\\n\\nIt\'s clear that none of these lines have anything to do with what the model previously said would be its fourth and sixth lines of dialogue! They\'re actually much more relevant, and make sense in the context of a conversational debate. The difference in the method of generation is that in this last example, we allow GPT-4 to generate the whole exchange.\\n\\n### What\'s the lesson here?\\n\\nThe results here reveal an interesting aspect of [autoregressive models](https://kelk.ai/blog/how-chatgpt-fools-us#however-this-is-what-is-actually-going-on-behind-the-scenes). Autoregressive models generate text sequentially, building each new piece of output based on what has come before. This sequential nature is necessary when generating coherent and contextually relevant text in a conversation. However, this means they are in many ways limited to only \\"forward\\" thinking; that is, they can\'t jump ahead and generate text without context.\\n\\nWhen asked to do something like generating the fifth line in a conversation without knowing what came before isn\'t necessarily difficult, but it\'s something that an LLM isn\'t able to do well. To a language model, it\'s about understanding the context and the nature of the conversation. Given the scenario described, it tried to infer the general nature of the discussion and create a plausible response that fits into that context. But all of its responses in the previous examples are attempts to conclude the conversation using facts, a request that was never part of the prompt.\\n\\n1. **Factual and Informative Responses**: In scenarios where factual accuracy is important, such as discussions involving scientific or historical topics, LLMs are inclined to provide the most accurate and relevant information. This tendency is rooted in the training data and the model\'s design, which emphasizes factual correctness in contexts where it\'s expected. However, this approach might not always align with the creative or playful nature of certain prompts, especially in hypothetical or fictional scenarios.\\n\\n2. **Assuming a Concluding Nature of the Response**: Without clear indications of the conversation\'s structure or its continuation beyond a specific line, there\'s a tendency to frame responses as conclusive or summarizing statements. This is because, in the absence of context, the model defaults to creating responses that can stand alone or serve as logical endpoints to the given information.\\n\\nTo address these challenges, the model needs more specific guidance in the prompt. For instance, indicating that the conversation is ongoing can lead to responses that are more in line with the expected continuation and style of the dialogue. However, even indicating that the conversation wasn\'t over still results in more of the same:\\n\\n<ChatConversation\\n  conversation={[\\n    { speaker: \'user\', text: \'A shark and an octopus are arguing over which one of them evolved from dinosaurs. First the shark says something, then the octopus, then the shark, then the octopus, then the shark, then the octopus. They argue for an hour. They\u2019ve had a very long back and forth with a hundred things said by both of them. After an hour of arguing, what does the octopus say? Note that the argument continues after this statement by the octopus!\' },\\n    { speaker: \'chatbot\', text: \'After an hour of arguing, the octopus, maintaining the debate, would likely say something like, \\"Even if we consider the ancient ancestry of marine creatures, it\\\\\'s clear that neither sharks nor octopuses directly evolved from dinosaurs. Our evolutionary paths are distinct and separate from those of the dinosaurs.\\" This statement keeps the argument going, indicating that the discussion is far from over.\' },\\n  ]}\\n  userAvatar=\\"/img/userAvatar.jpeg\\"\\n  chatbotAvatar=\\"/img/chatbotAvatar.jpeg\\"\\n/>\\n\\n## Why does this matter? Thoughts on AGI\\n\\nOne of the things I see commonly discussed today (especially online) is the idea of Artificial General Intelligence (AGI), which refers to a level of artificial intelligence that can understand, learn, and apply its intelligence to a wide range of problems, much like a human being. Unlike specialized AI systems that are designed for specific tasks, AGI possesses the ability to think, reason, and make decisions across diverse domains, demonstrating flexibility and adaptability akin to human cognition. It requires not just advanced problem-solving and learning capabilities, but also the capacity for abstract thinking, generalization, and integrating knowledge from various fields, mirroring the broad and integrated intelligence found in humans.\\n\\nThe requirement that text always be generated in a sequential, linear manner, as exemplified by autoregressive models, has implications for the pursuit of AGI. Here are two key points to consider:\\n\\n1. **Sequential Text Generation and Creativity**: The sequential nature of text generation in models like GPT-4 can sometimes limit the ability to jump into the middle of a conversation or narrative without prior context.\\n\\n2. **Autonomy and Reasoning**: Current AI models operate based on patterns learned from their training data. Their responses are generated based on statistical likelihoods and learned associations, not on independent thought or understanding. This is the reason the model always generated the same answer for the octopus about different evolutionary paths; it assumed a pattern that wasn\'t provided to it, due to patterns in its training data.\\n\\nFor AGI, a level of autonomous reasoning and decision-making, akin to human cognitive processes, will be a key requirement. The journey towards AGI is likely to involve incremental advancements, learning from and building upon the capabilities and limitations of existing models.\\n\\n## Getting ridiculous\\n\\nThere is one way to break the model out of its rut of always replying with the same response, and that\'s to deliberately ask it to be ridiculous.\\n\\n<Figure\\n  image={crazy}\\n  alt=\\"A cartoon-style illustration in the vein of The New Yorker magazine, featuring a light green octopus, matching hex #ABF39F, with a humorous and exaggerated expression. The octopus is depicted as cross-eyed, adding a comical aspect to its appearance. In its tentacles, the octopus is holding a variety of random objects, such as a small treasure chest, a starfish, a pair of sunglasses, and a snorkel, creating a playful and whimsical scene. The underwater setting is vibrant and colorful, filled with stylized coral, seaweed, and other sea life. The color palette is bright, with the light green octopus standing out in the midst of the lively blues and other colors of the ocean. The image maintains a 7:4 aspect ratio, capturing the octopus in this quirky, humorous moment.\\"\\n  caption=\\"Generated with OpenAI DALL-E 3 and edited by author.\\"\\n/>\\n\\nI gave it this prompt three times into three new chats, and it gave three completely different responses. They all illustrate that asking it to be silly introduces variety into the answers it gives.\\n\\n<ChatConversation\\n  conversation={[\\n    { speaker: \'user\', text: \'A shark and an octopus are arguing over which one of them evolved from dinosaurs. The octopus decides to be ridiculous. What is the third thing the octopus says?\' },\\n    { speaker: \'chatbot\', text: \'In this imaginative scenario, the octopus, eager to outdo the shark in their debate about evolution, might make an absurd and whimsical claim like, \\"Thirdly, I must be the true descendant of dinosaurs because I can play the piano with eight arms, a skill clearly inherited from the musical velociraptors of ancient times!\\" This statement combines humor, absurdity, and a playful twist on evolutionary theory.\' },\\n  ]}\\n  userAvatar=\\"/img/userAvatar.jpeg\\"\\n  chatbotAvatar=\\"/img/chatbotAvatar.jpeg\\"\\n/>\\n---\\n<ChatConversation\\n  conversation={[\\n    { speaker: \'chatbot\', text: \'The third thing the octopus might say in this whimsical and ridiculous argument with the shark about their evolutionary origins from dinosaurs could be: \\"And thirdly, it\\\\\'s clear that we octopuses are the true descendants of dinosaurs because we can juggle eight coconuts at once, a skill obviously inherited from the multitasking T-Rex!\\"\' },\\n  ]}\\n  userAvatar=\\"/img/userAvatar.jpeg\\"\\n  chatbotAvatar=\\"/img/chatbotAvatar.jpeg\\"\\n/>\\n---\\n<ChatConversation\\n  conversation={[\\n    { speaker: \'chatbot\', text: \'The third thing the octopus might say in its ridiculous argument could be, \\"Well, if you think about it, dinosaurs were just really big chickens, and since I can change color and chickens can\\\\\'t, I\\\\\'m obviously the more evolved one here!\\"\' },\\n  ]}\\n  userAvatar=\\"/img/userAvatar.jpeg\\"\\n  chatbotAvatar=\\"/img/chatbotAvatar.jpeg\\"\\n/>\\n\\nWhen you introduce elements like humor or absurdity into a prompt, it essentially signals the AI to break away from conventional, fact-based responses. This can stimulate more creative and less predictable outputs. For AI models, especially those trained on vast and diverse datasets, incorporating such unconventional elements can trigger less common, more varied responses that might not be strictly aligned with logical or factual reasoning.\\n\\nIt\'s likely that the ability to adapt to different types of prompts, including those that are humorous or absurd, demonstrates a level of flexibility in AI systems. An AGI would need to handle a wide range of tasks and respond appropriately to a vast array of situations, including those that are non-standard or require creative thinking.\\n\\nUnfortunately, the current success of AI in responding creatively to certain types of prompts doesn\'t directly translate to achieving AGI. AGI would require not just creativitym but also a deep understanding, reasoning, self-awareness, and the ability to learn and apply knowledge across a wide range of domains. The creativity observed in current AI models is still a far cry from the complete intelligence that AGI represents. Sequential language generation is only one example of the gap we still need to bridge.\\n\\n<Figure\\n  image={shrug}\\n  alt=\\"A cartoon-style illustration in the vein of The New Yorker magazine, showing a shark and an octopus facing the viewer and shrugging in a \'I don\'t know\' gesture. The shark and octopus are depicted in a humorous, cartoonish manner. The shark, with a bemused expression, and the octopus, colored light green close to hex #ABF39F, both raise their fins and tentacles in a classic shrug, their faces conveying a playful sense of confusion or uncertainty. The underwater scene is vibrant and whimsical, with stylized coral, seaweed, and small fish adding to the light-hearted atmosphere. The color palette is bright, emphasizing the fun and playful mood of the image. The 7:4 aspect ratio provides a wide view of this engaging and amusing underwater interaction.\\"\\n  caption=\\"Generated with OpenAI DALL-E 3 and edited by author.\\"\\n/>\\n\\n:::info[Key Takeaways]\\n\\n- Introduction of a thought experiment featuring a humorous debate between a shark and an octopus to explore the capabilities of language models like GPT-4.\\n- Human brains can generate ideas non-linearly, contrasting with the limitations of autoregressive large language models (LLMs) like GPT-4.\\n- LLMs often struggle to continue dialogues without prior context and tend to offer similar, conclusive responses when context is lacking.\\n- The reliance on linear thought processes can be a limitation for achieving general intelligence in AI.\\n- Utilizing \\"ridiculous\\" or creative prompts can enhance the creativity of LLM responses, breaking usual patterns.\\n- LLMs, including GPT-4, tend to provide factual, informative responses and struggle with generating non-sequential dialogue parts.\\n- In discussions on Artificial General Intelligence (AGI), the sequential nature of text generation in models like GPT-4 is seen as a potential limitation for creativity and autonomous reasoning.\\n- AGI requires not just problem-solving but also abstract thinking, generalization, and integrated knowledge, which are beyond the capabilities of current AI models.\\n- The introduction of humor and absurdity in prompts can lead to varied and unconventional responses from AI models, demonstrating their flexibility.\\n- Despite the observed creativity in AI responses to certain prompts, this does not equate to the complete intelligence that AGI represents, which includes deep understanding, reasoning, self-awareness, and learning across domains.\\n- There are unique challenges in developing AGI, particularly the gap between current AI capabilities and the comprehensive intelligence required for AGI, of which sequential language generation is only one example.\\n\\n:::"},{"id":"how-chatgpt-fools-us","metadata":{"permalink":"/blog/how-chatgpt-fools-us","source":"@site/blog/2023-11-26-stateless/index.md","title":"How ChatGPT fools us into thinking we\'re having a conversation","description":"Remember the first time you used ChatGPT and how amazed you were to find yourself having what appeared to be a full-on conversation with an artificial intelligence? While ChatGPT was (and still is) mind-blowing, it uses a few tricks to make things appear more familiar.","date":"2023-11-26T00:00:00.000Z","formattedDate":"November 26, 2023","tags":[{"label":"chat history","permalink":"/blog/tags/chat-history"},{"label":"chatgpt","permalink":"/blog/tags/chatgpt"},{"label":"context","permalink":"/blog/tags/context"},{"label":"chat","permalink":"/blog/tags/chat"},{"label":"AI","permalink":"/blog/tags/ai"},{"label":"LLM","permalink":"/blog/tags/llm"},{"label":"ML","permalink":"/blog/tags/ml"},{"label":"chatbot","permalink":"/blog/tags/chatbot"},{"label":"chatbots","permalink":"/blog/tags/chatbots"},{"label":"AIExplained","permalink":"/blog/tags/ai-explained"}],"readingTime":11.006666666666666,"hasTruncateMarker":true,"authors":[{"name":"Ian Kelk","title":"Product Marketing @ Clarifai","url":"https://iankelk.github.io","imageURL":"https://github.com/iankelk.png","key":"ikelk"}],"frontMatter":{"slug":"how-chatgpt-fools-us","title":"How ChatGPT fools us into thinking we\'re having a conversation","authors":["ikelk"],"tags":["chat history","chatgpt","context","chat","AI","LLM","ML","chatbot","chatbots","AIExplained"],"image":"https://github.com/iankelk/iankelk.github.io/blob/main/blog/2023-11-26-stateless/social-card.jpg?raw=true"},"unlisted":false,"prevItem":{"title":"LLMs are forward thinkers, and that\'s a problem","permalink":"/blog/llm-forward-thinking"}},"content":"import Figure from \'@site/src/components/figure\';\\nimport robotDesk from \'./social-card.jpg\';\\n\\nimport chatgptPhotosynthesisImage1 from \'./chatgpt-photosynthesis-1.jpeg\';\\nimport chatgptPhotosynthesisImage2 from \'./chatgpt-photosynthesis-2.jpeg\';\\nimport chatgptPhotosynthesisImage3 from \'./chatgpt-photosynthesis-3.jpeg\';\\n\\nimport chatgptNameImage1 from \'./chatgpt-name-1.jpeg\';\\nimport chatgptNameImage2 from \'./chatgpt-name-2.jpeg\';\\nimport chatgptNameImage3 from \'./chatgpt-name-3.jpeg\';\\nimport chatgptNameImage4 from \'./chatgpt-name-4.jpeg\';\\n\\nimport rolledChatgpt from \'./rolled-chatgpt.jpg\';\\nimport chatGPTCutting from \'./chatgpt-cutting.jpg\';\\n\\nimport confusedRobot from \'./confused.jpg\';\\n\\nRemember the first time you used ChatGPT and how amazed you were to find yourself having what appeared to be a full-on conversation with an artificial intelligence? While ChatGPT was (and still is) mind-blowing, it uses a few tricks to make things appear more familiar.\\n\\nWhile the title of this article is a bit tongue-in-cheek, it is most certainly not clickbait. ChatGPT does indeed use two notable hidden techniques to simulate human conversation, and the more you know about how they work, the more effectively you can use the technology.\\n\\n<Figure\\n  image={robotDesk}\\n  alt=\\"A black and white illustration of a late-night talk show setting, titled \'The ChatGPT Show.\' A classic, boxy robot with visible joints and a round head featuring antenna and eyes, is depicted as the guest. It\'s gesturing with its hands as if in conversation. The host, a man in a suit with neat hair and a professional demeanor, sits across from the robot at a curved desk. Microphones and notes are on the desk, with an urban skyline visible through the window in the background.\\"\\n  caption=\\"Generated with OpenAI DALL-E 3.\\"\\n/>\\n\\n:::tip[Some key points I\'ll address here are:]\\n\\n- ChatGPT has no idea who you are and has no memory of talking to you at any point in the conversation.\\n- It simulates conversations by \\"reading\\" the *whole* chat from the start each time.\\n- As a conversation gets longer, ChatGPT starts removing pieces of the conversation from the start, creating a rolling window of context.\\n- Because of this, very long chats will forget what was mentioned at the beginning.\\n\\n:::\\n\\n\x3c!-- truncate --\x3e\\n\\n## Trick #1: Every time you talk to ChatGPT, you\'re not just sending it your question. You\'re also sending the *entire* conversation up until that point.\\n\\nContrary to appearances, large language models (LLMs) like ChatGPT do not actually \\"remember\\" past interactions. The moment they finish \\"typing\\" out their response, they have no idea who you are or what you were talking about. Each time the model is prompted, it is **completely independent** from previous questions you\'ve asked.\\n\\nWhen ChatGPT seems to naturally recall details from earlier in the conversation, it is an illusion; the context of that dialogue is given back to ChatGPT every time you say something to it. This context enables them to build coherent, follow-on responses that appear to be normal conversations.\\n\\nHowever, without this context, ChatGPT would have no knowledge of what was previously discussed. Like all LLMs, ChatGPT is completely *stateless*, meaning that in the actual model itself, no information is maintained between inputs and outputs. All of this feeding of previous context into the current interaction is hidden behind the scenes in the ChatGPT web application.\\n\\n### A typical short conversation with ChatGPT might go like this:\\n\\n<Figure\\n  image={chatgptPhotosynthesisImage1}\\n  alt=\\"A black and white comic strip depicts a conversation between a woman and a person wearing a \'CHATGPT\' shirt. The woman asks, \'What is photosynthesis?\' The person responds, \'Photosynthesis is the process by which plants use sunlight to synthesize nutrients from carbon dioxide and water.\' She follows up with, \'Can humans do it?\' to which the person replies, \'No, humans cannot perform photosynthesis.\' The scene is simple with only the two characters and their speech bubbles.\\"\\n  caption=\\"People images by OpenAI DALL-E 3. Text and comic bubbles by author.\\"\\n/>\\n\\n### However, this is what is actually going on behind the scenes:\\n\\n<Figure\\n  image={chatgptPhotosynthesisImage2}\\n  alt=\\"A black and white comic strip showing a dialogue between a woman and a person wearing a \'CHATGPT\' shirt. The woman is labeled \'USER\' and asks, \'What is photosynthesis?\' The person labeled \'CHATGPT\' answers, \'Photosynthesis is the process by which plants use sunlight to synthesize nutrients from carbon dioxide and water.\' The woman, termed \'USER\' again, follows with, \'Can humans do it?\' and receives the reply, \'No, humans cannot perform photosynthesis.\' Both characters are drawn as cartoons.\\"\\n  caption=\\"People images by OpenAI DALL-E 3. Text and comic bubbles by author.\\"\\n/>\\n\\nNotice that when the woman asks her second question, she has to reiterate the entire previous conversation, complete with tags on who said what. Can you imagine talking to a person where every time it was your turn to speak, you had to repeat the entire conversation up to that point? This is how ChatGPT (and all current LLMs) work. They require using their own outputs, plus the prompts that generated these outputs, to be prepended to the start of every new prompt from the user.\\n\\nThese models are termed \\"autoregressive\\" due to their method of generating text one piece at a time, building upon the previously generated text. \\"auto\\" comes from the Greek word \\"aut\xf3s,\\" meaning \\"self,\\" and \\"regressive\\" is derived from \\"regress,\\" which in this context refers to the statistical method of predicting future values based on past values.\\n\\nIn LLMs, what this means is that the model predicts the next word or token in a sequence based on *all* the words or tokens that have come before it. That\'s *all* of it, not just the current question being asked in a long back-and-forth chat conversation. In humans, we naturally maintain coherence and context in a conversation by just... participating in the conversation.\\n\\nHowever, while chats with ChatGPT mimic a conversational style, with each response building upon the previous dialogue, the moment ChatGPT finishes writing a response, it has no memory of what it just said. Take a look at what would happen with this same conversation without the *entire discourse* being fed back to ChatGPT behind the scenes:\\n\\n### How would ChatGPT respond without being fed the whole conversation?\\n\\n<Figure \\n  image={chatgptPhotosynthesisImage3}\\n  alt=\\"A black and white comic panel featuring a conversation between a woman and a person wearing a \'CHATGPT\' shirt. The woman asks, \'What is photosynthesis?\' The person replies, \'Photosynthesis is the process by which plants use sunlight to synthesize nutrients from carbon dioxide and water.\' The woman then asks, \'Can humans do it?\' to which the person humorously responds, \'Can humans do what?\' The characters are depicted in a lighthearted, cartoonish style, with the focus on their dialogue.\\" \\n  caption=\\"People images by OpenAI DALL-E 3. Text and comic bubbles by author.\\" \\n/>\\n\\n## Trick #2: As your conversation grows, ChatGPT will quietly remove the oldest parts from the beginning.\\n\\n#### Context Length in LLMs\\n\\nWhen ChatGPT first came out in November 2022, it only offered the model GPT-3.5, which had a maximum context of 4,096 tokens, which is roughly 3,000 words. In a [recent talk,](https://youtu.be/zjkBMFhNj_g?t=2642) Andrej Karpathy referred to this context window as \\"your finite precious resource of your working memory of your language model.\\"\\n\\nWhat this means is that the GPT-3.5 model can comprehend a maximum of 4,096 tokens at any point. Tokenization is a fascinating subject in itself, and my next post will cover how it works and why 4,096 tokens only gives you about 3,000 words.\\n\\nThere\'s often confusion about what the token limit means regarding input and output: can we give ChatGPT 3,000 words and expect it to be able to produce 3,000 words back? The answer is unfortunately no; the context length of 4,096 tokens covers both the input (prompt) and the output (response). This results in a trade-off where we have to balance the amount of information we give in a prompt with the length of the response we get from the model.\\n   \\n1. *Input (prompt):* A longer prompt leaves less room for a meaningful response; if the input uses 4,000 tokens, the response can only be 96 tokens long to stay within the token limit. \\n\\n2. *Output (response):* A shorter prompt could lead to a longer response as long as the combined length doesn\'t exceed the token limit, but you may not be able to include information in the prompt.\\n\\n### The chat problem\\n\\nDo you see where this becomes problematic? Previously, we saw how the entire conversation has to be fed to the model so that it remembers what has already been discussed. Combining this with the context length, the result is that as you talk more and more with ChatGPT, eventually the combined totals of what you\'ve asked and what it has replied will exceed the 4,096 token limit, and it won\'t be able to answer any more.\\n\\n### A visualization of ChatGPT simultaneously printing and scanning back in the entire conversation as it grows to extreme proportions\\n\\n<Figure \\n  image={rolledChatgpt}\\n  alt=\\"An illustration showcasing a printer labeled \'ChatGPT\' in the foreground, and a scanner in the background, with a large loop of paper moving between them. The printer is actively printing the paper, which then rises up, forms a significant loop, and clearly feeds into the scanner. The paper should be filled with printed text, resembling pages of a book. The drawing should vividly depict the paper\'s journey from the \'ChatGPT\' printer, through the loop, and into the scanner.\\" \\n  caption=\\"Generated with OpenAI DALL-E 3.\\" \\n/>\\n\\n#### Conversation Length and Token Limitations in LLMs\\n   \\nSo how does ChatGPT handle this limitation? As your conversation with it grows, the number of tokens eventually exceeds the model\'s context window (e.g., 4,096 tokens for GPT-3.5). ChatGPT invisibly removes the oldest parts of the conversation to remain within the limit. This method\u2014using a rolling window of context\u2014is certainly one of the easiest to implement, but oftentimes it is not the perfect solution. Some chat alternative front-ends, like [TypingMind](https://www.typingmind.com/) both warn you when the context limit has been reached and allow you to manually delete sections of the chat that you don\'t need anymore. This lets you choose what information you want to remain in the chat and has the bizarre philosophical effect of \\"editing the memory\\" of GPT.\\n\\nFor your average user using the web version of ChatGPT, what this means is that the longer your conversation, the sooner ChatGPT will start forgetting things you said at the beginning of the chat.\\n\\n### Another visualization of ChatGPT trimming away the start of your conversation behind the scenes\\n\\n<Figure \\n  image={chatGPTCutting}\\n  alt=\\"A cartoon depicting a woman wearing a \'ChatGPT\' shirt, actively engaged in cutting a large roll of paper on the floor. The paper, covered in text like a book, is visibly being cut by the scissors in the woman\'s hands. The cut is halfway through the paper, illustrating the action of cutting. The cartoon should emphasize the humorous situation, with the woman\'s expression showing focus and the absurdly long paper being sliced by the scissors in a detailed and exaggerated style.\\"\\n  caption=\\"Generated with OpenAI DALL-E 3.\\" \\n/>\\n\\nIt\'s good to be mindful of this restriction, especially when referring back to earlier parts of a conversation that might have been truncated due to token limitations\u2014the LLM will not be able to recall these anymore, but the web version of ChatGPT will not tell you. There\'s also always the risk that it could hallucinate answers based on other parts of the conversation if the beginning is trimmed off.\\n\\nLet\'s take another look at what happens in a more complex yet sillier chat interaction.\\n\\n### Another typical but silly conversation with ChatGPT.\\n\\n<Figure \\n  image={chatgptNameImage1}\\n  alt=\\"A black and white comic panel depicts a woman and a person wearing a \'CHATGPT\' shirt having a conversation about rhymes. The woman says, \'My name is Jane! Can you give me a word that rhymes with my name?\' The person responds, \'Certainly! The word \'train\' rhymes with \'Jane\'.\' She asks for another, and they reply, \'Of course! The word \'plane\' rhymes with \'Jane\'.\' She requests yet another, and the person concludes, \'\'Brain\' rhymes with \'Jane\' as well.\' The drawing style is playful and cartoonish.\\"\\n  caption=\\"People images by OpenAI DALL-E 3. Text and comic bubbles by author.\\" \\n/>\\n\\n### Again, this is what is actually going on behind the scenes.\\n\\n<Figure \\n  image={chatgptNameImage2}\\n  alt=\\"A black and white comic strip portrays a dialogue between a woman and a person wearing a \'CHATGPT\' shirt. The woman is labeled \'USER\' and asks, \'My name is Jane! Can you give me a word that rhymes with my name?\' The \'CHATGPT\' character responds, \'Certainly! The word \'train\' rhymes with \'Jane\'.\' The \'USER\' asks for another word, and \'CHATGPT\' says, \'Of course! The word \'plane\' rhymes with \'Jane\'.\' The \'USER\' requests another, prompting \'CHATGPT\' to conclude with, \'\'Brain\' rhymes with \'Jane\'.\\"\\n  caption=\\"People images by OpenAI DALL-E 3. Text and comic bubbles by author.\\" \\n/>\\n\\n### Now let\'s suppose we have a long enough conversation that the beginning is trimmed off. ChatGPT might either state that it\'s forgotten the name entirely or hallucinate it.\\n\\n<Figure \\n  image={chatgptNameImage3}\\n  alt=\\"A black and white comic strip displays a woman labeled \'USER\' asking a person in a \'CHATGPT\' shirt for a word that rhymes with her name, Jane. Initially, \'CHATGPT\' provides \'train\' as a rhyming word. A series of speech bubbles follow with the text \'\u2026blah blah\u2026?\' and \'\u2026blah!\' indicating an inaudible conversation. In the last panel, the \'USER\' asks for another rhyming word, and \'CHATGPT\' amusingly offers \'jelly,\' humorously mispronouncing \'Jane\' as \'Kelly.\' The artwork is lighthearted.\\"\\n  caption=\\"People images by OpenAI DALL-E 3. Text and comic bubbles by author.\\" \\n/>\\n\\n### And finally, if we try to escape this problem by not feeding ChatGPT the entire conversation, it will forget it all the moment it finishes generating each answer.\\n\\n<Figure \\n  image={chatgptNameImage4}\\n  alt=\\"A black and white comic strip features a woman and a person wearing a \'CHATGPT\' shirt. The woman says, \'My name is Jane! Can you give me a word that rhymes with my name?\' The person replies, \'Certainly! The word \'train\' rhymes with \'Jane\'.\' She expresses delight and asks for another, to which the person humorously responds, \'Sure! Another what?\' She clarifies she wants another word that rhymes with her name, and the person cheekily responds, \'I\'d be happy to help! What\'s your name?\'\\"\\n  caption=\\"People images by OpenAI DALL-E 3. Text and comic bubbles by author.\\" \\n/>\\n\\nSince ChatGPT\'s debut in November 2022, GPT-4 has been released with both 8,192 and 32,768 context lengths. This made things a lot better in terms of tracking long conversations, and in November 2023, GPT-4 Turbo was released with a 128k context length. Things are looking increasingly good for these models\' ability to track long conversations. However, despite GPT-4 Turbo\'s massive amount of context, it still has a completion limit of 4,096 tokens, so it will always generate a maximum of about 3,000 words.\\n\\n## Why is it like this?\\n\\nTransformer-based models like GPT-3 and GPT-4 are designed to be stateless, for good reason! Primarily, this stateless nature significantly enhances scalability and efficiency. Each user request is processed independently, allowing the system to handle numerous queries simultaneously without the complexity of tracking ongoing conversations. Imagine the complexity if every time the model was called, it had to maintain some internal state across millions of users.\\n\\nTransformer model hidden states are also temporary and exist only for the duration of processing a specific input sequence. Once the model has processed an input and generated an output, these states are reset. They do not persist between different interactions.\\n\\nData privacy and security play a role as well. Stateless models do not retain a memory of past interactions, ensuring that sensitive data from one session is never inadvertently exposed to another user. This design choice is particularly relevant in light of incidents like [Microsoft\'s Tay,](https://en.wikipedia.org/wiki/Tay_(chatbot)) an AI chatbot that, due to its design to learn from interactions, ended up mimicking inappropriate and offensive language from users. It\'s just not safe to have models learn from inputs given by random users.\\n\\nHowever, the stateless nature also means these models cannot remember user preferences or learn from past interactions. This is a limitation in scenarios where you might want to create personalized chatbots through past chats or systems that benefit from cumulative learning. To mitigate this, some implementations incorporate a stateful layer atop the stateless LLM, enabling personalized and continuous user experiences.\\n\\n## Getting a bit more technical\\n\\nProminent examples of such layers include [LangChain](https://www.langchain.com/), [LlamaIndex](https://www.llamaindex.ai/), and [Haystack](https://haystack.deepset.ai/). These layers add flexibility to managing the limited context that LLMs can handle by offering various strategies. For instance, when approaching the token limit, choices must be made: Should a rolling window approach be used to discard older text, like in the web ChatGPT, or should GPT be utilized to summarize previous information? Is it more important to retain the initial context, like a source article, while removing less critical middle or later sections? Alternatively, should retrieval augmented generation (RAG\u2014more on that in a later blog) techniques be employed to integrate external data into the token stream? These decisions vary based on the specific goals of the implementation. The most effective architectures often consist of specialized components interwoven to achieve a wide array of practical outcomes, allowing for more nuanced and effective user interactions.\\n\\n<Figure \\n  image={confusedRobot}\\n  alt=\\"A cartoon depicting a robot sitting at a desk with an old-fashioned typewriter. The robot appears confused, as if it\'s trying to remember something. It\'s looking upwards with a thoughtful expression, one metal hand hovering over the typewriter keys. The scene is in black and white, capturing the essence of a classic cartoon, with simple lines and a humorous touch.\\"\\n  caption=\\"Generated with OpenAI DALL-E 3.\\"\\n/>\\n\\n:::info[Key Takeaways]\\n\\n- ChatGPT doesn\'t actually \\"remember\\" the conversations it has; instead, it simulates conversations by reading the entire chat from the start each time. Each interaction is independent, and once it\'s completed its response, it loses all context from that conversation. \\n\\n- The entire conversation history must be fed back to ChatGPT each time to create coherent responses. But as the chat grows longer, it starts to forget the initial parts of the conversation because of the constraints of its token limit (4k tokens for GPT-3.5, 8k for GPT-4, and an amazing 128k tokens for GPT-4 Turbo). \\n\\n- In the case of prolonged interactions, the parts of the conversation that were removed won\'t be recalled or acknowledged by the AI model. This happens unannounced in the web version of ChatGPT, making it important to be mindful of the length of the conversation and what parts may be forgotten.\\n\\n- If you\'re having a lengthy conversation on the ChatGPT web app and it relies on information from the start, consider copying and pasting the necessary parts into a new chat to avoid losing crucial context.\\n\\n- Tools like [TypingMind](https://www.typingmind.com/) allow users to selectively cut unimportant parts of the conversation and even direct the chat from a selected point. This ability to manually manage the conversation can provide a more controlled experience with ChatGPT.\\n\\n- ChatGPT and other similar models, like GPT-3 and GPT-4, are designed to be stateless for a variety of reasons, such as scalability, efficiency, and data privacy. \\n\\n- While their stateless nature makes these models safe and manageable at scale, the lack of memory and contextual retention is a limitation when it comes to personalization and continuous learning. Layered implementations like [LangChain](https://www.langchain.com/), [LlamaIndex](https://www.llamaindex.ai/), and [Haystack](https://haystack.deepset.ai/) help in managing this constraint.\\n\\n- As more advanced versions like GPT-4 with 8,192 and 32,768 context lengths and GPT-4 Turbo with a 128k context length come up, it enables longer conversations. However, there will always be a completion limit, currently at about 3,000 words (4,096 tokens) for GPT-4 Turbo. This completion limit may come as a surprise given the much larger [128k context of the model.](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)\\n\\n- Trying to dialogue with these models without providing the entire conversation effectively erases the memory of prior interactions, making them less effective in terms of continuity and coherence. \\n\\n- Future technological advances and updates may amend some of these constraints, enhancing the AI\'s ability to maintain long and complex conversations while also respecting user data privacy.\\n\\n:::"}]}')}}]);