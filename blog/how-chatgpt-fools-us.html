<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.0">
<title data-rh="true">How ChatGPT fools us into thinking we&#x27;re having a conversation | Short Attention</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://kelk.ai/blog/how-chatgpt-fools-us"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="How ChatGPT fools us into thinking we&#x27;re having a conversation | Short Attention"><meta data-rh="true" name="description" content="Remember the first time you used ChatGPT and how amazed you were to find yourself having what appeared to be a full-on conversation with an artificial intelligence? While ChatGPT was (and still is) mind-blowing, it uses a few tricks to make things appear more familiar."><meta data-rh="true" property="og:description" content="Remember the first time you used ChatGPT and how amazed you were to find yourself having what appeared to be a full-on conversation with an artificial intelligence? While ChatGPT was (and still is) mind-blowing, it uses a few tricks to make things appear more familiar."><meta data-rh="true" property="og:image" content="https://github.com/iankelk/iankelk.github.io/blob/main/blog/2023-11-26-stateless/social-card.jpg?raw=true"><meta data-rh="true" name="twitter:image" content="https://github.com/iankelk/iankelk.github.io/blob/main/blog/2023-11-26-stateless/social-card.jpg?raw=true"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2023-11-26T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://iankelk.github.io"><meta data-rh="true" property="article:tag" content="chat history,chatgpt,context,chat,AI,LLM,ML,chatbot,chatbots,AIExplained"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://kelk.ai/blog/how-chatgpt-fools-us"><link data-rh="true" rel="alternate" href="https://kelk.ai/blog/how-chatgpt-fools-us" hreflang="en"><link data-rh="true" rel="alternate" href="https://kelk.ai/blog/how-chatgpt-fools-us" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Short Attention RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Short Attention Atom Feed">
<link rel="alternate" type="application/json" href="/blog/feed.json" title="Short Attention JSON Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PNHB98RZ0D"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-PNHB98RZ0D",{anonymize_ip:!0})</script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.3d17bba5.css">
<script src="/assets/js/runtime~main.5d63cd4e.js" defer="defer"></script>
<script src="/assets/js/main.7cdb87a5.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Short Attention Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Short Attention Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Projects Page</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Short Attention Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/iankelk" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/llm-forward-thinking">LLMs are forward thinkers, and that&#x27;s a problem</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/how-chatgpt-fools-us">How ChatGPT fools us into thinking we&#x27;re having a conversation</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="https://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="Remember the first time you used ChatGPT and how amazed you were to find yourself having what appeared to be a full-on conversation with an artificial intelligence? While ChatGPT was (and still is) mind-blowing, it uses a few tricks to make things appear more familiar."><link itemprop="image" href="https://github.com/iankelk/iankelk.github.io/blob/main/blog/2023-11-26-stateless/social-card.jpg?raw=true"><header><h1 class="title_f1Hy" itemprop="headline">How ChatGPT fools us into thinking we&#x27;re having a conversation</h1><div class="container_mt6G margin-vert--md"><time datetime="2023-11-26T00:00:00.000Z" itemprop="datePublished">November 26, 2023</time> · <!-- -->12 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://iankelk.github.io" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/iankelk.png" alt="Ian Kelk" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://iankelk.github.io" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Ian Kelk</span></a></div><small class="avatar__subtitle" itemprop="description">Product Marketing @ Clarifai</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><p>Remember the first time you used ChatGPT and how amazed you were to find yourself having what appeared to be a full-on conversation with an artificial intelligence? While ChatGPT was (and still is) mind-blowing, it uses a few tricks to make things appear more familiar.</p>
<p>While the title of this article is a bit tongue-in-cheek, it is most certainly not clickbait. ChatGPT does indeed use two notable hidden techniques to simulate human conversation, and the more you know about how they work, the more effectively you can use the technology.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="/assets/images/social-card-e9b8326af5cd7ed2f1080c7e0dcc443c.jpg" data-pswp-width="0" data-pswp-height="0"><img src="/assets/images/social-card-e9b8326af5cd7ed2f1080c7e0dcc443c.jpg" alt="A black and white illustration of a late-night talk show setting, titled &#x27;The ChatGPT Show.&#x27; A classic, boxy robot with visible joints and a round head featuring antenna and eyes, is depicted as the guest. It&#x27;s gesturing with its hands as if in conversation. The host, a man in a suit with neat hair and a professional demeanor, sits across from the robot at a curved desk. Microphones and notes are on the desk, with an urban skyline visible through the window in the background." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em">Generated with OpenAI DALL-E 3.</figcaption></figure>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Some key points I&#x27;ll address here are:</div><div class="admonitionContent_BuS1"><ul>
<li>ChatGPT has no idea who you are and has no memory of talking to you at any point in the conversation.</li>
<li>It simulates conversations by &quot;reading&quot; the <em>whole</em> chat from the start each time.</li>
<li>As a conversation gets longer, ChatGPT starts removing pieces of the conversation from the start, creating a rolling window of context.</li>
<li>Because of this, very long chats will forget what was mentioned at the beginning.</li>
</ul></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="trick-1-every-time-you-talk-to-chatgpt-youre-not-just-sending-it-your-question-youre-also-sending-the-entire-conversation-up-until-that-point">Trick #1: Every time you talk to ChatGPT, you&#x27;re not just sending it your question. You&#x27;re also sending the <em>entire</em> conversation up until that point.<a href="#trick-1-every-time-you-talk-to-chatgpt-youre-not-just-sending-it-your-question-youre-also-sending-the-entire-conversation-up-until-that-point" class="hash-link" aria-label="Direct link to trick-1-every-time-you-talk-to-chatgpt-youre-not-just-sending-it-your-question-youre-also-sending-the-entire-conversation-up-until-that-point" title="Direct link to trick-1-every-time-you-talk-to-chatgpt-youre-not-just-sending-it-your-question-youre-also-sending-the-entire-conversation-up-until-that-point">​</a></h2>
<p>Contrary to appearances, large language models (LLMs) like ChatGPT do not actually &quot;remember&quot; past interactions. The moment they finish &quot;typing&quot; out their response, they have no idea who you are or what you were talking about. Each time the model is prompted, it is <strong>completely independent</strong> from previous questions you&#x27;ve asked.</p>
<p>When ChatGPT seems to naturally recall details from earlier in the conversation, it is an illusion; the context of that dialogue is given back to ChatGPT every time you say something to it. This context enables them to build coherent, follow-on responses that appear to be normal conversations.</p>
<p>However, without this context, ChatGPT would have no knowledge of what was previously discussed. Like all LLMs, ChatGPT is completely <em>stateless</em>, meaning that in the actual model itself, no information is maintained between inputs and outputs. All of this feeding of previous context into the current interaction is hidden behind the scenes in the ChatGPT web application.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-typical-short-conversation-with-chatgpt-might-go-like-this">A typical short conversation with ChatGPT might go like this:<a href="#a-typical-short-conversation-with-chatgpt-might-go-like-this" class="hash-link" aria-label="Direct link to A typical short conversation with ChatGPT might go like this:" title="Direct link to A typical short conversation with ChatGPT might go like this:">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="/assets/images/chatgpt-photosynthesis-1-c2aa8fee81245c48d51d92df0afc0aa5.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="/assets/images/chatgpt-photosynthesis-1-c2aa8fee81245c48d51d92df0afc0aa5.jpeg" alt="A black and white comic strip depicts a conversation between a woman and a person wearing a &#x27;CHATGPT&#x27; shirt. The woman asks, &#x27;What is photosynthesis?&#x27; The person responds, &#x27;Photosynthesis is the process by which plants use sunlight to synthesize nutrients from carbon dioxide and water.&#x27; She follows up with, &#x27;Can humans do it?&#x27; to which the person replies, &#x27;No, humans cannot perform photosynthesis.&#x27; The scene is simple with only the two characters and their speech bubbles." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em">People images by OpenAI DALL-E 3. Text and comic bubbles by author.</figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="however-this-is-what-is-actually-going-on-behind-the-scenes">However, this is what is actually going on behind the scenes:<a href="#however-this-is-what-is-actually-going-on-behind-the-scenes" class="hash-link" aria-label="Direct link to However, this is what is actually going on behind the scenes:" title="Direct link to However, this is what is actually going on behind the scenes:">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="/assets/images/chatgpt-photosynthesis-2-f3fb095ef8519a0ef8b7681e7719670c.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="/assets/images/chatgpt-photosynthesis-2-f3fb095ef8519a0ef8b7681e7719670c.jpeg" alt="A black and white comic strip showing a dialogue between a woman and a person wearing a &#x27;CHATGPT&#x27; shirt. The woman is labeled &#x27;USER&#x27; and asks, &#x27;What is photosynthesis?&#x27; The person labeled &#x27;CHATGPT&#x27; answers, &#x27;Photosynthesis is the process by which plants use sunlight to synthesize nutrients from carbon dioxide and water.&#x27; The woman, termed &#x27;USER&#x27; again, follows with, &#x27;Can humans do it?&#x27; and receives the reply, &#x27;No, humans cannot perform photosynthesis.&#x27; Both characters are drawn as cartoons." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em">People images by OpenAI DALL-E 3. Text and comic bubbles by author.</figcaption></figure>
<p>Notice that when the woman asks her second question, she has to reiterate the entire previous conversation, complete with tags on who said what. Can you imagine talking to a person where every time it was your turn to speak, you had to repeat the entire conversation up to that point? This is how ChatGPT (and all current LLMs) work. They require using their own outputs, plus the prompts that generated these outputs, to be prepended to the start of every new prompt from the user.</p>
<p>These models are termed &quot;autoregressive&quot; due to their method of generating text one piece at a time, building upon the previously generated text. &quot;auto&quot; comes from the Greek word &quot;autós,&quot; meaning &quot;self,&quot; and &quot;regressive&quot; is derived from &quot;regress,&quot; which in this context refers to the statistical method of predicting future values based on past values.</p>
<p>In LLMs, what this means is that the model predicts the next word or token in a sequence based on <em>all</em> the words or tokens that have come before it. That&#x27;s <em>all</em> of it, not just the current question being asked in a long back-and-forth chat conversation. In humans, we naturally maintain coherence and context in a conversation by just... participating in the conversation.</p>
<p>However, while chats with ChatGPT mimic a conversational style, with each response building upon the previous dialogue, the moment ChatGPT finishes writing a response, it has no memory of what it just said. Take a look at what would happen with this same conversation without the <em>entire discourse</em> being fed back to ChatGPT behind the scenes:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-would-chatgpt-respond-without-being-fed-the-whole-conversation">How would ChatGPT respond without being fed the whole conversation?<a href="#how-would-chatgpt-respond-without-being-fed-the-whole-conversation" class="hash-link" aria-label="Direct link to How would ChatGPT respond without being fed the whole conversation?" title="Direct link to How would ChatGPT respond without being fed the whole conversation?">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="/assets/images/chatgpt-photosynthesis-3-12c4e20361df1dbcb1838a483460eb32.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="/assets/images/chatgpt-photosynthesis-3-12c4e20361df1dbcb1838a483460eb32.jpeg" alt="A black and white comic panel featuring a conversation between a woman and a person wearing a &#x27;CHATGPT&#x27; shirt. The woman asks, &#x27;What is photosynthesis?&#x27; The person replies, &#x27;Photosynthesis is the process by which plants use sunlight to synthesize nutrients from carbon dioxide and water.&#x27; The woman then asks, &#x27;Can humans do it?&#x27; to which the person humorously responds, &#x27;Can humans do what?&#x27; The characters are depicted in a lighthearted, cartoonish style, with the focus on their dialogue." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em">People images by OpenAI DALL-E 3. Text and comic bubbles by author.</figcaption></figure>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="trick-2-as-your-conversation-grows-chatgpt-will-quietly-remove-the-oldest-parts-from-the-beginning">Trick #2: As your conversation grows, ChatGPT will quietly remove the oldest parts from the beginning.<a href="#trick-2-as-your-conversation-grows-chatgpt-will-quietly-remove-the-oldest-parts-from-the-beginning" class="hash-link" aria-label="Direct link to Trick #2: As your conversation grows, ChatGPT will quietly remove the oldest parts from the beginning." title="Direct link to Trick #2: As your conversation grows, ChatGPT will quietly remove the oldest parts from the beginning.">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="context-length-in-llms">Context Length in LLMs<a href="#context-length-in-llms" class="hash-link" aria-label="Direct link to Context Length in LLMs" title="Direct link to Context Length in LLMs">​</a></h4>
<p>When ChatGPT first came out in November 2022, it only offered the model GPT-3.5, which had a maximum context of 4,096 tokens, which is roughly 3,000 words. In a <a href="https://youtu.be/zjkBMFhNj_g?t=2642" target="_blank" rel="noopener noreferrer">recent talk,</a> Andrej Karpathy referred to this context window as &quot;your finite precious resource of your working memory of your language model.&quot;</p>
<p>What this means is that the GPT-3.5 model can comprehend a maximum of 4,096 tokens at any point. Tokenization is a fascinating subject in itself, and my next post will cover how it works and why 4,096 tokens only gives you about 3,000 words.</p>
<p>There&#x27;s often confusion about what the token limit means regarding input and output: can we give ChatGPT 3,000 words and expect it to be able to produce 3,000 words back? The answer is unfortunately no; the context length of 4,096 tokens covers both the input (prompt) and the output (response). This results in a trade-off where we have to balance the amount of information we give in a prompt with the length of the response we get from the model.</p>
<ol>
<li>
<p><em>Input (prompt):</em> A longer prompt leaves less room for a meaningful response; if the input uses 4,000 tokens, the response can only be 96 tokens long to stay within the token limit.</p>
</li>
<li>
<p><em>Output (response):</em> A shorter prompt could lead to a longer response as long as the combined length doesn&#x27;t exceed the token limit, but you may not be able to include information in the prompt.</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-chat-problem">The chat problem<a href="#the-chat-problem" class="hash-link" aria-label="Direct link to The chat problem" title="Direct link to The chat problem">​</a></h3>
<p>Do you see where this becomes problematic? Previously, we saw how the entire conversation has to be fed to the model so that it remembers what has already been discussed. Combining this with the context length, the result is that as you talk more and more with ChatGPT, eventually the combined totals of what you&#x27;ve asked and what it has replied will exceed the 4,096 token limit, and it won&#x27;t be able to answer any more.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-visualization-of-chatgpt-simultaneously-printing-and-scanning-back-in-the-entire-conversation-as-it-grows-to-extreme-proportions">A visualization of ChatGPT simultaneously printing and scanning back in the entire conversation as it grows to extreme proportions<a href="#a-visualization-of-chatgpt-simultaneously-printing-and-scanning-back-in-the-entire-conversation-as-it-grows-to-extreme-proportions" class="hash-link" aria-label="Direct link to A visualization of ChatGPT simultaneously printing and scanning back in the entire conversation as it grows to extreme proportions" title="Direct link to A visualization of ChatGPT simultaneously printing and scanning back in the entire conversation as it grows to extreme proportions">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="/assets/images/rolled-chatgpt-51756537e64b16efdf83b5001c773e26.jpg" data-pswp-width="0" data-pswp-height="0"><img src="/assets/images/rolled-chatgpt-51756537e64b16efdf83b5001c773e26.jpg" alt="An illustration showcasing a printer labeled &#x27;ChatGPT&#x27; in the foreground, and a scanner in the background, with a large loop of paper moving between them. The printer is actively printing the paper, which then rises up, forms a significant loop, and clearly feeds into the scanner. The paper should be filled with printed text, resembling pages of a book. The drawing should vividly depict the paper&#x27;s journey from the &#x27;ChatGPT&#x27; printer, through the loop, and into the scanner." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em">Generated with OpenAI DALL-E 3.</figcaption></figure>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="conversation-length-and-token-limitations-in-llms">Conversation Length and Token Limitations in LLMs<a href="#conversation-length-and-token-limitations-in-llms" class="hash-link" aria-label="Direct link to Conversation Length and Token Limitations in LLMs" title="Direct link to Conversation Length and Token Limitations in LLMs">​</a></h4>
<p>So how does ChatGPT handle this limitation? As your conversation with it grows, the number of tokens eventually exceeds the model&#x27;s context window (e.g., 4,096 tokens for GPT-3.5). ChatGPT invisibly removes the oldest parts of the conversation to remain within the limit. This method—using a rolling window of context—is certainly one of the easiest to implement, but oftentimes it is not the perfect solution. Some chat alternative front-ends, like <a href="https://www.typingmind.com/" target="_blank" rel="noopener noreferrer">TypingMind</a> both warn you when the context limit has been reached and allow you to manually delete sections of the chat that you don&#x27;t need anymore. This lets you choose what information you want to remain in the chat and has the bizarre philosophical effect of &quot;editing the memory&quot; of GPT.</p>
<p>For your average user using the web version of ChatGPT, what this means is that the longer your conversation, the sooner ChatGPT will start forgetting things you said at the beginning of the chat.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="another-visualization-of-chatgpt-trimming-away-the-start-of-your-conversation-behind-the-scenes">Another visualization of ChatGPT trimming away the start of your conversation behind the scenes<a href="#another-visualization-of-chatgpt-trimming-away-the-start-of-your-conversation-behind-the-scenes" class="hash-link" aria-label="Direct link to Another visualization of ChatGPT trimming away the start of your conversation behind the scenes" title="Direct link to Another visualization of ChatGPT trimming away the start of your conversation behind the scenes">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="/assets/images/chatgpt-cutting-a46d0da8fb8e542b1fc4668473f7d58b.jpg" data-pswp-width="0" data-pswp-height="0"><img src="/assets/images/chatgpt-cutting-a46d0da8fb8e542b1fc4668473f7d58b.jpg" alt="A cartoon depicting a woman wearing a &#x27;ChatGPT&#x27; shirt, actively engaged in cutting a large roll of paper on the floor. The paper, covered in text like a book, is visibly being cut by the scissors in the woman&#x27;s hands. The cut is halfway through the paper, illustrating the action of cutting. The cartoon should emphasize the humorous situation, with the woman&#x27;s expression showing focus and the absurdly long paper being sliced by the scissors in a detailed and exaggerated style." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em">Generated with OpenAI DALL-E 3.</figcaption></figure>
<p>It&#x27;s good to be mindful of this restriction, especially when referring back to earlier parts of a conversation that might have been truncated due to token limitations—the LLM will not be able to recall these anymore, but the web version of ChatGPT will not tell you. There&#x27;s also always the risk that it could hallucinate answers based on other parts of the conversation if the beginning is trimmed off.</p>
<p>Let&#x27;s take another look at what happens in a more complex yet sillier chat interaction.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="another-typical-but-silly-conversation-with-chatgpt">Another typical but silly conversation with ChatGPT.<a href="#another-typical-but-silly-conversation-with-chatgpt" class="hash-link" aria-label="Direct link to Another typical but silly conversation with ChatGPT." title="Direct link to Another typical but silly conversation with ChatGPT.">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="/assets/images/chatgpt-name-1-dc45db4079f1e8dafba7ab49b90ae76b.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="/assets/images/chatgpt-name-1-dc45db4079f1e8dafba7ab49b90ae76b.jpeg" alt="A black and white comic panel depicts a woman and a person wearing a &#x27;CHATGPT&#x27; shirt having a conversation about rhymes. The woman says, &#x27;My name is Jane! Can you give me a word that rhymes with my name?&#x27; The person responds, &#x27;Certainly! The word &#x27;train&#x27; rhymes with &#x27;Jane&#x27;.&#x27; She asks for another, and they reply, &#x27;Of course! The word &#x27;plane&#x27; rhymes with &#x27;Jane&#x27;.&#x27; She requests yet another, and the person concludes, &#x27;&#x27;Brain&#x27; rhymes with &#x27;Jane&#x27; as well.&#x27; The drawing style is playful and cartoonish." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em">People images by OpenAI DALL-E 3. Text and comic bubbles by author.</figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="again-this-is-what-is-actually-going-on-behind-the-scenes">Again, this is what is actually going on behind the scenes.<a href="#again-this-is-what-is-actually-going-on-behind-the-scenes" class="hash-link" aria-label="Direct link to Again, this is what is actually going on behind the scenes." title="Direct link to Again, this is what is actually going on behind the scenes.">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="/assets/images/chatgpt-name-2-67272e5821cb56c4a9ca8fd3edd0dd51.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="/assets/images/chatgpt-name-2-67272e5821cb56c4a9ca8fd3edd0dd51.jpeg" alt="A black and white comic strip portrays a dialogue between a woman and a person wearing a &#x27;CHATGPT&#x27; shirt. The woman is labeled &#x27;USER&#x27; and asks, &#x27;My name is Jane! Can you give me a word that rhymes with my name?&#x27; The &#x27;CHATGPT&#x27; character responds, &#x27;Certainly! The word &#x27;train&#x27; rhymes with &#x27;Jane&#x27;.&#x27; The &#x27;USER&#x27; asks for another word, and &#x27;CHATGPT&#x27; says, &#x27;Of course! The word &#x27;plane&#x27; rhymes with &#x27;Jane&#x27;.&#x27; The &#x27;USER&#x27; requests another, prompting &#x27;CHATGPT&#x27; to conclude with, &#x27;&#x27;Brain&#x27; rhymes with &#x27;Jane&#x27;." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em">People images by OpenAI DALL-E 3. Text and comic bubbles by author.</figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="now-lets-suppose-we-have-a-long-enough-conversation-that-the-beginning-is-trimmed-off-chatgpt-might-either-state-that-its-forgotten-the-name-entirely-or-hallucinate-it">Now let&#x27;s suppose we have a long enough conversation that the beginning is trimmed off. ChatGPT might either state that it&#x27;s forgotten the name entirely or hallucinate it.<a href="#now-lets-suppose-we-have-a-long-enough-conversation-that-the-beginning-is-trimmed-off-chatgpt-might-either-state-that-its-forgotten-the-name-entirely-or-hallucinate-it" class="hash-link" aria-label="Direct link to Now let&#x27;s suppose we have a long enough conversation that the beginning is trimmed off. ChatGPT might either state that it&#x27;s forgotten the name entirely or hallucinate it." title="Direct link to Now let&#x27;s suppose we have a long enough conversation that the beginning is trimmed off. ChatGPT might either state that it&#x27;s forgotten the name entirely or hallucinate it.">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="/assets/images/chatgpt-name-3-8ba86b96f0761141eb93a27cbb4d0e12.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="/assets/images/chatgpt-name-3-8ba86b96f0761141eb93a27cbb4d0e12.jpeg" alt="A black and white comic strip displays a woman labeled &#x27;USER&#x27; asking a person in a &#x27;CHATGPT&#x27; shirt for a word that rhymes with her name, Jane. Initially, &#x27;CHATGPT&#x27; provides &#x27;train&#x27; as a rhyming word. A series of speech bubbles follow with the text &#x27;…blah blah…?&#x27; and &#x27;…blah!&#x27; indicating an inaudible conversation. In the last panel, the &#x27;USER&#x27; asks for another rhyming word, and &#x27;CHATGPT&#x27; amusingly offers &#x27;jelly,&#x27; humorously mispronouncing &#x27;Jane&#x27; as &#x27;Kelly.&#x27; The artwork is lighthearted." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em">People images by OpenAI DALL-E 3. Text and comic bubbles by author.</figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="and-finally-if-we-try-to-escape-this-problem-by-not-feeding-chatgpt-the-entire-conversation-it-will-forget-it-all-the-moment-it-finishes-generating-each-answer">And finally, if we try to escape this problem by not feeding ChatGPT the entire conversation, it will forget it all the moment it finishes generating each answer.<a href="#and-finally-if-we-try-to-escape-this-problem-by-not-feeding-chatgpt-the-entire-conversation-it-will-forget-it-all-the-moment-it-finishes-generating-each-answer" class="hash-link" aria-label="Direct link to And finally, if we try to escape this problem by not feeding ChatGPT the entire conversation, it will forget it all the moment it finishes generating each answer." title="Direct link to And finally, if we try to escape this problem by not feeding ChatGPT the entire conversation, it will forget it all the moment it finishes generating each answer.">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="/assets/images/chatgpt-name-4-338403f314511d72e5f115cdd83ccdbf.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="/assets/images/chatgpt-name-4-338403f314511d72e5f115cdd83ccdbf.jpeg" alt="A black and white comic strip features a woman and a person wearing a &#x27;CHATGPT&#x27; shirt. The woman says, &#x27;My name is Jane! Can you give me a word that rhymes with my name?&#x27; The person replies, &#x27;Certainly! The word &#x27;train&#x27; rhymes with &#x27;Jane&#x27;.&#x27; She expresses delight and asks for another, to which the person humorously responds, &#x27;Sure! Another what?&#x27; She clarifies she wants another word that rhymes with her name, and the person cheekily responds, &#x27;I&#x27;d be happy to help! What&#x27;s your name?&#x27;" style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em">People images by OpenAI DALL-E 3. Text and comic bubbles by author.</figcaption></figure>
<p>Since ChatGPT&#x27;s debut in November 2022, GPT-4 has been released with both 8,192 and 32,768 context lengths. This made things a lot better in terms of tracking long conversations, and in November 2023, GPT-4 Turbo was released with a 128k context length. Things are looking increasingly good for these models&#x27; ability to track long conversations. However, despite GPT-4 Turbo&#x27;s massive amount of context, it still has a completion limit of 4,096 tokens, so it will always generate a maximum of about 3,000 words.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-is-it-like-this">Why is it like this?<a href="#why-is-it-like-this" class="hash-link" aria-label="Direct link to Why is it like this?" title="Direct link to Why is it like this?">​</a></h2>
<p>Transformer-based models like GPT-3 and GPT-4 are designed to be stateless, for good reason! Primarily, this stateless nature significantly enhances scalability and efficiency. Each user request is processed independently, allowing the system to handle numerous queries simultaneously without the complexity of tracking ongoing conversations. Imagine the complexity if every time the model was called, it had to maintain some internal state across millions of users.</p>
<p>Transformer model hidden states are also temporary and exist only for the duration of processing a specific input sequence. Once the model has processed an input and generated an output, these states are reset. They do not persist between different interactions.</p>
<p>Data privacy and security play a role as well. Stateless models do not retain a memory of past interactions, ensuring that sensitive data from one session is never inadvertently exposed to another user. This design choice is particularly relevant in light of incidents like <a href="https://en.wikipedia.org/wiki/Tay_(chatbot)" target="_blank" rel="noopener noreferrer">Microsoft&#x27;s Tay,</a> an AI chatbot that, due to its design to learn from interactions, ended up mimicking inappropriate and offensive language from users. It&#x27;s just not safe to have models learn from inputs given by random users.</p>
<p>However, the stateless nature also means these models cannot remember user preferences or learn from past interactions. This is a limitation in scenarios where you might want to create personalized chatbots through past chats or systems that benefit from cumulative learning. To mitigate this, some implementations incorporate a stateful layer atop the stateless LLM, enabling personalized and continuous user experiences.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="getting-a-bit-more-technical">Getting a bit more technical<a href="#getting-a-bit-more-technical" class="hash-link" aria-label="Direct link to Getting a bit more technical" title="Direct link to Getting a bit more technical">​</a></h2>
<p>Prominent examples of such layers include <a href="https://www.langchain.com/" target="_blank" rel="noopener noreferrer">LangChain</a>, <a href="https://www.llamaindex.ai/" target="_blank" rel="noopener noreferrer">LlamaIndex</a>, and <a href="https://haystack.deepset.ai/" target="_blank" rel="noopener noreferrer">Haystack</a>. These layers add flexibility to managing the limited context that LLMs can handle by offering various strategies. For instance, when approaching the token limit, choices must be made: Should a rolling window approach be used to discard older text, like in the web ChatGPT, or should GPT be utilized to summarize previous information? Is it more important to retain the initial context, like a source article, while removing less critical middle or later sections? Alternatively, should retrieval augmented generation (RAG—more on that in a later blog) techniques be employed to integrate external data into the token stream? These decisions vary based on the specific goals of the implementation. The most effective architectures often consist of specialized components interwoven to achieve a wide array of practical outcomes, allowing for more nuanced and effective user interactions.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="/assets/images/confused-1597cabfce805e83f79ef2cf41a2807c.jpg" data-pswp-width="0" data-pswp-height="0"><img src="/assets/images/confused-1597cabfce805e83f79ef2cf41a2807c.jpg" alt="A cartoon depicting a robot sitting at a desk with an old-fashioned typewriter. The robot appears confused, as if it&#x27;s trying to remember something. It&#x27;s looking upwards with a thoughtful expression, one metal hand hovering over the typewriter keys. The scene is in black and white, capturing the essence of a classic cartoon, with simple lines and a humorous touch." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em">Generated with OpenAI DALL-E 3.</figcaption></figure>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Key Takeaways</div><div class="admonitionContent_BuS1"><ul>
<li>
<p>ChatGPT doesn&#x27;t actually &quot;remember&quot; the conversations it has; instead, it simulates conversations by reading the entire chat from the start each time. Each interaction is independent, and once it&#x27;s completed its response, it loses all context from that conversation.</p>
</li>
<li>
<p>The entire conversation history must be fed back to ChatGPT each time to create coherent responses. But as the chat grows longer, it starts to forget the initial parts of the conversation because of the constraints of its token limit (4k tokens for GPT-3.5, 8k for GPT-4, and an amazing 128k tokens for GPT-4 Turbo).</p>
</li>
<li>
<p>In the case of prolonged interactions, the parts of the conversation that were removed won&#x27;t be recalled or acknowledged by the AI model. This happens unannounced in the web version of ChatGPT, making it important to be mindful of the length of the conversation and what parts may be forgotten.</p>
</li>
<li>
<p>If you&#x27;re having a lengthy conversation on the ChatGPT web app and it relies on information from the start, consider copying and pasting the necessary parts into a new chat to avoid losing crucial context.</p>
</li>
<li>
<p>Tools like <a href="https://www.typingmind.com/" target="_blank" rel="noopener noreferrer">TypingMind</a> allow users to selectively cut unimportant parts of the conversation and even direct the chat from a selected point. This ability to manually manage the conversation can provide a more controlled experience with ChatGPT.</p>
</li>
<li>
<p>ChatGPT and other similar models, like GPT-3 and GPT-4, are designed to be stateless for a variety of reasons, such as scalability, efficiency, and data privacy.</p>
</li>
<li>
<p>While their stateless nature makes these models safe and manageable at scale, the lack of memory and contextual retention is a limitation when it comes to personalization and continuous learning. Layered implementations like <a href="https://www.langchain.com/" target="_blank" rel="noopener noreferrer">LangChain</a>, <a href="https://www.llamaindex.ai/" target="_blank" rel="noopener noreferrer">LlamaIndex</a>, and <a href="https://haystack.deepset.ai/" target="_blank" rel="noopener noreferrer">Haystack</a> help in managing this constraint.</p>
</li>
<li>
<p>As more advanced versions like GPT-4 with 8,192 and 32,768 context lengths and GPT-4 Turbo with a 128k context length come up, it enables longer conversations. However, there will always be a completion limit, currently at about 3,000 words (4,096 tokens) for GPT-4 Turbo. This completion limit may come as a surprise given the much larger <a href="https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo" target="_blank" rel="noopener noreferrer">128k context of the model.</a></p>
</li>
<li>
<p>Trying to dialogue with these models without providing the entire conversation effectively erases the memory of prior interactions, making them less effective in terms of continuity and coherence.</p>
</li>
<li>
<p>Future technological advances and updates may amend some of these constraints, enhancing the AI&#x27;s ability to maintain long and complex conversations while also respecting user data privacy.</p>
</li>
</ul></div></div></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/chat-history">chat history</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/chatgpt">chatgpt</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/context">context</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/chat">chat</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/ai">AI</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/llm">LLM</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/ml">ML</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/chatbot">chatbot</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/chatbots">chatbots</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/ai-explained">AIExplained</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/llm-forward-thinking"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">LLMs are forward thinkers, and that&#x27;s a problem</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#trick-1-every-time-you-talk-to-chatgpt-youre-not-just-sending-it-your-question-youre-also-sending-the-entire-conversation-up-until-that-point" class="table-of-contents__link toc-highlight">Trick #1: Every time you talk to ChatGPT, you&#39;re not just sending it your question. You&#39;re also sending the <em>entire</em> conversation up until that point.</a><ul><li><a href="#a-typical-short-conversation-with-chatgpt-might-go-like-this" class="table-of-contents__link toc-highlight">A typical short conversation with ChatGPT might go like this:</a></li><li><a href="#however-this-is-what-is-actually-going-on-behind-the-scenes" class="table-of-contents__link toc-highlight">However, this is what is actually going on behind the scenes:</a></li><li><a href="#how-would-chatgpt-respond-without-being-fed-the-whole-conversation" class="table-of-contents__link toc-highlight">How would ChatGPT respond without being fed the whole conversation?</a></li></ul></li><li><a href="#trick-2-as-your-conversation-grows-chatgpt-will-quietly-remove-the-oldest-parts-from-the-beginning" class="table-of-contents__link toc-highlight">Trick #2: As your conversation grows, ChatGPT will quietly remove the oldest parts from the beginning.</a><ul><li><a href="#the-chat-problem" class="table-of-contents__link toc-highlight">The chat problem</a></li><li><a href="#a-visualization-of-chatgpt-simultaneously-printing-and-scanning-back-in-the-entire-conversation-as-it-grows-to-extreme-proportions" class="table-of-contents__link toc-highlight">A visualization of ChatGPT simultaneously printing and scanning back in the entire conversation as it grows to extreme proportions</a></li><li><a href="#another-visualization-of-chatgpt-trimming-away-the-start-of-your-conversation-behind-the-scenes" class="table-of-contents__link toc-highlight">Another visualization of ChatGPT trimming away the start of your conversation behind the scenes</a></li><li><a href="#another-typical-but-silly-conversation-with-chatgpt" class="table-of-contents__link toc-highlight">Another typical but silly conversation with ChatGPT.</a></li><li><a href="#again-this-is-what-is-actually-going-on-behind-the-scenes" class="table-of-contents__link toc-highlight">Again, this is what is actually going on behind the scenes.</a></li><li><a href="#now-lets-suppose-we-have-a-long-enough-conversation-that-the-beginning-is-trimmed-off-chatgpt-might-either-state-that-its-forgotten-the-name-entirely-or-hallucinate-it" class="table-of-contents__link toc-highlight">Now let&#39;s suppose we have a long enough conversation that the beginning is trimmed off. ChatGPT might either state that it&#39;s forgotten the name entirely or hallucinate it.</a></li><li><a href="#and-finally-if-we-try-to-escape-this-problem-by-not-feeding-chatgpt-the-entire-conversation-it-will-forget-it-all-the-moment-it-finishes-generating-each-answer" class="table-of-contents__link toc-highlight">And finally, if we try to escape this problem by not feeding ChatGPT the entire conversation, it will forget it all the moment it finishes generating each answer.</a></li></ul></li><li><a href="#why-is-it-like-this" class="table-of-contents__link toc-highlight">Why is it like this?</a></li><li><a href="#getting-a-bit-more-technical" class="table-of-contents__link toc-highlight">Getting a bit more technical</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Social</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://twitter.com/kelkulus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/iankelk" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Blog Feeds</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://kelk.ai/blog/rss.xml" target="_blank" rel="noopener noreferrer" class="footer__link-item">RSS<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://kelk.ai/blog/atom.xml" target="_blank" rel="noopener noreferrer" class="footer__link-item">Atom<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://kelk.ai/blog/feed.json" target="_blank" rel="noopener noreferrer" class="footer__link-item">JSON<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Short Attention Blog</div></div></div></footer></div>
</body>
</html>