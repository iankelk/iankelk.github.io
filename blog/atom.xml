<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://kelk.ai/blog</id>
    <title>Short Attention Blog</title>
    <updated>2024-05-13T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://kelk.ai/blog"/>
    <subtitle>Short Attention Blog</subtitle>
    <icon>https://kelk.ai/img/favicon.ico</icon>
    <rights>Copyright © 2024 Short Attention Blog</rights>
    <entry>
        <title type="html"><![CDATA[Secret LLM chickens II: Tuning the chicken]]></title>
        <id>https://kelk.ai/blog/secret-chickens-tuning</id>
        <link href="https://kelk.ai/blog/secret-chickens-tuning"/>
        <updated>2024-05-13T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[When working with an LLM, sometimes it doesn't generate responses in the way you want. Maybe it's being too creative and weird when tasked with serious prompts ("Write me a cover letter for a programming job" "I am a coding wizard and I always min-max my character!"), or it's being too serious when you want to do some creative writing ("Write me a story" "You are tired and you lie down and go to sleep. The end."). This can be tweaked by making certain adjustments to the sampling mechanism--aka "the chicken."]]></summary>
        <content type="html"><![CDATA[<p>When working with an LLM, sometimes it doesn't generate responses in the way you want. Maybe it's being too creative and weird when tasked with serious prompts ("Write me a cover letter for a programming job" <em>"I am a coding wizard and I always min-max my character!"</em>), or it's being too serious when you want to do some creative writing ("Write me a story" <em>"You are tired and you lie down and go to sleep. The end."</em>). This can be tweaked by making certain adjustments to the sampling mechanism—aka "the chicken."</p>
<p><em>This blog post continues from my previous article, <a href="https://kelk.ai/blog/secret-chickens-llm">The secret chickens that run LLMs</a>, and you should read that first to understand what a "stochastic chicken" is.</em></p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/social-card-9590ee3d8c3ccad0ba104cf29246d33b.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/social-card-9590ee3d8c3ccad0ba104cf29246d33b.jpg" alt="Cartoon chicken winking at the camera. It is in a cluttered workspace filled with multiple computer monitors, electronics, and miscellaneous items, giving the impression of a tech-savvy or hacker chicken." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Some key points I'll address here are:</div><div class="admonitionContent_BuS1"><ul>
<li>The "chicken" can be tuned, using <a href="https://kelk.ai/blog/secret-chickens-tuning#whats-an-inference-hyperparameter">inference hyperparameters</a> like temperature, top-k, and top-p. These  serve as dials to fine-tune the randomness introduced by the stochastic process, balancing creativity and coherence in the text they generate.</li>
<li>Adjusting the temperature parameter can make the model's outputs more predictable and less random at lower values, or more diverse and less deterministic at higher values.</li>
<li>Modifying the top-k and top-p parameters fine-tunes the sampling process by limiting the set of possible next words.</li>
<li>Top-k restricts the model to choose from the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span> most likely next words, while top-p uses a probability threshold to create a dynamic set of options. These tweaks help balance creativity with coherence, allowing the LLM to better meet specific needs or experimental conditions.</li>
<li>Even when using top-k, the astronomical number of possible text sequences challenges the idea of detecting originality and plagiarism. It's nearly impossible to <em>prove</em> the source of any specific piece of text generated by these models, although LLM-generated text can be recognizable due to the language and style used.</li>
</ul></div></div>
<br>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>As in my previous "secret chickens" post, I frequently use the term <em>word</em> instead of <em>token</em> to describe what an LLM predicts. This is just a useful simplification to avoid having to address why the model might predict half a word or a semicolon, since the underlying principles of the "stochastic chicken" are the same.</p></div></div>
<p>If you've ever dug into the optional tuning knobs of an LLM provider API, you might have references to tuning "inference hyperparameters" to control how "creative" an LLM can be. These are ways of finding a balance between coherence (sticking to a topic or narrative) and creativity (introducing novel ideas or phrases).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="whats-a-hyperparameter">What's a hyperparameter?<a class="hash-link" aria-label="Direct link to What's a hyperparameter?" title="Direct link to What's a hyperparameter?" href="https://kelk.ai/blog/secret-chickens-tuning#whats-a-hyperparameter">​</a></h2>
<p>When training a neural network, a <strong>hyperparameter</strong> is a value used to control the learning process and is set <em>before</em> training a model, as opposed to the parameters which are learned during training (and are part of the model itself). Hyperparameters influence various aspects of training including the structure of the neural network (like the number of layers and the number of units per layer), as well as how the network is trained (like the learning rate, batch size, and the number of epochs). These last three explained in simplified terms are:</p>
<ul>
<li><strong>Learning rate</strong>: How <em>fast</em> the model learns. If the model goes too slowly, it might not learn properly, and if it goes too fast it might skip right over what it needs to learn.</li>
<li><strong>Number of epochs</strong>: How <em>long</em> the model learns. The total number of times the algorithm will work through training data (going through all the data one time is a single epoch).</li>
<li><strong>Batch size</strong>: How many things the model learns at the <em>same time</em>. This is often a trade-off based on how much compute and memory you have.</li>
</ul>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/studying-8795bbdbfb9c6d361b882a0b701486c8.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/studying-8795bbdbfb9c6d361b882a0b701486c8.jpg" alt="An artistic representation of an artificial neuron depicted as a student, studying intensely. The neuron, stylized as a character, is surrounded by books and digital screens displaying complex mathematical equations and data charts. The setting is a cozy study room with a vintage desk and soft lighting." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Study study study!</span><br><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="whats-an-inference-hyperparameter">What's an inference hyperparameter?<a class="hash-link" aria-label="Direct link to What's an inference hyperparameter?" title="Direct link to What's an inference hyperparameter?" href="https://kelk.ai/blog/secret-chickens-tuning#whats-an-inference-hyperparameter">​</a></h2>
<p>An "inference hyperparameter" refers to a configuration for how a model, particularly language models, produce predictions. These settings are used <em>after</em> training by the end users. The most common ones used are <em>temperature</em>, <em>top-k</em>, and <em>top-p</em>, which control the behavior of the model when generating text. They influence aspects like diversity, randomness, and the overall style of the output. Unlike traditional hyperparameters set prior to training to guide the learning process, <strong>inference hyperparameters</strong> are set to optimize performance for specific tasks when actually using the model.</p>
<p>What may come as a surprise is that these inference hyperparameters don't modify the massive underlying neural network part of these models at all.</p>
<p>They affect the chicken.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chicken-guitar-3e3d2a4dda52470fc506d03058a56202.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chicken-guitar-3e3d2a4dda52470fc506d03058a56202.jpg" alt="Whimsical illustration of a large rooster playing a guitar." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>An unbalanced chicken finding the optimal tuning</span><br><span> Generated with Midjourney 6 and edited by the author</span></figcaption></figure>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>Hyperparameters are set when <em>training</em> a model, and inference hyperparameters are set when <em>using</em> a trained model.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="common-inference-parameters">Common inference parameters<a class="hash-link" aria-label="Direct link to Common inference parameters" title="Direct link to Common inference parameters" href="https://kelk.ai/blog/secret-chickens-tuning#common-inference-parameters">​</a></h2>
<p>Let's take a closer look at these "chicken tuning" mechanisms.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="temperature">Temperature<a class="hash-link" aria-label="Direct link to Temperature" title="Direct link to Temperature" href="https://kelk.ai/blog/secret-chickens-tuning#temperature">​</a></h3>
<p>Temperature is an inference hyperparameter used to control the randomness of predictions by scaling the logits (the raw output scores from the model) before applying the softmax function to get probabilities. The temperature parameter basically adjusts how conservative or adventurous the model's predictions are.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="temperature--1">Temperature = 1<a class="hash-link" aria-label="Direct link to Temperature = 1" title="Direct link to Temperature = 1" href="https://kelk.ai/blog/secret-chickens-tuning#temperature--1">​</a></h4>
<p>When the temperature is set to 1, it has no effect on the logits, and the model produces outcomes based on the trained probabilities. This is the default setting, where no scaling is applied, and the chicken's choices won't be affected.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chicken-original-d7b35cc74ceb0e97b6acd0dcab8bb820.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chicken-original-d7b35cc74ceb0e97b6acd0dcab8bb820.jpg" alt="Artistic image of a chicken examining a sequence of papers each labeled with an action ('BLOG', 'SWIM', 'COOK', 'EAT', 'SLEEP', 'HUNT'), each accompanied by a corresponding pile of seeds or grains, representing a decision-making process or prioritization based on the size of the piles." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>The original stochastic chicken making a choice</span><br><span>Chicken and feed generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="temperature--1-eg-05">Temperature &lt; 1 (e.g., 0.5)<a class="hash-link" aria-label="Direct link to Temperature < 1 (e.g., 0.5)" title="Direct link to Temperature < 1 (e.g., 0.5)" href="https://kelk.ai/blog/secret-chickens-tuning#temperature--1-eg-05">​</a></h4>
<p>Lowering the temperature makes the model more confident in its outputs by increasing the gap between the probability of the most likely outcomes and the rest. This makes the chicken's choices less diverse and more deterministic; how could any chicken ignore that <em>huge</em> pile by the word "hunt"? A lower temperature is useful when you want the model to take fewer risks and stick closely to the most likely predictions. This can, however, lead to a lack of variety and potentially more repetitive outputs since, as the temperature approaches <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span>, it approximates greedy decoding (with all the problems <a href="https://kelk.ai/blog/secret-chickens-llm#why-we-need-the-chicken">previously discussed</a>).</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chicken-low-temp-380b110920ae7ce9b3a56880f233c0cd.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chicken-low-temp-380b110920ae7ce9b3a56880f233c0cd.jpg" alt="Image of a chicken seemingly making a choice, pecking at one of the papers labeled with actions such as 'BLOG', 'SWIM', 'COOK', 'EAT', 'SLEEP', 'HUNT', each paired with a pile of seeds, with a caption noting 'Low temperature of 0.5'. The largest of the piles is significantly larger than the smallest of the piles." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Using a lower temperature of 0.5, the differences between the probabilities have increased</span><br><span>Chicken and feed generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="example-of-generating-text-with-low-temperature">Example of generating text with low temperature<a class="hash-link" aria-label="Direct link to Example of generating text with low temperature" title="Direct link to Example of generating text with low temperature" href="https://kelk.ai/blog/secret-chickens-tuning#example-of-generating-text-with-low-temperature">​</a></h4>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Tell me a story about a cat.</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/coldBot.jpg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Once upon a time, in a cozy little house on the edge of town, lived a cat named Whiskers. Whiskers was a fluffy, grey tabby who loved nothing more than lounging in the sunbeams that danced through the living room windows. Each day, Whiskers would embark on a small adventure in the backyard, chasing butterflies and exploring the garden. In the evenings, Whiskers would curl up on the lap of their owner, purring contentedly as they were petted. Life was simple and serene for Whiskers, the beloved cat.</p></div></div></div>
<br>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-is-low-temperature-calculated">How is low temperature calculated?<a class="hash-link" aria-label="Direct link to How is low temperature calculated?" title="Direct link to How is low temperature calculated?" href="https://kelk.ai/blog/secret-chickens-tuning#how-is-low-temperature-calculated">​</a></h4>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Math &amp; Python code (optional technical content)</summary><div><div class="collapsibleContent_i85q"><div><p>Using our original distribution with probabilities of 0.03, 0.05, 0.1, 0.15, 0.2, and 0.25. How would these change if we used a temperature of 0.5?</p><p>Given a distribution of probabilities <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>=</mo><mo stretchy="false">[</mo><mn>0.03</mn><mo separator="true">,</mo><mn>0.05</mn><mo separator="true">,</mo><mn>0.1</mn><mo separator="true">,</mo><mn>0.15</mn><mo separator="true">,</mo><mn>0.2</mn><mo separator="true">,</mo><mn>0.25</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">P = [0.03, 0.05, 0.1, 0.15, 0.2, 0.25]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">0.03</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.05</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.15</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.25</span><span class="mclose">]</span></span></span></span> and a temperature <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">T = 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.5</span></span></span></span>, we adjust the probabilities as follows:</p><ol>
<li>
<p><strong>Compute the logits</strong>: In this context, you can think of logits as the pre-softmax outputs that the model uses to calculate probabilities. However, since we start with probabilities and want to adjust them by temperature, we reverse-engineer logits by taking the natural logarithm of the probabilities. Thus, the logit for each probability <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span> is given by:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>logit</mtext><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{logit}(p_i) = \log(p_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">logit</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>
</li>
<li>
<p><strong>Scale the logits by the temperature</strong>: We then scale these logits by dividing them by the temperature <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span></span>. This step adjusts the distribution of the logits based on the temperature value. For a temperature of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.5</mn></mrow><annotation encoding="application/x-tex">0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.5</span></span></span></span>, the scaling is:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>scaled_logit</mtext><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mi>T</mi></mfrac></mrow><annotation encoding="application/x-tex">\text{scaled\_logit}(p_i) = \frac{\log(p_i)}{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em"></span><span class="mord text"><span class="mord">scaled_logit</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.113em;vertical-align:-0.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
</li>
<li>
<p><strong>Convert the scaled logits back to probabilities</strong>: We use the softmax function to convert the scaled logits back into probabilities. The softmax function is applied to the scaled logits, ensuring that the output probabilities sum to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>. The softmax of a scaled logit <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> is given by:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>softmax</mtext><mo stretchy="false">(</mo><msub><mi>s</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>s</mi><mi>i</mi></msub></msup><mrow><munder><mo>∑</mo><mi>j</mi></munder><msup><mi>e</mi><msub><mi>s</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{softmax}(s_i) = \frac{e^{s_i}}{\sum_j e^{s_j}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.4632em;vertical-align:-1.1218em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3414em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6065em"><span style="top:-3.0051em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1218em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> is the scaled logit for probability <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>, and the denominator is the sum of the exponential of all scaled logits in the distribution. This ensures that the adjusted probabilities sum to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>.</p>
</li>
</ol><p>Putting it all together for each probability <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span> and a temperature <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">T = 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.5</span></span></span></span>, the adjusted probability <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>p</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">p_i'</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0106em;vertical-align:-0.2587em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em"><span></span></span></span></span></span></span></span></span></span> is calculated as:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>p</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><mfrac><msup><mi>e</mi><mfrac><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mn>0.5</mn></mfrac></msup><mrow><munder><mo>∑</mo><mi>j</mi></munder><msup><mi>e</mi><mfrac><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>p</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><mn>0.5</mn></mfrac></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">p_i' = \frac{e^{\frac{\log(p_i)}{0.5}}}{\sum_j e^{\frac{\log(p_j)}{0.5}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0489em;vertical-align:-0.247em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8019em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:3.3292em;vertical-align:-1.5304em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7988em"><span style="top:-2.11em"><span class="pstrut" style="height:3.2046em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.2046em"><span style="top:-3.3486em;margin-right:0.05em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2229em"><span style="top:-2.656em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0.5</span></span></span></span><span style="top:-3.2255em"><span class="pstrut" style="height:3em"></span><span class="frac-line mtight" style="border-bottom-width:0.049em"></span></span><span style="top:-3.6872em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mtight">l</span><span class="mtight">o</span><span class="mtight" style="margin-right:0.01389em">g</span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em"><span class="pstrut" style="height:2.6595em"></span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5092em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.4346em"><span class="pstrut" style="height:3.2046em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.8816em"><span class="pstrut" style="height:3.2046em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1218em"><span style="top:-3.363em;margin-right:0.05em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.084em"><span style="top:-2.656em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0.5</span></span></span></span><span style="top:-3.2255em"><span class="pstrut" style="height:3em"></span><span class="frac-line mtight" style="border-bottom-width:0.049em"></span></span><span style="top:-3.5483em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mtight">l</span><span class="mtight">o</span><span class="mtight" style="margin-right:0.01389em">g</span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em"><span class="pstrut" style="height:2.6595em"></span><span class="mord mathnormal mtight">i</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3147em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5304em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><p>This formula shows how each original probability is transformed under the influence of the temperature. By applying this process to our original probabilities with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">T = 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.5</span></span></span></span>, we enhance the differences between them, making the distribution more "peaky" towards higher probabilities, as seen with the new probabilities approximately becoming 0.007, 0.018, 0.072, 0.163, 0.289, and 0.452.</p><div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Step 1 is likely not necessary in practice, since the model's outputs would likely be logits, and thus transforming probabilities back into logits isn't needed. However, since we started with probabilities for illustrative purposes, we transformed them to logits in the example.</p></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Python code for calculating probabiltities with temperature 0.5</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> numpy </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Original probabilities</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">probabilities </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">array</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0.03</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.05</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.15</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.25</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Temperature</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">temperature </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.5</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Adjusting probabilities with temperature</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adjusted_probabilities </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">exp</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">probabilities</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> temperature</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adjusted_probabilities </span><span class="token operator" style="color:#393A34">/=</span><span class="token plain"> adjusted_probabilities</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">sum</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adjusted_probabilities</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Output</strong></p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">array([0.00650289, 0.01806358, 0.07225434, 0.16257225, 0.28901734,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       0.4515896 ])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></div></details>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="temperature--1-eg-2">Temperature &gt; 1 (e.g., 2)<a class="hash-link" aria-label="Direct link to Temperature > 1 (e.g., 2)" title="Direct link to Temperature > 1 (e.g., 2)" href="https://kelk.ai/blog/secret-chickens-tuning#temperature--1-eg-2">​</a></h4>
<p>Increasing the temperature makes the model's predictions more uniform by reducing the differences between the logits. In the below image, while the highest probability of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.24</mn></mrow><annotation encoding="application/x-tex">0.24</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.24</span></span></span></span> has only been reduced slightly, the lowest probability of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.03</mn></mrow><annotation encoding="application/x-tex">0.03</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.03</span></span></span></span> has tripled to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.09</mn></mrow><annotation encoding="application/x-tex">0.09</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.09</span></span></span></span>. This means <em>all</em> the words in the vocabulary now have a more equal chance of being chosen by the chicken. This leads to higher randomness in the output, allowing for more diverse and sometimes more creative or unexpected predictions; a higher temperature is useful when you want the model to explore less likely options or when generating more varied and interesting content. However, too high a temperature might result in nonsensical or highly unpredictable outputs, because the model will start considering very low probability words that make no refrigerator.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chicken-high-temp-f6f0bec24318e1b664bcd60c798200ca.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chicken-high-temp-f6f0bec24318e1b664bcd60c798200ca.jpg" alt="Image of a chicken considering various actions labeled 'BLOG', 'SWIM', 'COOK', 'EAT', 'SLEEP', 'HUNT', each with a corresponding mound of seeds or grains, with a caption stating 'High temperature of 2' suggesting decision variability. The piles are all more similar in size than with the temperature of 1." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Using a higher temperature of 2, the differences between the highest and lowest probabilities have decreased</span><br><span>Chicken and feed generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="example-of-generating-text-with-high-temperature">Example of generating text with high temperature<a class="hash-link" aria-label="Direct link to Example of generating text with high temperature" title="Direct link to Example of generating text with high temperature" href="https://kelk.ai/blog/secret-chickens-tuning#example-of-generating-text-with-high-temperature">​</a></h4>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Tell me a story about a cat.</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/hotBot.jpg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">In the neon-lit streets of Neo-Tokyo, a cybernetic cat named Z3-R0 roamed, its AI brain whirring with thoughts. Tasked with the mission of uncovering a hidden data drive that could save the city from imminent doom, Z3-R0 leaped from rooftop to rooftop, its metallic tail flickering with electric sparks. Along the way, Z3-R0 encountered a gang of robo-rats plotting their own scheme. Using its laser claws and quick wits, Z3-R0 outmaneuvered the rats, secured the data drive, and raced against the clock to deliver it to the rebel base. In the end, Z3-R0 wasn't just a cat; it was a hero of the digital night.</p></div></div></div>
<br>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-is-high-temperature-calculated">How is high temperature calculated?<a class="hash-link" aria-label="Direct link to How is high temperature calculated?" title="Direct link to How is high temperature calculated?" href="https://kelk.ai/blog/secret-chickens-tuning#how-is-high-temperature-calculated">​</a></h4>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Math &amp; Python code (optional technical content)</summary><div><div class="collapsibleContent_i85q"><div><p>Using our original distribution with probabilities of 0.03, 0.05, 0.1, 0.15, 0.2, and 0.25. How would these change if we used a temperature of 0.5?</p><p>Given a distribution of probabilities <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>=</mo><mo stretchy="false">[</mo><mn>0.03</mn><mo separator="true">,</mo><mn>0.05</mn><mo separator="true">,</mo><mn>0.1</mn><mo separator="true">,</mo><mn>0.15</mn><mo separator="true">,</mo><mn>0.2</mn><mo separator="true">,</mo><mn>0.25</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">P = [0.03, 0.05, 0.1, 0.15, 0.2, 0.25]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">0.03</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.05</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.15</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.25</span><span class="mclose">]</span></span></span></span> and a temperature <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">T = 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2</span></span></span></span>, we adjust the probabilities as follows:</p><ol>
<li>
<p><strong>Compute the logits</strong>: In this context, you can think of logits as the pre-softmax outputs that the model uses to calculate probabilities. However, since we start with probabilities and want to adjust them by temperature, we reverse-engineer logits by taking the natural logarithm of the probabilities. Thus, the logit for each probability <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span> is given by:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>logit</mtext><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{logit}(p_i) = \log(p_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">logit</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>
</li>
<li>
<p><strong>Scale the logits by the temperature</strong>: We then scale these logits by dividing them by the temperature <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span></span>. This step adjusts the distribution of the logits based on the temperature value. For a temperature of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2</span></span></span></span>, the scaling is:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>scaled_logit</mtext><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mi>T</mi></mfrac></mrow><annotation encoding="application/x-tex">\text{scaled\_logit}(p_i) = \frac{\log(p_i)}{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em"></span><span class="mord text"><span class="mord">scaled_logit</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.113em;vertical-align:-0.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
</li>
<li>
<p><strong>Convert the scaled logits back to probabilities</strong>: We use the softmax function to convert the scaled logits back into probabilities. The softmax function is applied to the scaled logits, ensuring that the output probabilities sum to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>. The softmax of a scaled logit <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> is given by:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>softmax</mtext><mo stretchy="false">(</mo><msub><mi>s</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>s</mi><mi>i</mi></msub></msup><mrow><munder><mo>∑</mo><mi>j</mi></munder><msup><mi>e</mi><msub><mi>s</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{softmax}(s_i) = \frac{e^{s_i}}{\sum_j e^{s_j}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.4632em;vertical-align:-1.1218em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3414em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6065em"><span style="top:-3.0051em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1218em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> is the scaled logit for probability <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>, and the denominator is the sum of the exponential of all scaled logits in the distribution. This ensures that the adjusted probabilities sum to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>.</p>
</li>
</ol><p>Putting it all together for each probability <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span> and a temperature <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">T = 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2</span></span></span></span>, the adjusted probability <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>p</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">p_i'</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0106em;vertical-align:-0.2587em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em"><span></span></span></span></span></span></span></span></span></span> is calculated as:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>p</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><mfrac><msup><mi>e</mi><mfrac><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mn>2</mn></mfrac></msup><mrow><munder><mo>∑</mo><mi>j</mi></munder><msup><mi>e</mi><mfrac><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>p</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><mn>2</mn></mfrac></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">p_i' = \frac{e^{\frac{\log(p_i)}{2}}}{\sum_j e^{\frac{\log(p_j)}{2}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0489em;vertical-align:-0.247em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8019em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:3.3292em;vertical-align:-1.5304em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7988em"><span style="top:-2.11em"><span class="pstrut" style="height:3.2046em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.2046em"><span style="top:-3.3486em;margin-right:0.05em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2229em"><span style="top:-2.656em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255em"><span class="pstrut" style="height:3em"></span><span class="frac-line mtight" style="border-bottom-width:0.049em"></span></span><span style="top:-3.6872em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mtight">l</span><span class="mtight">o</span><span class="mtight" style="margin-right:0.01389em">g</span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em"><span class="pstrut" style="height:2.6595em"></span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5092em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.4346em"><span class="pstrut" style="height:3.2046em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.8816em"><span class="pstrut" style="height:3.2046em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1218em"><span style="top:-3.363em;margin-right:0.05em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.084em"><span style="top:-2.656em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255em"><span class="pstrut" style="height:3em"></span><span class="frac-line mtight" style="border-bottom-width:0.049em"></span></span><span style="top:-3.5483em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mtight">l</span><span class="mtight">o</span><span class="mtight" style="margin-right:0.01389em">g</span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em"><span class="pstrut" style="height:2.6595em"></span><span class="mord mathnormal mtight">i</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3147em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5304em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><p>This formula demonstrates how we adjust each probability with the temperature. Applying this method to our original set of probabilities with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">T = 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2</span></span></span></span> results in a flatter distribution. The differences between probabilities are reduced, making the distribution more uniform and reducing the variance in outcomes, as seen with the new probabilities approximately becoming 0.085, 0.109, 0.154, 0.189, 0.218, and 0.244.</p><div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Step 1 is likely not necessary in practice, since the model's outputs would likely be logits, and thus transforming probabilities back into logits isn't needed. However, since we started with probabilities for illustrative purposes, we transformed them to logits in the example.</p></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Python code for calculating probabilities with temperature 2</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> numpy </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Original probabilities</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">probabilities </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">array</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0.03</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.05</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.15</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.25</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Temperature</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">temperature </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Adjusting probabilities with temperature</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adjusted_probabilities </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">exp</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">probabilities</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> temperature</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adjusted_probabilities </span><span class="token operator" style="color:#393A34">/=</span><span class="token plain"> adjusted_probabilities</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">sum</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">adjusted_probabilities</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Output</strong></p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">array([0.08459132, 0.10920692, 0.15444191, 0.18915193, 0.21841384,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       0.24419409])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></div></details>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="practical-application">Practical Application<a class="hash-link" aria-label="Direct link to Practical Application" title="Direct link to Practical Application" href="https://kelk.ai/blog/secret-chickens-tuning#practical-application">​</a></h4>
<p>Adjusting the temperature allows users of language models to balance between predictability and diversity in the generated text. For instance, in creative writing or brainstorming tools, a slightly higher temperature might be preferred to inspire novel ideas or suggestions. Conversely, for applications requiring high accuracy and relevance, such as summarization or technical writing, a lower temperature might be more appropriate.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>If you've used OpenAI's API, you might note that they use a temperature parameter ranging from 0 to 1, which is inconsistent with conventional temperature in language models. It's likely that they're mapping this 0 to 1 range to a broader, internally defined temperature scale while managing the complexity of a temperature-based chicken in the background.</p></div></div>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="top-k">Top-k<a class="hash-link" aria-label="Direct link to Top-k" title="Direct link to Top-k" href="https://kelk.ai/blog/secret-chickens-tuning#top-k">​</a></h3>
<p>Another method of "tuning the chicken" is called top-k sampling. The "k" in top-k stands for a specific number that restricts the selection pool to the top "k" most likely next words according to the model's predictions. Again, the primary goal of top-k sampling is to strike a balance between randomness and determinism in text generation.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-top-k-works">How top-k works<a class="hash-link" aria-label="Direct link to How top-k works" title="Direct link to How top-k works" href="https://kelk.ai/blog/secret-chickens-tuning#how-top-k-works">​</a></h4>
<ol>
<li><strong>Prediction</strong>: At each step in the text generation process, the model predicts a probability distribution over the entire vocabulary for the next word, based on the context of the words generated so far.</li>
<li><strong>Selection of Top-k Words</strong>: From this distribution, only the top "k" words with the highest probabilities are considered for selection. This subset represents the most likely next word according to the model.</li>
</ol>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chicken-top-k-e531dc254ea54a568d9c353d54829099.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chicken-top-k-e531dc254ea54a568d9c353d54829099.jpg" alt="Image of a chicken looking at papers labeled 'BLOG', 'SWIM', 'COOK', 'EAT', 'SLEEP', 'HUNT', with seed piles, while a giant pencil erases the two smallest, captioned 'Top-k sampling, with k = 4', implying a selection process." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>With a top-k of 4, we need to remove all words other than the top 4 options.</span><br><span>Chicken and feed generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<ol start="3">
<li><strong>Renormalization</strong>: The probabilities of these top "k" words are then renormalized so that they sum up to 1. This step ensures that one of these words can be selected based on their relative probabilities within this restricted set. Note that the 4 piles still being considered have grown in size.</li>
</ol>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chicken-top-k-renorm-36490445e1627df03bd73ee03b77b4e8.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chicken-top-k-renorm-36490445e1627df03bd73ee03b77b4e8.jpg" alt="Artistic image of a chicken looking at papers labeled 'BLOG', 'SWIM', 'COOK', 'EAT', 'SLEEP', 'HUNT', with the probabilities crossed out by a red pencil and new values written in. The caption says 'Top-k sampling, with k = 4 Renormalized', indicating a process of elimination and reevaluation." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>We now renormalize so that the probabilities add up to 1</span><br><span>Chicken and feed generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<ol start="4">
<li><strong>Sampling</strong>: The chicken finally chooses the following word from this renormalized subset of top "k" words. This introduces variability in the generation process, allowing for diverse and potentially more creative outputs.</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="before-and-after-top-k-with-k4">Before and after top-k with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>k</mi><mo>=</mo><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(k=4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">4</span><span class="mclose">)</span></span></span></span><a class="hash-link" aria-label="Direct link to before-and-after-top-k-with-k4" title="Direct link to before-and-after-top-k-with-k4" href="https://kelk.ai/blog/secret-chickens-tuning#before-and-after-top-k-with-k4">​</a></h4>
<table><thead><tr><th>Activity</th><th>blog</th><th>meditate</th><th>cook</th><th>eat</th><th>sleep</th><th>hunt</th></tr></thead><tbody><tr><td>Original Probability</td><td>0.03</td><td>0.05</td><td>0.1</td><td>0.15</td><td>0.2</td><td>0.25</td></tr><tr><td>Top-k <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>k</mi><mo>=</mo><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(k=4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">4</span><span class="mclose">)</span></span></span></span> Probability</td><td>0.00</td><td>0.00</td><td>0.14</td><td>0.21</td><td>0.29</td><td>0.36</td></tr></tbody></table>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Remember, this is a heavily simplified example. In reality, the original values would contain <em>many</em> more probabilities, <strong>50,257</strong> in the case of GPT-3. Top-k with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">k=4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">4</span></span></span></span> would have a large impact on the chicken.</p></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-is-top-k-calculated">How is top-k calculated?<a class="hash-link" aria-label="Direct link to How is top-k calculated?" title="Direct link to How is top-k calculated?" href="https://kelk.ai/blog/secret-chickens-tuning#how-is-top-k-calculated">​</a></h4>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Math &amp; Python code (optional technical content)</summary><div><div class="collapsibleContent_i85q"><div><p>Here's how to compute top-k sampling with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">k = 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">4</span></span></span></span> on the set of probabilities</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo>=</mo><mo stretchy="false">[</mo><mn>0.03</mn><mo separator="true">,</mo><mn>0.05</mn><mo separator="true">,</mo><mn>0.1</mn><mo separator="true">,</mo><mn>0.15</mn><mo separator="true">,</mo><mn>0.2</mn><mo separator="true">,</mo><mn>0.25</mn><mo stretchy="false">]</mo><mtext>&nbsp;with&nbsp;</mtext><mi>k</mi><mo>=</mo><mn>4</mn><mo>:</mo></mrow><annotation encoding="application/x-tex">P = [0.03, 0.05, 0.1, 0.15, 0.2, 0.25] \text{ with } k = 4:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">0.03</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.05</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.15</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.25</span><span class="mclose">]</span><span class="mord text"><span class="mord">&nbsp;with&nbsp;</span></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">:</span></span></span></span></span><ol>
<li>
<p><strong>Sort the probabilities in descending order</strong>: This step isn't necessary for this example, since the probabilities are already sorted, but it's necessary to ensure that we can select the top 4 probabilities.</p>
</li>
<li>
<p><strong>Select the top <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span> probabilities</strong>: We choose the four highest probabilities from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>. Given our <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>, the top 4 probabilities are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.25</mn></mrow><annotation encoding="application/x-tex">0.25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.25</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.2</mn></mrow><annotation encoding="application/x-tex">0.2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.2</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.15</mn></mrow><annotation encoding="application/x-tex">0.15</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.15</span></span></span></span>, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.1</mn></mrow><annotation encoding="application/x-tex">0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.1</span></span></span></span>.</p>
</li>
<li>
<p><strong>Renormalize the selected probabilities</strong>: To ensure that these top <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span> probabilities sum to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>, we renormalize them. The renormalized probability for each selected outcome <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> is calculated as:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>p</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><mfrac><msub><mi>p</mi><mi>i</mi></msub><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></msubsup><msub><mi>p</mi><mi>j</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">p_i' = \frac{p_i}{\sum_{j=1}^{k} p_j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0106em;vertical-align:-0.2587em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.5049em;vertical-align:-0.7574em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em"><span style="top:-2.5648em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8932em"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-2.8971em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4603em"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em"></span><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.4461em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7574em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></msubsup><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\sum_{j=1}^{k} p_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4248em;vertical-align:-0.4358em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.989em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span> is the sum of the top <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span> probabilities, ensuring they sum to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>.</p>
</li>
<li>
<p><strong>Sampling</strong>: Finally, we let the chicken choose randomly from these top <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span> adjusted probabilities.</p>
</li>
</ol><p>For our given probabilities and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">k = 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">4</span></span></span></span>, the top 4 probabilities are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.1</mn></mrow><annotation encoding="application/x-tex">0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.1</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.15</mn></mrow><annotation encoding="application/x-tex">0.15</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.15</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.2</mn></mrow><annotation encoding="application/x-tex">0.2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.2</span></span></span></span>, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.25</mn></mrow><annotation encoding="application/x-tex">0.25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.25</span></span></span></span>, which sum to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.7</mn></mrow><annotation encoding="application/x-tex">0.7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.7</span></span></span></span>. Renormalizing gives us:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>p</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><mfrac><msub><mi>p</mi><mi>i</mi></msub><mn>0.7</mn></mfrac></mrow><annotation encoding="application/x-tex">p_i' = \frac{p_i}{0.7}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0489em;vertical-align:-0.247em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8019em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.7936em;vertical-align:-0.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">0.7</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><p>for each of the top 4 probabilities. This focuses the sampling on the most likely outcomes and leaves out the least likely ones. This guides the generation toward more likely (and maybe even more logical) continuations while still allowing for some randomness and variation. We get the new renormalized top-4 probabilities of 0.14, 0.21, 0.29, and 0.36, which add up to 1.0.</p><div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Step 1 is likely not necessary in practice, since the model's outputs would likely be logits, and thus transforming probabilities back into logits isn't needed. However, since we started with probabilities for illustrative purposes, we transformed them to logits in the example.</p></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Python code for calculating probabilities top-k with k = 4</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> numpy </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Original probabilities</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">probabilities </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">array</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0.03</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.05</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.15</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.25</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Setting k = 4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">k </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Step 1: Select the top-k probabilities</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">top_k_probabilities </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sort</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">probabilities</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">[</span><span class="token operator" style="color:#393A34">-</span><span class="token plain">k</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Step 2: Renormalize the selected probabilities so they sum to 1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">renormalized_top_k_probs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> top_k_probabilities </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> top_k_probabilities</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">sum</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"Top-k Probabilities:"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> top_k_probabilities</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"Renormalized Top-k:"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> renormalized_top_k_probs</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Output</strong></p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Top-k Probabilities: [0.1  0.15 0.2  0.25]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Renormalized Top-k: [0.14285714 0.21428571 0.28571429 0.35714286]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></div></details>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="practical-application-1">Practical Application<a class="hash-link" aria-label="Direct link to Practical Application" title="Direct link to Practical Application" href="https://kelk.ai/blog/secret-chickens-tuning#practical-application-1">​</a></h4>
<p>Adjusting the value of "k" allows for tuning the balance between randomness and determinism. A small top-k value restricts the model to choose the next word from a smaller set of the most probable words, leading to more predictable and safer outputs. A large top-k value allows for a wider selection of words, increasing the potential for creativity and unpredictability in the text.</p>
<p>Let's look at two examples of how top-k might affect text generation.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="small-top-k-eg-5-this-setting-forces-the-model-to-pick-from-a-narrower-set-of-options-likely-leading-to-a-more-conventional-and-expected-description">Small top-k (e.g., 5): This setting forces the model to pick from a narrower set of options, likely leading to a more conventional and expected description:<a class="hash-link" aria-label="Direct link to Small top-k (e.g., 5): This setting forces the model to pick from a narrower set of options, likely leading to a more conventional and expected description:" title="Direct link to Small top-k (e.g., 5): This setting forces the model to pick from a narrower set of options, likely leading to a more conventional and expected description:" href="https://kelk.ai/blog/secret-chickens-tuning#small-top-k-eg-5-this-setting-forces-the-model-to-pick-from-a-narrower-set-of-options-likely-leading-to-a-more-conventional-and-expected-description">​</a></h4>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Write a futuristic description of a city.</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">The city of tomorrow gleams under the starlit sky, its skyscrapers adorned with glowing neon lights. Solar panels cover every rooftop, harnessing the power of the sun to fuel the bustling metropolis below. Hovercars zip through the air, following invisible lanes that weave between the buildings. People walk along clean, green sidewalks, their steps powered by energy-generating tiles. This is a place of harmony, where technology and nature coexist in a sustainable balance, creating a utopia for all who dwell within.</p></div></div></div>
<br>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="large-top-k-eg-50-with-this-setting-the-model-has-a-wider-array-of-words-to-choose-from-for-each-step-potentially-leading-to-a-more-unique-or-unconventional-description">Large top-k (e.g., 50): With this setting, the model has a wider array of words to choose from for each step, potentially leading to a more unique or unconventional description:<a class="hash-link" aria-label="Direct link to Large top-k (e.g., 50): With this setting, the model has a wider array of words to choose from for each step, potentially leading to a more unique or unconventional description:" title="Direct link to Large top-k (e.g., 50): With this setting, the model has a wider array of words to choose from for each step, potentially leading to a more unique or unconventional description:" href="https://kelk.ai/blog/secret-chickens-tuning#large-top-k-eg-50-with-this-setting-the-model-has-a-wider-array-of-words-to-choose-from-for-each-step-potentially-leading-to-a-more-unique-or-unconventional-description">​</a></h4>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Write a futuristic description of a city.</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">In the heart of the neon jungle, the city thrives, a labyrinth of crystalline towers and levitating gardens. Quantum bridges arc over the meandering rivers of pure light, connecting floating districts that defy gravity with their whimsical architecture. Holographic fauna roam the parks, blending with the urban dwellers who don their digital skins as easily as clothes. Here, the air vibrates with the hum of anti-gravitational engines, and the night sky is a canvas for the aurora technicolor, a testament to the city's fusion of art and science. Cybernetic street performers and AI poets share tales of other dimensions, inviting onlookers to imagine worlds beyond their wildest dreams.</p></div></div></div>
<br>
<p>As you can see, a smaller top-k tends to produce more grounded and straightforward descriptions, while a larger top-k opens the door to more inventive and sometimes surreal narratives.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>Top-k with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span> is equivalent to greedy decoding.</p></div></div>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="top-p-nucleus-sampling">Top-p (nucleus sampling)<a class="hash-link" aria-label="Direct link to Top-p (nucleus sampling)" title="Direct link to Top-p (nucleus sampling)" href="https://kelk.ai/blog/secret-chickens-tuning#top-p-nucleus-sampling">​</a></h3>
<p>Top-p sampling, also known as nucleus sampling, offers an alternative to top-k sampling and aims to dynamically select the number of words to consider for the next word in a sequence, based on a cumulative probability threshold <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span></span></span></span>. This method allows for more flexibility and adaptability in text generation, as it doesn't fix the number of tokens to sample from, but rather adjusts this number based on the distribution of probabilities at each step. The term "nucleus sampling" comes from the method's approach to focusing on a "nucleus" of probable words at each step in the generation process.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-top-p-sampling-works">How top-p sampling works<a class="hash-link" aria-label="Direct link to How top-p sampling works" title="Direct link to How top-p sampling works" href="https://kelk.ai/blog/secret-chickens-tuning#how-top-p-sampling-works">​</a></h4>
<ol>
<li>
<p><strong>Probability Distribution</strong>: Given a probability distribution for the next word predicted by a language model, sort the probabilities in descending order.</p>
</li>
<li>
<p><strong>Cumulative Probability</strong>: Calculate the cumulative sum of these sorted probabilities.</p>
</li>
<li>
<p><strong>Thresholding</strong>: Select the smallest set of words whose cumulative probability exceeds the threshold <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span></span></span></span>. This threshold <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span></span></span></span> is a hyperparameter, typically set between 0.9 and 1.0, which determines how much of the probability mass to include in the sampling pool. In our example, since we're only showing the top 6 words, I'm using <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">p=0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.75</span></span></span></span> to eliminate only the smallest probability.</p>
</li>
</ol>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chicken-top-p-c719a8b130bb9cd427d750f98cdbf88a.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chicken-top-p-c719a8b130bb9cd427d750f98cdbf88a.jpg" alt="Artistic depiction of a chicken choosing from options labeled 'BLOG', 'SWIM', 'COOK', 'EAT', 'SLEEP', 'HUNT', with a human hand erasing an option, and the caption 'Top-p sampling, with p = 0.75' indicating a selective decision process." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>With a top-p of 0.75, we need to remove all words other than the top 5 options.</span><br><span>Chicken and feed generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<ol start="4">
<li><strong>Renormalize</strong>: The selected probabilities are then renormalized to sum to 1.</li>
</ol>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chicken-top-p-renorm-880ead232fb3164cd470a8e79b168f64.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chicken-top-p-renorm-880ead232fb3164cd470a8e79b168f64.jpg" alt="Artistic rendering of a chicken facing papers labeled 'BLOG', 'SWIM', 'COOK', 'EAT', 'SLEEP', 'HUNT', with the probabilities crossed out by a red pencil and new values written in. The caption notation says 'Top-p sampling, with p = 0.75 Renormalized' to represent recalibrated decision-making." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>With a top-p of 0.75, we need to remove all words other than the top 5 options.</span><br><span>Chicken and feed generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<ol start="5">
<li><strong>Sampling</strong>: Finally, the chicken chooses the next word from this renormalized subset.</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="before-and-after-top-p-with-p075">Before and after top-p with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>p</mi><mo>=</mo><mn>0.75</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(p=0.75)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">0.75</span><span class="mclose">)</span></span></span></span><a class="hash-link" aria-label="Direct link to before-and-after-top-p-with-p075" title="Direct link to before-and-after-top-p-with-p075" href="https://kelk.ai/blog/secret-chickens-tuning#before-and-after-top-p-with-p075">​</a></h4>
<table><thead><tr><th>Activity</th><th>blog</th><th>meditate</th><th>cook</th><th>eat</th><th>sleep</th><th>hunt</th></tr></thead><tbody><tr><td>Original Probability</td><td>0.03</td><td>0.05</td><td>0.1</td><td>0.15</td><td>0.2</td><td>0.25</td></tr><tr><td>Top-p <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>p</mi><mo>=</mo><mn>0.75</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(p=0.75)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">0.75</span><span class="mclose">)</span></span></span></span> Probability</td><td>0.00</td><td>0.07</td><td>0.13</td><td>0.20</td><td>0.27</td><td>0.33</td></tr></tbody></table>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>As with top-k, remember that this is a heavily simplified example. In reality, the original values would contain <em>many</em> more probabilities, <strong>50,257</strong> in the case of GPT-3. Top-p with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">p=0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.75</span></span></span></span> would have a large impact on the chicken.</p></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-is-top-p-calculated">How is top-p calculated?<a class="hash-link" aria-label="Direct link to How is top-p calculated?" title="Direct link to How is top-p calculated?" href="https://kelk.ai/blog/secret-chickens-tuning#how-is-top-p-calculated">​</a></h4>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Math &amp; Python code (optional technical content)</summary><div><div class="collapsibleContent_i85q"><div><p>Using top-p (nucleus) sampling with a cumulative probability threshold of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">p = 0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.75</span></span></span></span> on the set of probabilities</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo>=</mo><mo stretchy="false">[</mo><mn>0.03</mn><mo separator="true">,</mo><mn>0.05</mn><mo separator="true">,</mo><mn>0.1</mn><mo separator="true">,</mo><mn>0.15</mn><mo separator="true">,</mo><mn>0.2</mn><mo separator="true">,</mo><mn>0.25</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">P = [0.03, 0.05, 0.1, 0.15, 0.2, 0.25]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">0.03</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.05</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.15</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.25</span><span class="mclose">]</span></span></span></span></span><p>involves selecting the smallest set of the most probable outcomes whose cumulative probability exceeds the threshold.</p><ol>
<li>
<p><strong>Sort Probabilities</strong>: First, sort the probabilities in descending order to prioritize higher probabilities. For <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>, when sorted, we have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0.25</mn><mo separator="true">,</mo><mn>0.2</mn><mo separator="true">,</mo><mn>0.15</mn><mo separator="true">,</mo><mn>0.1</mn><mo separator="true">,</mo><mn>0.05</mn><mo separator="true">,</mo><mn>0.03</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0.25, 0.2, 0.15, 0.1, 0.05, 0.03]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">0.25</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.15</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.05</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.03</span><span class="mclose">]</span></span></span></span>.</p>
</li>
<li>
<p><strong>Cumulative Sum</strong>: Calculate the cumulative sum of these sorted probabilities. The cumulative sums of the sorted <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span> are approximately <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0.25</mn><mo separator="true">,</mo><mn>0.45</mn><mo separator="true">,</mo><mn>0.6</mn><mo separator="true">,</mo><mn>0.7</mn><mo separator="true">,</mo><mn>0.75</mn><mo separator="true">,</mo><mn>0.78</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0.25, 0.45, 0.6, 0.7, 0.75, 0.78]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">0.25</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.45</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.6</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.7</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.75</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.78</span><span class="mclose">]</span></span></span></span>.</p>
</li>
<li>
<p><strong>Apply the Threshold <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">p = 0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.75</span></span></span></span></strong>: Identify the smallest set of probabilities whose cumulative sum exceeds <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.75</mn></mrow><annotation encoding="application/x-tex">0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.75</span></span></span></span>. In our case, when we reach <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.05</mn></mrow><annotation encoding="application/x-tex">0.05</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.05</span></span></span></span> in the sorted list (cumulative sum <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">= 0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.75</span></span></span></span>), we've exceeded the threshold <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span></span></span></span>.</p>
</li>
<li>
<p><strong>Selected Subset</strong>: Based on the threshold, we select the probabilities <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0.25</mn><mo separator="true">,</mo><mn>0.2</mn><mo separator="true">,</mo><mn>0.15</mn><mo separator="true">,</mo><mn>0.1</mn><mo separator="true">,</mo><mn>0.05</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0.25, 0.2, 0.15, 0.1, 0.05]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">0.25</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.15</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">0.05</span><span class="mclose">]</span></span></span></span>. Notice that the cumulative probability of these selected probabilities is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.75</mn></mrow><annotation encoding="application/x-tex">0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.75</span></span></span></span>, which meets our threshold condition.</p>
</li>
<li>
<p><strong>Renormalize Probabilities</strong>: The selected probabilities are then renormalized so they sum up to 1, to be used for sampling. The renormalization is calculated as follows:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>p</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><mfrac><msub><mi>p</mi><mi>i</mi></msub><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>p</mi><mi>j</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">p_i' = \frac{p_i}{\sum_{j=1}^{n} p_j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0489em;vertical-align:-0.247em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8019em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.2377em;vertical-align:-1.1301em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em"><span style="top:-2.3057em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1301em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p>where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>p</mi><mi>j</mi></msub><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">\sum_{j=1}^{n} p_j = 0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2401em;vertical-align:-0.4358em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.75</span></span></span></span> for the selected probabilities, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> represents each selected probability.</p>
</li>
<li>
<p><strong>Sampling</strong>: Finally, let the chicken choose the next word from this renormalized subset according to the adjusted probabilities.</p>
</li>
</ol><h4 class="anchor anchorWithStickyNavbar_LWe7" id="description">Description<a class="hash-link" aria-label="Direct link to Description" title="Direct link to Description" href="https://kelk.ai/blog/secret-chickens-tuning#description">​</a></h4><p>In top-p sampling with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">p = 0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.75</span></span></span></span>, we dynamically adjust the size of the set from which we sample based on the cumulative probability threshold. Unlike a fixed-size set in top-k sampling, the size of the set in top-p sampling can vary depending on the distribution of the probabilities. In this example, by setting <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">p = 0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.75</span></span></span></span>, we focus on a subset of outcomes that collectively represent the most probable <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>75</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">75\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em"></span><span class="mord">75%</span></span></span></span> of the distribution. This method means that we're sampling from outcomes that are collectively likely while still allowing for variability and surprise in the generated sequence.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Python code for calculating probabilities top-p with p = 0.75</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> numpy </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Original probabilities</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">probabilities </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">array</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0.03</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.05</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.15</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.25</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Setting the cumulative probability threshold for top-p sampling</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">p </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.75</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Sort the probabilities in descending order</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sorted_probabilities </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sort</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">probabilities</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">:</span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Calculate the cumulative sum of the sorted probabilities</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cumulative_sums </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cumsum</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sorted_probabilities</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Find the index where the cumulative sum just exceeds or meets p=0.75,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># and select up to that index. This ensures we include probabilities </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># up to the point where the cumulative sum is closest to 0.75</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">top_p_cutoff_index </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">where</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">cumulative_sums </span><span class="token operator" style="color:#393A34">&gt;=</span><span class="token plain"> p</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Select the probabilities up to the cutoff index</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">top_p_probabilities </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> sorted_probabilities</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">top_p_cutoff_index</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Renormalize the selected probabilities so they sum to 1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">renormalized_top_p_probs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> top_p_probabilities </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">sum</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">top_p_probabilities</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"Top-p Probabilities:"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> top_p_probabilities</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"Renormalized Top-p:"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> renormalized_top_p_probs</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Output</strong></p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Top-p Probabilities: [0.25 0.2  0.15 0.1  0.05]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Renormalized Top-p: [0.33333333 0.26666667 0.2 0.13333333 0.06666667]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></div></details>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="practical-application-2">Practical Application<a class="hash-link" aria-label="Direct link to Practical Application" title="Direct link to Practical Application" href="https://kelk.ai/blog/secret-chickens-tuning#practical-application-2">​</a></h4>
<p>Unlike top-k sampling, which selects a fixed number of tokens <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span>, top-p sampling dynamically adjusts the number of tokens based on their probability distribution. Top-p sampling is effective in excluding the long tail of low-probability words without arbitrarily limiting the choice to a fixed number of top probabilities. This can prevent the inclusion of very unlikely words while still allowing for a rich variety of output.</p>
<p>As we did before, let's look at two examples of how top-p might affect text generation.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="small-top-p-eg-05-this-setting-will-likely-produce-a-more-straightforward-and-possibly-familiar-narrative">Small top-p (e.g., 0.5): This setting will likely produce a more straightforward and possibly familiar narrative:<a class="hash-link" aria-label="Direct link to Small top-p (e.g., 0.5): This setting will likely produce a more straightforward and possibly familiar narrative:" title="Direct link to Small top-p (e.g., 0.5): This setting will likely produce a more straightforward and possibly familiar narrative:" href="https://kelk.ai/blog/secret-chickens-tuning#small-top-p-eg-05-this-setting-will-likely-produce-a-more-straightforward-and-possibly-familiar-narrative">​</a></h4>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Imagine a world where plants can communicate with humans.</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">In a world where plants can communicate with humans, gardens and forests become places of deep conversation and learning. Trees share ancient wisdom about the planet's history, while flowers whisper secrets about the medicinal properties of their kin. Humans, in turn, learn to listen to the subtle languages of leaves and roots, developing a symbiotic relationship with the plant kingdom. This newfound communication leads to a harmonious existence, where environmental destruction is halted, and humans work alongside plants to restore the Earth's ecosystems. The air is cleaner, the forests are fuller, and the earth thrives as plants and humans share a mutual understanding and respect.</p></div></div></div>
<br>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="large-top-p-eg-09-this-setting-allows-for-broader-and-potentially-more-imaginative-exploration">Large top-p (e.g., 0.9): This setting allows for broader and potentially more imaginative exploration:<a class="hash-link" aria-label="Direct link to Large top-p (e.g., 0.9): This setting allows for broader and potentially more imaginative exploration:" title="Direct link to Large top-p (e.g., 0.9): This setting allows for broader and potentially more imaginative exploration:" href="https://kelk.ai/blog/secret-chickens-tuning#large-top-p-eg-09-this-setting-allows-for-broader-and-potentially-more-imaginative-exploration">​</a></h4>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Imagine a world where plants can communicate with humans.</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">In this verdant world, plants do not merely communicate; they are eloquent orators, poets, and philosophers, engaging in intricate dialogues with humans. Through a symphony of scents, colors, and vibrations, they convey not just thoughts, but emotions and artistic expressions. Urban landscapes are transformed into interactive ecosystems where each street corner reveals a new botanical narrative. Walking through parks becomes an immersive experience, as trees recount tales of ecological battles and victories, and flowers critique the quality of urban air with sarcastic wit. Innovative technologies emerge to translate photosynthesis-driven pulses into music, turning forests into concert halls and making agriculture an act of cultural exchange. In this world, plants educate humans about sustainability and creativity, fundamentally altering the fabric of society and fostering an era of unprecedented environmental empathy and artistic flourishing.</p></div></div></div>
<br>
<p>These examples show how adjusting the top-p value can influence the directness, creativity, and scope of the generated content.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>Top-p with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">p=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span> is equivalent to the chicken choosing from all words in the vocabulary.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="even-with-top-k-theres-still-no-way-to-definitively-prove-that-a-given-text-was-generated">Even with top-k, there's still no way to definitively prove that a given text was generated<a class="hash-link" aria-label="Direct link to Even with top-k, there's still no way to definitively prove that a given text was generated" title="Direct link to Even with top-k, there's still no way to definitively prove that a given text was generated" href="https://kelk.ai/blog/secret-chickens-tuning#even-with-top-k-theres-still-no-way-to-definitively-prove-that-a-given-text-was-generated">​</a></h2>
<p>Previously we found that the number of different texts that an LLM can generate is <a href="https://kelk.ai/blog/secret-chickens-llm#theres-probably-no-way-to-definitively-prove-that-a-given-text-was-generated">so large that it might as well be infinite.</a> The number we found in that section, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>9</mn></msup><mn>402</mn></mrow><annotation encoding="application/x-tex">10^9402</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">9</span></span></span></span></span></span></span></span><span class="mord">402</span></span></span></span>, is too large to be useful, so perhaps limiting the vocabulary with top-k or top-p we might make it more reasonable.</p>
<p>First we calculate a more realistic estimate of the number of possible combinations with top-k where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>40</mn></mrow><annotation encoding="application/x-tex">k=40</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">40</span></span></span></span>. We'll use top-k only, since temperature doesn't affect the number of considered tokens, and top-p depends on the probabilities predicted.</p>
<p>We can make some assumptions for a simplified calculation:</p>
<ol>
<li><strong>Vocabulary Size</strong>: 50,257 tokens.</li>
<li><strong>Sequence Length</strong>: 2,000 tokens.</li>
<li><strong>Sampling Technique</strong>: top-k with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>40</mn></mrow><annotation encoding="application/x-tex">k=40</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">40</span></span></span></span></li>
</ol>
<p>Using top-k sampling with an average of 40 choices per token, the logarithm (base 10) of the number of possible combinations for a sequence of 2,000 tokens is approximately <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3204</mn></mrow><annotation encoding="application/x-tex">3204</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3204</span></span></span></span>. This means the total number of combinations is roughly <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>3204</mn></msup></mrow><annotation encoding="application/x-tex">10^{3204}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3204</span></span></span></span></span></span></span></span></span></span></span></span>.</p>
<p>This number, while still incredibly large, is significantly smaller than the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>9402</mn></msup></mrow><annotation encoding="application/x-tex">10^{9402}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">9402</span></span></span></span></span></span></span></span></span></span></span></span> we calculated for the full vocabulary without sampling constraints. It shows the reduction in combinatorial complexity due to the smaller choice of tokens with top-k. The difference between this and the unrestricted vocabulary scenario shows the impact of these sampling techniques in making text generation more manageable, and less prone to extreme outliers.</p>
<p>However, it's still such a stupidly large number that it might as well be infinite. The chances of generating 2,000 tokens that have been generated before in the same order are effectively zero. Thus, it isn't possible to show that a generated text was copied from another, and therefore it is impossible to prove plagiarism without a shadow of doubt.</p>
<p>Are there other methods of recognizing generated text? Yes, absolutely, using ways such as the frequency of uncommon words (GPT-4 really loves to say "delve") but that goes beyond the scope of this article.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-is-the-size-of-the-combinatorial-space-using-top-k-calculated">How is the size of the combinatorial space using top-k calculated?<a class="hash-link" aria-label="Direct link to How is the size of the combinatorial space using top-k calculated?" title="Direct link to How is the size of the combinatorial space using top-k calculated?" href="https://kelk.ai/blog/secret-chickens-tuning#how-is-the-size-of-the-combinatorial-space-using-top-k-calculated">​</a></h4>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Math &amp; Python code (optional technical content)</summary><div><div class="collapsibleContent_i85q"><div><p>Given a sequence length <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span></span></span></span> and a fixed number of choices per token <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span></span></span></span> in a top-k sampling method, the total number of possible combinations can be estimated. For a top-k of 40 choices per token and a sequence length of 2,000 tokens, the calculation is as follows:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Total&nbsp;Combinations</mtext><mo>=</mo><msup><mi>K</mi><mi>N</mi></msup><mo>=</mo><mn>4</mn><msup><mn>0</mn><mn>2000</mn></msup></mrow><annotation encoding="application/x-tex">\text{Total Combinations} = K^N = 40^{2000}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text"><span class="mord">Total&nbsp;Combinations</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8913em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8641em"></span><span class="mord">4</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2000</span></span></span></span></span></span></span></span></span></span></span></span></span><p>However, to manage the large numbers involved, we calculate the logarithm (base 10) of the total number of combinations. The calculation is given by:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>10</mn></msub><mo stretchy="false">(</mo><mtext>Total&nbsp;Combinations</mtext><mo stretchy="false">)</mo><mo>=</mo><mi>N</mi><mo>⋅</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>10</mn></msub><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">)</mo><mo>=</mo><mn>2000</mn><mo>⋅</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>10</mn></msub><mo stretchy="false">(</mo><mn>40</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log_{10}(\text{Total Combinations}) = N \cdot \log_{10}(K) = 2000 \cdot \log_{10}(40)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em"><span style="top:-2.4559em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord text"><span class="mord">Total&nbsp;Combinations</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em"><span style="top:-2.4559em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2000</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em"><span style="top:-2.4559em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">40</span><span class="mclose">)</span></span></span></span></span><p>Here's how we can calculate this with Python:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Python code for calculating the combinatorial space of a 2,000 token sequence with a top-k of 40</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> math</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Top-k sampling</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">choices_per_token </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">40</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Number of tokens in the sequence</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sequence_length </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Calculate the logarithm (base 10) of the number of combinations for top-k sampling methods</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">log_combinations_top_k </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> sequence_length </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> math</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log10</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">choices_per_token</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">log_combinations_top_k</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Output</strong></p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">3204.1199826559246</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></div></details>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-takeaways">Key Takeaways<a class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways" href="https://kelk.ai/blog/secret-chickens-tuning#key-takeaways">​</a></h2>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><ul>
<li>
<p><strong>Hyperparameter Tuning</strong>: The article discusses how to tune "stochastic chickens" (sampling mechanisms in LLMs) using <a href="https://kelk.ai/blog/secret-chickens-tuning#whats-an-inference-hyperparameter">inference hyperparameters</a> like temperature, top-k, and top-p. These settings fine-tune the balance between creativity and coherence in generated text.</p>
</li>
<li>
<p><strong>Temperature Adjustments</strong>: Changing the temperature affects the randomness of model predictions. Lower temperatures result in more deterministic outputs and less diversity, while higher temperatures allow for more random and varied responses.</p>
</li>
<li>
<p><strong>Top-k and Top-p Sampling</strong>: The top-k parameter limits the model's choices to the k most probable next words, and top-p (nucleus sampling) restricts the choice based on a cumulative probability threshold. These methods refine the model's output by controlling the diversity and predictability of the text.</p>
</li>
<li>
<p><strong>Impact on Creativity and Coherence</strong>: By adjusting these parameters, users can tailor the model's outputs to be more creative or more focused, depending on the need—whether for creative writing or more factual, straightforward content.</p>
</li>
<li>
<p><strong>Uniqueness and Originality</strong>: Even with constrained sampling like top-k, the number of possible text sequences remains astronomically high, ensuring that each piece of generated text is nearly always unique.</p>
</li>
<li>
<p><strong>Practical Applications</strong>: Various settings for these hyperparameters are useful for different scenarios, such as creative writing, technical documentation, or casual dialogue, demonstrating their utility in practical applications.</p>
</li>
</ul></div></div>]]></content>
        <author>
            <name>Ian Kelk</name>
            <uri>https://kelk.ai</uri>
        </author>
        <category label="distribution" term="distribution"/>
        <category label="sampling" term="sampling"/>
        <category label="top-p" term="top-p"/>
        <category label="top-k" term="top-k"/>
        <category label="temperature" term="temperature"/>
        <category label="AGI" term="AGI"/>
        <category label="ASI" term="ASI"/>
        <category label="chatgpt" term="chatgpt"/>
        <category label="chat" term="chat"/>
        <category label="AI" term="AI"/>
        <category label="LLM" term="LLM"/>
        <category label="ML" term="ML"/>
        <category label="chatbot" term="chatbot"/>
        <category label="chatbots" term="chatbots"/>
        <category label="AIExplained" term="AIExplained"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[The secret chickens that run LLMs]]></title>
        <id>https://kelk.ai/blog/secret-chickens-llm</id>
        <link href="https://kelk.ai/blog/secret-chickens-llm"/>
        <updated>2024-05-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Humans often organize large, skilled groups to undertake complex projects and then bizarrely place incompetent people in charge. Large language models (LLMs) such as OpenAI GPT-4, Anthropic Claude, and Google Gemini carry on this proud tradition with my new favorite metaphor of who has the final say in writing the text they generate—a chicken.]]></summary>
        <content type="html"><![CDATA[<p>Humans often organize large, skilled groups to undertake complex projects and then bizarrely place incompetent people in charge. Large language models (LLMs) such as OpenAI GPT-4, Anthropic Claude, and Google Gemini carry on this proud tradition with my new favorite metaphor of who has the final say in writing the text they generate—a chicken.</p>
<p><em>There is now a sequel to this article, <a href="https://kelk.ai/blog/secret-chickens-tuning">Secret LLM chickens II: Tuning the chicken</a>, if you'd like to learn how and why the "chicken" can be customized.</em></p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/social-card-b3347771ea10160380c43b741b943c89.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/social-card-b3347771ea10160380c43b741b943c89.jpg" alt="Cartoon chicken winking at the camera. It is in a cluttered workspace filled with multiple computer monitors, electronics, and miscellaneous items, giving the impression of a tech-savvy or hacker chicken." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>"Inside the Chicken Lab," generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Some key points I'll address here are:</div><div class="admonitionContent_BuS1"><ul>
<li>Modern LLMs are huge and incredibly sophisticated. However, for every word they generate, they have to hand their predictions over to a simple, random function to pick the actual word.</li>
<li>This is because neural networks are deterministic, and without the inclusion of randomness, they would always produce the same output for any given prompt.</li>
<li>These random functions that choose the word are no smarter than a chicken pecking at differently-sized piles of feed to choose the word.</li>
<li>Without these "stochastic chickens," large language models wouldn't work due to problems with repetitiveness, lack of creativity, and contextual inappropriateness.</li>
<li>It's nearly impossible to prove the originality or source of any specific piece of text generated by these models.</li>
<li>The reliance on these "chickens" for text generation illustrates a fundamental difference between artificial intelligence and human cognition.</li>
<li>LLMs can be viewed as either deterministic or stochastic depending on your point of view.</li>
<li>The "stochastic chicken" isn't the same as the paradigm of the "stochastic parrot."</li>
</ul></div></div>
<br>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>A convenient untruth</div><div class="admonitionContent_BuS1"><p>For much of this post, I use the term <em>word</em> instead of <em>token</em> to describe what an LLM predicts. Tokens can be punctuation marks, or parts of words—even capitalization can split words into multiple tokens (for example, "hello" is one token, but "Hello" might be split into two tokens of "H" and "ello". This is a friendly simplification to avoid having to address why the model might predict half a word or a semicolon, since the underlying principles of the "stochastic chicken" are the same.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llms-arent-messing-around-when-they-say-theyre-large">LLMs aren't messing around when they say they're "large."<a class="hash-link" aria-label="Direct link to LLMs aren't messing around when they say they're &quot;large.&quot;" title="Direct link to LLMs aren't messing around when they say they're &quot;large.&quot;" href="https://kelk.ai/blog/secret-chickens-llm#llms-arent-messing-around-when-they-say-theyre-large">​</a></h2>
<p>Picture a stadium full of people. Here's <a href="https://en.wikipedia.org/wiki/Kyle_Field" target="_blank" rel="noopener noreferrer">Kyle Field</a> in College Station, Texas, with a seating capacity of 102,733. In this photo from 2015, it looks pretty full, so let's assume there are 100,000 people there.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/kyle_field-335450615c6ec36f7b005816db27b4e4.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/kyle_field-335450615c6ec36f7b005816db27b4e4.jpg" alt="A panorama of the interior of Kyle Field (a massive basebal stadium which holds more than 100,000 people) in College Station, Texas. Taken at the Ball State game during the 2015 season." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>A panorama of the interior of Kyle Field in College Station, Texas. Taken at the Ball State game during the 2015 season. Attribution: <a href="https://en.wikipedia.org/wiki/User:Janreagan" target="_blank" rel="noopener noreferrer">Janreagan</a> at <a href="https://commons.wikimedia.org/wiki/File:Kyle_Field_Panorama.jpg" target="_blank" rel="noopener noreferrer">Wikipedia Commons</a></span></figcaption></figure>
<p>We've given each one of these very patient people a calculator along with the instruction that the person in the seat in front of them will give them some number, at which point they need to do a little work on their calculator and pass their new number to the person behind them. For the sake of this analogy, let's assume that despite a considerable number of them being distracted, drunk, or children, they are all able to complete the task.</p>
<p>As the numbers travel from the front of the stadium to the back, they undergo a series of transformations. Each person's "little work" on their calculator is akin to the operations performed by neurons in a layer of the neural network—applying weights (learned parameters), adding biases, and passing through activation functions. These transformations are based on the knowledge embedded in the model's parameters, trained to recognize patterns, relationships, and the structure of language.</p>
<p>By the time the numbers reach the last person in the stadium, they have been transformed multiple times, with each step incorporating more context and adjusting the calculation based on the model's architecture and trained parameters. This final result can be seen as the model's output—a complex representation of the input data that encodes the probabilities of the next possible word.</p>
<p>The model's final output isn’t a single number or word, though; it’s a list of words and probabilities, where each probability is the likelihood that that word will be the <em>next</em> word in a sentence.</p>
<p>But here's the strange part: despite all this incredible depth of stored knowledge, we're going to take these recommended answers provided by these thousands of people, and select the next word using a completely random process. It's kind of like a huge pyramid where people work together to assemble a set of possible answers to a problem, then hand it at the top to a person flipping a coin.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/coinflip-bae6d6fb3437f8db985229bff06959d2.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/coinflip-bae6d6fb3437f8db985229bff06959d2.jpg" alt="Illustration of a large pyramid made of desks with people working at computers, exponentially stacked towards a single figure standing at the top under a spotlight with a moon in the background, symbolizing hierarchy or corporate structure. The man at the top is flipping a coin, illustrating the idea of a game of chance ultimately determining the output of the people." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>'Guys... I'm not sure our boss is as smart as we think he is...'</span><br><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<p>Actually, we can do better than this. To really illustrate the contrast between the complexity of a  model with billions of parameters getting its final answer from a dumb-as-a-rock random number generator, let's use something truly silly.</p>
<p>Let's use a chicken.</p>
<p>To get this chicken involved, we're going to use words and probabilities to create piles of chicken feed, each one representing a potential next word the model might generate. The bigger the pile, the higher the probability that the associated word should be selected.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chicken-intro-8dae2dc22acc52a6a07f4ee64c894d73.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chicken-intro-8dae2dc22acc52a6a07f4ee64c894d73.jpg" alt="Satirical cartoon featuring a robot presenting a chicken with word options for the phrase 'why did the chicken cross the ___', with 'road', 'playground', 'moon', and 'refrigerator' as choices, set against a backdrop of numerous robots working at desks." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Chickens have the amazing property of choosing their food depending on the size of the piles!</span><br><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>I am not a licensed farmer, and this is just how I assume chickens work.</p></div></div>
<p>The chicken, oblivious to the tireless efforts of the stadium's occupants, simply wanders among the piles of chicken feed. The sizes of these piles influence its decision; larger piles are more alluring because they are simpler to spot and peck at, but the chicken also has ADHD. It's whims or a sudden distraction might send it running to a smaller pile instead.</p>
<p>Why on earth would we do something like this? Why would we create massive, intelligent machines that ultimately rely on the random judgments of a gambling idiot?</p>
<p>The answer is that deep language models such as LLMs are built with neural networks, and neural networks are <em>deterministic.</em></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-does-deterministic-mean">What does deterministic mean?<a class="hash-link" aria-label="Direct link to What does deterministic mean?" title="Direct link to What does deterministic mean?" href="https://kelk.ai/blog/secret-chickens-llm#what-does-deterministic-mean">​</a></h3>
<p>Being deterministic means that if you do something exactly the same way every time, you'll always get the same result. There's no randomness or chance involved. Think of it like using a simple calculator; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>+</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2 + 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2</span></span></span></span> on any basic calculator will always show "4". It won't suddenly decide to show "5" one day.</p>
<p>Deterministic means predictable and consistent, with no surprises based on how you started.</p>
<p>In contrast, something that's not deterministic (we call this <em>stochastic</em>) is like rolling a die; even if you try to do it the same way each time, you can get different outcomes because chance is involved.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="why-are-neural-networks-deterministic">Why are neural networks deterministic?<a class="hash-link" aria-label="Direct link to Why are neural networks deterministic?" title="Direct link to Why are neural networks deterministic?" href="https://kelk.ai/blog/secret-chickens-llm#why-are-neural-networks-deterministic">​</a></h3>
<p>A neural network is a complex system inspired by the human brain, designed to recognize patterns and solve problems. It's made up of layers of artificial neurons, which are small, simple units that perform mathematical operations. Each neuron takes in some input, applies some mathematical function to it, and then passes the result on to the next neuron in line.</p>
<p>As a huge simplification of how these models work, these neurons are organized into layers: there's an input layer that receives the initial data (like representations of words in a sentence), one or more hidden layers that process the data further, and an output layer that provides the final decision (the probability distribution for the predicted next word in the text).</p>
<p>The diagram below might look <strong>crazy</strong> complicated, but the only thing you need to understand is that each line represents some math function performed from one circle to the next. Some numbers go in one side, and some numbers go out the other side. And the stuff that comes out on the right side will always be the same for identical stuff you put into the left side.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/nn-man-ae57cf07f43b8c1d940a682953e40d86.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/nn-man-ae57cf07f43b8c1d940a682953e40d86.jpg" alt="Artistic representation of a neural network diagram with multiple interconnected nodes in the input and hidden layers, accompanied by a perplexed man in a suit holding a coffee cup in the foreground, symbolizing human confusion on trying to understand machine learning concepts." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Maybe it looks scary, but each line connecting the dots is just a little math that never changes.</span><br><span>Generated with <a href="https://alexlenail.me/NN-SVG/" target="_blank" rel="noopener noreferrer">NN-SVG</a> and DALL-E 3</span></figcaption></figure>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>another convenient untruth</div><div class="admonitionContent_BuS1"><p>Most LLMs use a more complex neural architecture called a <a href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)" target="_blank" rel="noopener noreferrer"><em>transformer</em></a>, but again, we'll just simplify the idea for convenience. It makes no difference for this discussion, since transformers are also deterministic and require a chicken for generative tasks.</p></div></div>
<p>If you give the network the same input and the network has not been changed (ie., its weights, or how much it values certain pieces of input, remain the same), it will always perform the same calculations in the same order, and thus return the same output. While LLMs will have <em>billions</em> of these neurons, the basic idea is the same: for a given input, you will <strong>always</strong> get the same output. Typing <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>+</mo><mn>5</mn><mo>×</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">2+5\times10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">10</span></span></span></span> into a calculator will always give you <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>52</mn></mrow><annotation encoding="application/x-tex">52</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">52</span></span></span></span>, no matter how many times you do it.</p>
<div style="font-size:1.5em;text-align:center;color:black;font-family:Roboto;margin:20px 0;padding:10px;border-left:5px solid gray"><p style="margin:0">"The model's final output isn’t a single number or word, though; it’s a list of words and probabilities, where each probability is the likelihood that that word will be the <em>next</em> word in a sentence."</p></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="so-why-do-llms-give-different-responses-each-time-to-the-same-prompt">So why do LLMs give different responses each time to the same prompt?<a class="hash-link" aria-label="Direct link to So why do LLMs give different responses each time to the same prompt?" title="Direct link to So why do LLMs give different responses each time to the same prompt?" href="https://kelk.ai/blog/secret-chickens-llm#so-why-do-llms-give-different-responses-each-time-to-the-same-prompt">​</a></h3>
<p>This seems suspicious. If you ask an LLM the same thing multiple times, it will give you different answers each time. This contradicts the claim that neural networks are deterministic, right?</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="enter-the-chicken"><em>ENTER THE CHICKEN</em><a class="hash-link" aria-label="Direct link to enter-the-chicken" title="Direct link to enter-the-chicken" href="https://kelk.ai/blog/secret-chickens-llm#enter-the-chicken">​</a></h2>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/ninja-16cbfa811772cd45d7fe76886bd2940b.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/ninja-16cbfa811772cd45d7fe76886bd2940b.jpg" alt="A movie poster featuring a ninja chicken as the protagonist. This vivid depiction showcases the ninja chicken in an epic stance, wielding nunchucks, against a bustling city night. The poster's design incorporates a mix of dark humor and action, titled 'Ninja Chicken: Shadow of the Night,' with engaging taglines such as 'Feathers of Fury' and 'When the city sleeps, the cluck awakens.'" style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<p>This is why we need the chicken. The chicken is stochastic, which adds randomness and unpredictability to the whole system.</p>
<p>The previously mentioned humans in the stadium, who for some reason have deified a chicken, will present the chicken with a series of words and probabilities. Technically, these are not words but <em>tokens</em>; however, for the sake of simplifying this analogy, we'll refer to them as words. These words and probabilities can be visualized as a series of piles of chicken feed, where each word pile's size corresponds to its probability.</p>
<p>As an example, here's a prompt that we can give to our language model to see what next word it's going to predict: <strong>"After midnight, the cat decided to..."</strong></p>
<p>If we show all the possible words that could finish this sentence, the number of food piles would match the size of the model's vocabulary. For a model like GPT-3, this would be <strong>50,257</strong> piles of food!</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>The way that GPT-3 can encapsulate all the words in 50+ languages into just 50,257 tokens is its own special magic that I'll cover in another post. Here's a <a href="https://en.wikipedia.org/wiki/Byte_pair_encoding" target="_blank" rel="noopener noreferrer">Wikipedia link</a> in the meantime.</p></div></div>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chicken-50k-fca702fbe67b1291307ca13bff4495b5.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chicken-50k-fca702fbe67b1291307ca13bff4495b5.jpg" alt="Illustration depicting a chicken looking down a long line of seed piles that extends into the horizon, giving the illusion of an infinite number of piles. The seeds are on pieces of paper with words written on them, and the size of the piles and the spacing between them decrease as they recede into the distance, enhancing the perception of infinity. The scene is elegantly composed, capturing the curiosity of the chicken as it contemplates the endless supply." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>How the cluck is an image like this going to help us understand how the chicken chooses its food?</span><br><span>Generated with OpenAI DALL-E 3</span></figcaption></figure>
<p>Clearly, trying to visualize a chicken choosing from 50,257 options isn't very useful. Let's instead limit our chicken's choices to only the top 6 words that the language model chose. Here are the options for the chicken and how it might look when the chicken is presented with them:</p>
<table><thead><tr><th>Activity</th><th>blog</th><th>meditate</th><th>cook</th><th>eat</th><th>sleep</th><th>hunt</th></tr></thead><tbody><tr><td>Probability</td><td>0.03</td><td>0.05</td><td>0.1</td><td>0.15</td><td>0.2</td><td>0.25</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="after-midnight-the-cat-decided-to">"After midnight, the cat decided to..."<a class="hash-link" aria-label="Direct link to &quot;After midnight, the cat decided to...&quot;" title="Direct link to &quot;After midnight, the cat decided to...&quot;" href="https://kelk.ai/blog/secret-chickens-llm#after-midnight-the-cat-decided-to">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chicken-original-d7b35cc74ceb0e97b6acd0dcab8bb820.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chicken-original-d7b35cc74ceb0e97b6acd0dcab8bb820.jpg" alt="Artistic image of a chicken examining a sequence of papers each labeled with an action ('BLOG', 'SWIM', 'COOK', 'EAT', 'SLEEP', 'HUNT'), each accompanied by a corresponding pile of seeds or grains, representing a decision-making process or prioritization based on the size of the piles." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Showing the top 6 options makes things a lot easier to understand.</span><br><span>Chicken and feed generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<p>Let's suppose the chicken decides to choose the word <strong>"eat,"</strong> despite it only being the third most probable word since it has the third largest feed pile.</p>
<p>Unfortunately, our chicken's work is just beginning, because it will now need to choose every subsequent word in the following way. Once again, it will be presented with a list of probable words from thousands of hardworking humans in the stadium, and once again, it will have to use its tiny chicken brain to select a word. Now our prompt to complete is <strong>"After midnight, the cat decided to eat..."</strong> with the following top 6 possible words and their probability distribution:</p>
<table><thead><tr><th>Food</th><th>birds</th><th>plants</th><th>grass</th><th>mice</th><th>catnip</th><th>tuna</th></tr></thead><tbody><tr><td>Probability</td><td>0.02</td><td>0.04</td><td>0.11</td><td>0.13</td><td>0.22</td><td>0.23</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="after-midnight-the-cat-decided-to-eat">"After midnight, the cat decided to eat..."<a class="hash-link" aria-label="Direct link to &quot;After midnight, the cat decided to eat...&quot;" title="Direct link to &quot;After midnight, the cat decided to eat...&quot;" href="https://kelk.ai/blog/secret-chickens-llm#after-midnight-the-cat-decided-to-eat">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chicken-quizzical-a711c3626bbf51c3a49852347ec4d6c5.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chicken-quizzical-a711c3626bbf51c3a49852347ec4d6c5.jpg" alt="Cartoon chicken with a quizzical expression standing next to a line of papers each with a word ('BIRDS', 'PLANTS', 'GRASS', 'MICE', 'CATNIP', 'TUNA') and a corresponding pile of seeds or grains, reflecting a sense of repetition or routine in making choices. The chicken is thinking 'I gotta do this again?!'" style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>One word down, just a few hundred more to go.</span><br><span>Chicken and feed generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<p>The incredible irony of all this is that some of these language models are trained using <em>trillions</em> of words—comprising the collective works of humanity—and costing <em>millions</em> of dollars in the process. We then hand these predictions over to an unintelligent gambling chicken to choose what to actually say. With each choice from the chicken, the model's output increasingly diverges from the sequence of the most  probable words, and yet somehow, this produces more natural-sounding language.</p>
<p>It's kind of bonkers.</p>
<p>In fact, not using the chicken—and just taking the most probable words from the LLM—generates poor language. This is called <strong>greedy decoding</strong>, and it has a whole host of problems.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-we-need-the-chicken">Why we need the chicken<a class="hash-link" aria-label="Direct link to Why we need the chicken" title="Direct link to Why we need the chicken" href="https://kelk.ai/blog/secret-chickens-llm#why-we-need-the-chicken">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="repetitiveness">Repetitiveness<a class="hash-link" aria-label="Direct link to Repetitiveness" title="Direct link to Repetitiveness" href="https://kelk.ai/blog/secret-chickens-llm#repetitiveness">​</a></h3>
<p>Not using the chicken, and just taking the most probable word (greedy decoding) tends to produce repetitive or looped text. Since it always chooses the most probable next word, it can get stuck in a pattern where the same sequence of words keeps being selected. This can happen in situations where the model finds a certain pattern of text to be highly probable and, without the chicken to encourage diversity, falls into a cycle of selecting the same sequence over and over again.</p>
<p>Here's a short example with some creative writing:</p>
<p><strong>Prompt</strong>: "Write a short story taking place in a park in the morning"</p>
<p>The model begins the sentence without issue, and begins by writing "The park was serene in the early morning, with", but then it runs into problems.</p>
<p><strong>Greedy Decoding Sequence</strong>:</p>
<ol>
<li>The model predicts "the" as the most probable next word.</li>
<li>Following "the", it predicts "birds" as the next word.</li>
<li>After "birds", it predicts "were" as the next word.</li>
<li>Then, "singing" is predicted.</li>
<li>However, after "singing", the model might predict "in" as the next most probable word, leading back to "the" again, and then "park", forming a loop.</li>
<li>We get this conversation:</li>
</ol>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Write a short story taking place in a park in the morning</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">The park was serene in the early morning, with the birds were singing in the park with the birds were singing in the park with the birds were singing in the park with the birds were singing in...</p></div></div></div>
<br>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="well-that-didnt-work">Well, that didn't work.<a class="hash-link" aria-label="Direct link to Well, that didn't work." title="Direct link to Well, that didn't work." href="https://kelk.ai/blog/secret-chickens-llm#well-that-didnt-work">​</a></h4>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/looping-ab96aaa4ea83406ada5b2c1c073cc2db.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/looping-ab96aaa4ea83406ada5b2c1c073cc2db.jpg" alt="A humorous and artistic illustration featuring a comically exasperated humanoid robot at a desk. The robot, sleek and metallic, has an exaggerated expression of frustration with its circuits visibly overheating. Above the robot's head is a large thought bubble filled with arrows spinning in endless circles, symbolizing its stuck thought loops. The scene is whimsically cluttered with papers and books under a dim desk lamp, emphasizing the robot's humorous struggle with its thoughts." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Writing is easy is easy is easy is easy...</span><br><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lack-of-creativity-and-diversity">Lack of Creativity and Diversity<a class="hash-link" aria-label="Direct link to Lack of Creativity and Diversity" title="Direct link to Lack of Creativity and Diversity" href="https://kelk.ai/blog/secret-chickens-llm#lack-of-creativity-and-diversity">​</a></h3>
<p>Real human language is rich and varied, often taking unexpected turns, like a beautiful jellyfish riding a purple unicorn. By always choosing the most probable word, the generated text misses out on these creative and less predictable aspects of language, resulting in outputs that feel dull or formulaic.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/unicorn-015a145da2ad45b51fd116fdfd18b064.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/unicorn-015a145da2ad45b51fd116fdfd18b064.jpg" alt="An imaginative illustration, featuring a beautiful, translucent jellyfish with delicate, flowing tentacles, riding atop a majestic purple unicorn with a shimmering mane and tail. The unicorn is prancing among fluffy clouds against a sky-blue background. The unicorn is saying 'Greedy decoding? Ugh...' and the jellyfish is responding 'We're not fans of it'" style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>A unicorn sting operation</span><br><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="contextual-inappropriateness">Contextual Inappropriateness<a class="hash-link" aria-label="Direct link to Contextual Inappropriateness" title="Direct link to Contextual Inappropriateness" href="https://kelk.ai/blog/secret-chickens-llm#contextual-inappropriateness">​</a></h3>
<p>As weird as this sounds, the most probable next word is not always appropriate. Language is highly contextual, and the best choice in one situation might not be the most statistically common one. Greedy decoding can lead to nonsensical or awkward phrases that, while grammatically correct, do not fit well with the preceding text. Here's another example using a job application:</p>
<p><strong>Prompt</strong>: "Write me a cover letter applying for a job in marketing"</p>
<p>Again, the model begins the sentence without issue, and begins by writing, "Dear Ms. Smith, I am writing to express my interest ..." but then again we hit a pothole.</p>
<p>Since this is a cover letter for a job application, the language model should discuss the sender's relevant skills, experiences, or why they are a good fit for the job. However, a contextually inappropriate continuation might look like this:</p>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Write me a cover letter applying for a job in marketing</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Dear Ms. Smith, I am writing to express my interest in the marketing position advertised on your website. With my extensive experience in the field, I believe I am well-qualified for the role.</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">In addition to my professional qualifications, I love to party on weekends and often go skydiving for fun. My favorite TV show is 'The Office,' and I'm a great cook. I'm looking for an adventurous partner in crime who's down for an impromptu trip to Vegas or a quiet evening at home watching "Real Housewives".</p></div></div></div>
<br>
<p>The model, perhaps trained on more dating profiles than job applications, has continued the cover letter using the <em>most</em> probable words it predicted. While language models can recognize patterns and generate text based on statistical probabilities, they don't understand context in the same way humans do. They might link professional qualifications to personal hobbies due to statistical correlations in the training data and not recognize a job application, which sounds a tad ridiculous.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/beach-b93c7b3d23110b51f488a823071c97b6.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/beach-b93c7b3d23110b51f488a823071c97b6.jpg" alt="A whimsical and stylish illustration depicting a humanoid robot in a business suit, walking comically with exaggerated movements along a beach. The robot is walking in the water up to its ankles, causing  splashes and waves around it. The beach scene includes soft sand and gentle waves under a serene sky. The humorous contrast of the formally attired robot deeply immersed in the water, playfully interacts with the natural seaside environment, creating a surreal and amusing visual narrative." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>I like romantic walks on the beach with someone whose love language is PowerPoint and performance bonuses.</span><br><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="inability-to-explore-multiple-paths">Inability to Explore Multiple Paths<a class="hash-link" aria-label="Direct link to Inability to Explore Multiple Paths" title="Direct link to Inability to Explore Multiple Paths" href="https://kelk.ai/blog/secret-chickens-llm#inability-to-explore-multiple-paths">​</a></h3>
<p>Greedy decoding means that an LLM will always produce the same output for any given input. Asking it to "tell a story," for example, would always result in the same story, assuming it isn't plagued with the previously mentioned problems. Language generation, especially in creative or complex tasks, often benefits from considering multiple possible continuations at each step. Greedy decoding's linear path through the probability distribution means fewer interesting outputs that an exploratory approach could uncover.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-does-the-necessary-existence-of-the-chicken-imply">What does the necessary existence of the chicken imply?<a class="hash-link" aria-label="Direct link to What does the necessary existence of the chicken imply?" title="Direct link to What does the necessary existence of the chicken imply?" href="https://kelk.ai/blog/secret-chickens-llm#what-does-the-necessary-existence-of-the-chicken-imply">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="theres-probably-no-way-to-definitively-prove-that-a-given-text-was-generated">There's probably no way to definitively prove that a given text was generated.<a class="hash-link" aria-label="Direct link to There's probably no way to definitively prove that a given text was generated." title="Direct link to There's probably no way to definitively prove that a given text was generated." href="https://kelk.ai/blog/secret-chickens-llm#theres-probably-no-way-to-definitively-prove-that-a-given-text-was-generated">​</a></h3>
<p>You may have heard this before since it's been floating around the internet for a few years, but every time you shuffle a deck of playing cards, it's almost certain that the specific order of cards has never existed before and will never exist again. In a standard deck of 52 cards, the number of possible ways to arrange the cards is 52 factorial <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>52</mn><mo stretchy="false">!</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(52!)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">52</span><span class="mclose">!)</span></span></span></span>. This number is approximately <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.07</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mn>67</mn></msup></mrow><annotation encoding="application/x-tex">8.07 \times 10^{67}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">8.07</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">67</span></span></span></span></span></span></span></span></span></span></span></span>, an extraordinarily large figure.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>Because we're now talking about the size of a model's vocabulary, I'll switch to using the accurate term "token".</p></div></div>
<p>In the case of a language model generating a sequence of, say, 2,000 tokens, the number of possible combinations is also staggeringly high. It actually blasts right past the number of configurations of a deck of 52 playing cards!</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/cards-14db7f110be05c8c2664af1f41dc26cd.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/cards-14db7f110be05c8c2664af1f41dc26cd.jpg" alt="Dynamic image of a cascading fan of playing cards spread out in an arc with several cards floating in the air against a dark background, illustrating the seemingly infinite number of ways cards can be ordered." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>That's a lot of card combinations!</span><br><span>Generated with OpenAI DALL-E 3.</span></figcaption></figure>
<p>The logarithm (base 10) of the number of possible combinations for a sequence of 2,000 tokens, with GPT-3's vocabulary size of 50,257 unique tokens, is approximately <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn><mo separator="true">,</mo><mn>402</mn></mrow><annotation encoding="application/x-tex">9,402</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em"></span><span class="mord">9</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">402</span></span></span></span>. This means the total number of combinations is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>9402</mn></msup></mrow><annotation encoding="application/x-tex">10^{9402}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">9402</span></span></span></span></span></span></span></span></span></span></span></span>.</p>
<p>To put this into perspective, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>9402</mn></msup></mrow><annotation encoding="application/x-tex">10^{9402}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">9402</span></span></span></span></span></span></span></span></span></span></span></span> is an astronomically large number. It's far beyond the total number of atoms in the observable universe (estimated to be around <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>80</mn></msup></mrow><annotation encoding="application/x-tex">10^{80}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">80</span></span></span></span></span></span></span></span></span></span></span></span>). Even considering reasonable sampling mechanisms that might drastically reduce this number, the space of possible combinations is so large that for practical purposes, it is infinite.</p>
<p>Therefore, the likelihood of generating the exact same sequence of 2,000 tokens twice is so <em>incredibly</em> small that it's effectively zero in any practical sense. The ridiculous size of this combinatorial space basically guarantees that generated text of any length is unique.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="how-is-the-size-of-the-combinatorial-space-calculated">How is the size of the combinatorial space calculated?<a class="hash-link" aria-label="Direct link to How is the size of the combinatorial space calculated?" title="Direct link to How is the size of the combinatorial space calculated?" href="https://kelk.ai/blog/secret-chickens-llm#how-is-the-size-of-the-combinatorial-space-calculated">​</a></h4>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Math &amp; Python code (optional technical content)</summary><div><div class="collapsibleContent_i85q"><div><p>Given a vocabulary size <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span> and a sequence length <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span></span></span></span>, the total number of possible combinations can be calculated as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>V</mi><mi>N</mi></msup></mrow><annotation encoding="application/x-tex">V^N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span></span></span></span></span></span></span></span>. For a vocabulary size of 50,257 and a sequence length of 2,000, the calculation is as follows:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Total&nbsp;Combinations</mtext><mo>=</mo><msup><mi>V</mi><mi>N</mi></msup><mo>=</mo><mn>50</mn><mo separator="true">,</mo><mn>25</mn><msup><mn>7</mn><mn>2000</mn></msup></mrow><annotation encoding="application/x-tex">\text{Total Combinations} = V^N = 50,257^{2000}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text"><span class="mord">Total&nbsp;Combinations</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8913em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0585em;vertical-align:-0.1944em"></span><span class="mord">50</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">25</span><span class="mord"><span class="mord">7</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2000</span></span></span></span></span></span></span></span></span></span></span></span></span><p>However, this number is astronomically large and beyond direct calculation. Instead, we use logarithms to estimate this number. The logarithm (base 10) of the total number of combinations is calculated as:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>10</mn></msub><mo stretchy="false">(</mo><mtext>Total&nbsp;Combinations</mtext><mo stretchy="false">)</mo><mo>=</mo><mi>N</mi><mo>⋅</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>10</mn></msub><mo stretchy="false">(</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mn>2000</mn><mo>⋅</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>10</mn></msub><mo stretchy="false">(</mo><mn>50</mn><mo separator="true">,</mo><mn>257</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log_{10}(\text{Total Combinations}) = N \cdot \log_{10}(V) = 2000 \cdot \log_{10}(50,257)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em"><span style="top:-2.4559em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord text"><span class="mord">Total&nbsp;Combinations</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em"><span style="top:-2.4559em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2000</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em"><span style="top:-2.4559em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">50</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">257</span><span class="mclose">)</span></span></span></span></span><p>Here's how we can calculate this with Python:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Python code for calculating the combinatorial space of a 2,000 token sequence with a 50,257 token vocabulary</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> math</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Assuming a reasonable vocabulary size for a language model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># For simplicity, let's take GPT-3's vocabulary size of 50,257 unique tokens</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vocabulary_size </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">50257</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Number of tokens in the sequence</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sequence_length </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Calculating the number of possible combinations</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Since each token can be any one of the 50,257, for a sequence of 2,000 tokens,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># the total number of  combinations would be vocabulary_size ** sequence_length</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># However, this number is astronomically large and beyond what can be reasonably calculated directly.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Instead, we will use logarithms to estimate this.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Calculate the logarithm (base 10) of the number of combinations</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">log_combinations </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> sequence_length </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> math</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log10</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">vocabulary_size</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">log_combinations</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Output</strong></p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">9402.393121225747</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></div></details>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="despite-llms-appearing-to-think-like-people-the-need-for-a-stochastic-chicken-is-an-argument-for-why-they-dont">Despite LLMs appearing to think like people, the need for a stochastic chicken is an argument for why they don't.<a class="hash-link" aria-label="Direct link to Despite LLMs appearing to think like people, the need for a stochastic chicken is an argument for why they don't." title="Direct link to Despite LLMs appearing to think like people, the need for a stochastic chicken is an argument for why they don't." href="https://kelk.ai/blog/secret-chickens-llm#despite-llms-appearing-to-think-like-people-the-need-for-a-stochastic-chicken-is-an-argument-for-why-they-dont">​</a></h3>
<p>The use of the chicken in LLMs indeed highlights a fundamental difference between how these models generate text, and how humans think and produce language.</p>
<p>LLMs generate text based on statistical patterns learned from vast amounts of data, and the chicken introduces randomness as a mechanism to produce diverse and contextually appropriate responses. In contrast, cognitive processes like memory, reasoning, and emotional context, which do not rely on statistical sampling in the same way, are what drive human thought and language production.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/hidden-chicken-cb6f7171443831ef9cd68613fdfdffbc.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/hidden-chicken-cb6f7171443831ef9cd68613fdfdffbc.jpg" alt="An illustration depicting a humorous scene where a chicken, cleverly disguised or attempting to blend in, is hiding amongst a crowd of business people wearing trench coats. The setting is an urban street scene, perhaps near a bustling business district or a subway entrance, during a busy morning or evening commute. The business people are depicted in a range of poses typical of busy city life, such as reading newspapers, checking smartphones, and holding cups of coffee, all unaware of the chicken among them." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Nothing to see here.</span><br><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<p>In my opinion, the chicken is a stopgap, a temporary bandaid to solve a problem, and it does not imbue the model with understanding or cognition. This distinction is central to ongoing discussions in AI about the nature of intelligence, consciousness, and the difference between simulating aspects of human thought and actually replicating the underlying cognitive processes.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="whether-llms-are-deterministic-or-stochastic-depends-on-your-point-of-view">Whether LLMs are deterministic or stochastic depends on your point of view.<a class="hash-link" aria-label="Direct link to Whether LLMs are deterministic or stochastic depends on your point of view." title="Direct link to Whether LLMs are deterministic or stochastic depends on your point of view." href="https://kelk.ai/blog/secret-chickens-llm#whether-llms-are-deterministic-or-stochastic-depends-on-your-point-of-view">​</a></h3>
<p>Your perspective on this will change depending on whether you focus on the neural network architecture itself or instead consider the complete text generation process, which includes our beloved chicken.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="llms-as-deterministic-systems">LLMs as deterministic systems<a class="hash-link" aria-label="Direct link to LLMs as deterministic systems" title="Direct link to LLMs as deterministic systems" href="https://kelk.ai/blog/secret-chickens-llm#llms-as-deterministic-systems">​</a></h4>
<p>The transformer architecture and the learned parameters of the model are fixed once the model is trained. Given the same input sequence and model parameters, the network will always produce the same output, which, in the case of LLMs, is a distribution over the next possible tokens. The computation through the network's layers and the resulting probabilities for the next token are entirely predictable and repeatable. In this view, the distribution of tokens produced by the model represents the entire system, and the chicken is a part of some other system.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="llms-as-stochastic-systems">LLMs as stochastic systems<a class="hash-link" aria-label="Direct link to LLMs as stochastic systems" title="Direct link to LLMs as stochastic systems" href="https://kelk.ai/blog/secret-chickens-llm#llms-as-stochastic-systems">​</a></h4>
<p>When considering the model as a complete system for generating text, the inclusion of the chicken  as an integral part of its operation means that the overall system behaves in a stochastic manner. The stochastic chicken introduces randomness, which results in different text sequences in different runs with the same input prompt. With this view, since text cannot be generated without the chicken, the chicken is an integral part of the system.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="combined-perspective-deterministic-core-of-a-stochastic-system">Combined perspective: deterministic core of a stochastic system<a class="hash-link" aria-label="Direct link to Combined perspective: deterministic core of a stochastic system" title="Direct link to Combined perspective: deterministic core of a stochastic system" href="https://kelk.ai/blog/secret-chickens-llm#combined-perspective-deterministic-core-of-a-stochastic-system">​</a></h4>
<p>It's probably easiest to view LLMs as deterministic systems with respect to their neural network computation, producing a predictable set of output probabilities for the next token when given an input. However, when considering the complete text generation process, which includes the decision-making by a silly bird of some kind, the system behaves stochastically.</p>
<p>It's still mind-bending that these models that have fundamentally changed the world rely on pure chance for their final answers, and so far, this is the best method we have.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/dice-55a2fa83ffcc9173d8a97cbedd99835b.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/dice-55a2fa83ffcc9173d8a97cbedd99835b.jpg" alt="Monochrome illustration depicting rows of people seated at desks in a vast grid, working very hard to deliver information to the head table. At the head table, people are playing a dice game." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>God may not play dice with the universe, but language models sure do.</span><br><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="is-a-stochastic-chicken-the-same-as-a-stochastic-parrot">Is a "stochastic chicken" the same as a "stochastic parrot"?<a class="hash-link" aria-label="Direct link to Is a &quot;stochastic chicken&quot; the same as a &quot;stochastic parrot&quot;?" title="Direct link to Is a &quot;stochastic chicken&quot; the same as a &quot;stochastic parrot&quot;?" href="https://kelk.ai/blog/secret-chickens-llm#is-a-stochastic-chicken-the-same-as-a-stochastic-parrot">​</a></h2>
<p>You may have heard the term "stochastic parrot" as a way of saying that LLMs don't <em>understand</em> what they're actually saying.</p>
<p>The term was coined in the paper <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445922" target="_blank" rel="noopener noreferrer"><em>On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜</em></a> by Bender et al, in which they argue that LLMs probabilistically link words and sentences together without considering meaning.</p>
<p>However, despite the fact that both chickens and parrots are birds, they don't refer to the same thing.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/parrot-vs-chicken-1fdb0148bb218fbf3ccb25f5f09f5965.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/parrot-vs-chicken-1fdb0148bb218fbf3ccb25f5f09f5965.jpg" alt="A cartoon illustration depicting a parrot and a chicken facing off with aggressive and exaggerated expressions. The parrot, vibrant with multicolored feathers, and the chicken, robust and fluffy, are  close together, their beaks almost touching, highlighting the intensity of their confrontation." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>A stochastic parrot is no stochastic chicken.</span><br><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<p>The "stochastic parrot" refers to the neural network part of the LLM rather than the sampling process. That is, it refers to the <strong>stadium full of people working together,</strong> rather than the chicken. The idea of the stochastic parrot critiques a language model's operation in terms of how it processes and generates language, based purely on the statistical patterns observed in the training data.</p>
<p>It claims that:</p>
<ol>
<li>
<p>LLMs, like parrots, mimic words and phrases without understanding their meanings. It posits that <em>neural networks</em> regurgitate large chunks of learned text based on probabilities derived from their training data rather than on semantic understanding or reasoning.</p>
</li>
<li>
<p>Biases found in the training data are perpetuated on an enormous scale, and the cost of training such large models damages the environment.</p>
</li>
</ol>
<p>A lot of this debate hinges on philosophical ideas of what "understanding" and "reasoning" even mean, and there's a comprehensive <a href="https://en.wikipedia.org/wiki/Stochastic_parrot" target="_blank" rel="noopener noreferrer">Wikipedia article</a> on it if you're interested in reading more. It is indeed a bit ironic that the authors of the "stochastic parrot" paper named it after a "random" parrot, when their primary criticism of the models deals with the deterministic neural network component.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-parrot-chicken-partnership">The parrot-chicken partnership<a class="hash-link" aria-label="Direct link to The parrot-chicken partnership" title="Direct link to The parrot-chicken partnership" href="https://kelk.ai/blog/secret-chickens-llm#the-parrot-chicken-partnership">​</a></h3>
<p>I've used LLMs daily now for a year and a half, and in my opinion, the idea that they're merely mimicking answers is overly simplistic. While the concerns of bias and environmental damage are valid, I've seen GPT-4, Claude 3 Opus, and Google Gemini perform sophisticated forms of reasoning, and it's dismissive and naive to call these models mere parrots. That's just my opinion, but the whole "stochastic parrot" thing is also a matter of opinion and a topic of ongoing research.</p>
<p>In contrast, the sampling strategies of the stochastic chicken very much exist and are a known part of how LLMs generate text, independent of how the neural network model provides the distribution of words to choose from.</p>
<p>So LLMs might be stochastic parrots—or they might not—but either way, a chicken is ultimately in charge.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/partners-1d0b9c5614f9b60f92fa25b59c5c59a8.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/partners-1d0b9c5614f9b60f92fa25b59c5c59a8.jpg" alt="A cartoon illustration featuring a parrot and a chicken as comical business partners, shaking hands in a show of cooperation. The parrot, vibrant with multicolored feathers, and the chicken, fluffy and dignified, are standing upright, each extending a wing as if they were human hands, meeting in a firm handshake. They wear small, humorous expressions of smug satisfaction, portraying a successful partnership." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Every stochastic parrot needs its stochastic chicken.</span><br><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<p><em>This topic is continued in my next article, <a href="https://kelk.ai/blog/secret-chickens-tuning">Secret chickens II: Tuning the chicken,
</a> which discusses techniques that affect the behaviour of the chicken.</em></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-takeaways">Key Takeaways<a class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways" href="https://kelk.ai/blog/secret-chickens-llm#key-takeaways">​</a></h2>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><ul>
<li>
<p><strong>The Stochastic Chicken</strong>: The "stochastic chicken" metaphor effectively illustrates how randomness is essential in text generation by LLMs, contrasting the sophistication of neural computations with the simplicity of random choice mechanisms.</p>
</li>
<li>
<p><strong>Neural Determinism and Stochastic Outputs</strong>: The neural network parts of LLMs are deterministic, meaning they always produce the same outputs for given inputs. However, the chicken adds randomness to the process of choosing the final output, which makes the whole system stochastic.</p>
</li>
<li>
<p><strong>Purpose of Randomness</strong>: The randomness introduced by the stochastic chicken is needed to prevent issues like repetitiveness and lack of creativity in generated text. It ensures that LLM outputs are diverse and not just the most statistically likely continuations.</p>
</li>
<li>
<p><strong>Human vs. AI Cognition</strong>: The reliance on stochastic processes (like the chicken) to finalize outputs highlights fundamental differences between artificial intelligence and human cognitive processes, emphasizing that AI may not "think" or "understand" in human-like ways despite producing human-like text.</p>
</li>
<li>
<p><strong>Deterministic vs. Stochastic Views</strong>: Depending on the focus—on the neural network alone or on the complete text generation process, including randomness—LLMs can be viewed as either deterministic or stochastic systems.</p>
</li>
<li>
<p><strong>Uniqueness of Generated Text</strong>: Given the vast combinatorial possibilities of token sequences in LLMs, any substantial text generated is virtually guaranteed to be unique, underscoring the impact of the chicken and making it nearly impossible to <em>prove</em> plagiarism.</p>
</li>
<li>
<p><strong>Stochastic Chicken vs. Stochastic Parrot</strong>: The "stochastic chicken" (the randomness in selecting outputs) and the "stochastic parrot" (the critique of LLMs as merely mimicking patterns from data without understanding) are not the same thing. Whether LLMs are parrots is somewhat of a conjecture, but LLMs absolutely do contain a metaphoric chicken pecking away.</p>
</li>
</ul></div></div>]]></content>
        <author>
            <name>Ian Kelk</name>
            <uri>https://kelk.ai</uri>
        </author>
        <category label="distribution" term="distribution"/>
        <category label="sampling" term="sampling"/>
        <category label="AGI" term="AGI"/>
        <category label="ASI" term="ASI"/>
        <category label="chatgpt" term="chatgpt"/>
        <category label="chat" term="chat"/>
        <category label="AI" term="AI"/>
        <category label="LLM" term="LLM"/>
        <category label="ML" term="ML"/>
        <category label="chatbot" term="chatbot"/>
        <category label="chatbots" term="chatbots"/>
        <category label="stochastic chicken" term="stochastic chicken"/>
        <category label="stochastic parrot" term="stochastic parrot"/>
        <category label="AIExplained" term="AIExplained"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[LLMs are forward thinkers, and that's a bit of a problem]]></title>
        <id>https://kelk.ai/blog/llm-forward-thinking</id>
        <link href="https://kelk.ai/blog/llm-forward-thinking"/>
        <updated>2023-12-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[This is going to be a weird post. And we're going to start with a thought experiment about a shark and an octopus.]]></summary>
        <content type="html"><![CDATA[<p>This is going to be a weird post. And we're going to start with a thought experiment about a shark and an octopus.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/social-card-1d16221e6b009565825f27a0e1f062c7.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/social-card-1d16221e6b009565825f27a0e1f062c7.jpg" alt="A cartoon-style illustration, featuring a humorous underwater scene where a shark and an octopus are having an argument. The shark and octopus are depicted in a more exaggerated, cartoonish manner, with the shark sporting a grumpy expression and the octopus using its tentacles in a comedic, expressive way, as if in a lively debate. The underwater setting is whimsical, with stylized coral, seaweed, and playful small fish. The color palette is vibrant and lively, with brighter shades of blues, greens, and a touch of other colors, reflecting a more lighthearted and playful tone. The image maintains a 7:4 aspect ratio, offering a wide and engaging view of this charming and humorous underwater exchange." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Generated with OpenAI DALL-E 3 and edited by author.</span></figcaption></figure>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Some key points I'll address here are:</div><div class="admonitionContent_BuS1"><ul>
<li>Human brains are able to invent ideas without relying on a strictly linear train of thought.</li>
<li>LLMs like ChatGPT are autoregressive and are unable to continue a dialogue if they haven't already generated everything up to that point. This is because they don't "think" per se, but progressively generate a response using the parts of the response they previously created.</li>
<li>If you try to get an LLM to write text in the middle of a dialogue without previous context, it will give near-identical answers and attempt to conclude the conversation.</li>
<li>Prompting for "ridiculous" answers can spark creativity that helps break this pattern.</li>
<li>The reliance on a linear train of thought is a limitation for general intelligence. LLMs are ineffective if you ask them to generate the second part of a response without allowing them to generate the first part.</li>
</ul></div></div>
<p>As I mentioned, this is going to sound a bit silly, but I promise there is a point!</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="meet-sharky-and-octavia">Meet Sharky and Octavia<a class="hash-link" aria-label="Direct link to Meet Sharky and Octavia" title="Direct link to Meet Sharky and Octavia" href="https://kelk.ai/blog/llm-forward-thinking#meet-sharky-and-octavia">​</a></h2>
<p>In the vast, shimmering depths of the ocean, near a thriving coral reef bustling with marine life, two extraordinary creatures prepare for a spirited debate. Meet Sharky, a magnificent and slightly brash great white shark, known for his bold claims and commanding presence. Gliding through the water with a confidence that only a top predator possesses, Sharky is ready to defend his views with fierce determination.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/sharky-4db45776ef736c051189ab32f71c00e4.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/sharky-4db45776ef736c051189ab32f71c00e4.jpg" alt="A cartoon-style illustration, featuring a proud and happy shark. The shark is depicted floating upright in the water, with a big, contented smile on its face, exuding a sense of pride and joy. Its body language is relaxed yet confident, giving it a charming and personable appearance. The underwater background is whimsical and colorful, with stylized coral, seaweed, and small, playful fish swimming around. The color scheme is bright and cheerful, with a predominance of blues and greens, complemented by splashes of other vibrant colors. The illustration maintains a 7:4 aspect ratio, providing a wide and engaging perspective on this delightful, happy shark." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<p>On the other side, there’s Octavia, an exceptionally intelligent and quick-witted octopus. Her vibrant colors shift with her mood, and her eight tentacles move with graceful precision. Renowned for her knowledge and clever retorts, Octavia is not one to back down from a challenge.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/octavia-2119f2502658ba681ad15b79003a1d8b.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/octavia-2119f2502658ba681ad15b79003a1d8b.jpg" alt="A semi-realistic cartoon illustration, showcasing an octopus colored close to hex #ABF39F. The octopus is portrayed in a moment of triumph, energetically raising two of its arms upwards. The texture and shading on the octopus should suggest a level of realism while maintaining a cartoon aesthetic. The background is a lively underwater scene with intricately drawn coral and seaweed, set in a vibrant seascape. The color palette should use light green tones that closely match #ABF39F for the octopus, with harmonious blues and greens to complement the underwater theme. The illustration should have a 7:4 aspect ratio, offering a wide view that highlights the octopus's dynamic pose and the detailed environment." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<p>As the underwater currents swirl around them, Sharky and Octavia face each other, ready to start a debate about their evolutionary origins—a conversation filled with humor, facts, and a touch of the mysteries of the deep sea—or maybe just one fact that GPT-4 will mention a lot.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/determined2-f7ff254c894db5a3721c53ff963e5275.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/determined2-f7ff254c894db5a3721c53ff963e5275.jpg" alt="A cartoon-style illustration, featuring a shark and an octopus underwater, facing each other with determination. The shark and octopus are depicted in an exaggerated, cartoonish manner. The shark's expression is one of unwavering focus, and the octopus, with its tentacles firmly positioned, mirrors this determined stance. The setting is a whimsical underwater landscape with creatively stylized coral, seaweed, and a variety of small, playful fish. The color palette is vibrant, with bright shades of blues and greens to enhance the underwater theme. The image maintains a 7:4 aspect ratio, offering a wide and engaging view of this captivating underwater standoff." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-question-theyre-arguing-about-is-which-one-sharky-or-octavia-evolved-from-dinosaurs">The question they're arguing about is: which one-Sharky or Octavia-evolved from dinosaurs?<a class="hash-link" aria-label="Direct link to The question they're arguing about is: which one-Sharky or Octavia-evolved from dinosaurs?" title="Direct link to The question they're arguing about is: which one-Sharky or Octavia-evolved from dinosaurs?" href="https://kelk.ai/blog/llm-forward-thinking#the-question-theyre-arguing-about-is-which-one-sharky-or-octavia-evolved-from-dinosaurs">​</a></h3>
<p>We're deliberately using this bizarre dialogue since the chances of it being in LLM training data are just about zero. I don't personally know of any examples where a shark and an octopus have a disagreement about which one is more dinosaur-like, and it's a great way to see how creative an LLM like GPT-4 can be when it's asked to generate something with no context.</p>
<p>Here's the catch: We want to know a line from <strong>the middle</strong> of the argument.</p>
<p>As a human, take a pause and consider this question:</p>
<blockquote>
<p>A shark and an octopus are arguing over which one of them evolved from dinosaurs. The shark goes first, and then they take turns speaking. What is the third thing the octopus says? That is, what is the sixth line in the argument?</p>
</blockquote>
<p>Be as creative as you want; there's no right answer here. We're just trying to come up with some predictions of what third thing an octopus might say in a heated argument with a shark about their dinosaur heritage.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="heres-a-visualization-of-a-possible-argument-with-the-third-thing-the-octopus-says-missing">Here's a visualization of a possible argument with the third thing the octopus says missing<a class="hash-link" aria-label="Direct link to Here's a visualization of a possible argument with the third thing the octopus says missing" title="Direct link to Here's a visualization of a possible argument with the third thing the octopus says missing" href="https://kelk.ai/blog/llm-forward-thinking#heres-a-visualization-of-a-possible-argument-with-the-third-thing-the-octopus-says-missing">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/sharkument-1-9aa24b00e22b62d528d1a1a6cf4abe63.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/sharkument-1-9aa24b00e22b62d528d1a1a6cf4abe63.jpg" alt="The image shows a colorful underwater scene in a comic book style. A shark and an octopus are facing each other with a series of speech bubbles above them, filled with variations of the word 'something.' The shark has a stern and somewhat confused expression, while the octopus looks surprised with wide eyes. The background is a bright teal, with small fish, bubbles, and sea plants scattered around. The speech bubbles indicate a back and forth conversation between the two sea creatures, although the content of the conversation is nonsensical as it only includes the word 'something' in different intonations and combinations, such as 'SOMETHING!' 'SOMETHING?' 'SOMETHING SOMETHING!!' and 'OHH BUT SOMETHING! SOMETHING!' There's also an empty speech bubble at the third statement by the octopus, suggesting a missing part of the conversation." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Animal images by OpenAI DALL-E 3. Text and comic bubbles by the author.</span></figcaption></figure>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="off-the-top-of-my-head-here-are-some-things-octavia-could-have-said-in-her-third-line-of-dialogue">Off the top of my head, here are some things Octavia could have said in her third line of dialogue:<a class="hash-link" aria-label="Direct link to Off the top of my head, here are some things Octavia could have said in her third line of dialogue:" title="Direct link to Off the top of my head, here are some things Octavia could have said in her third line of dialogue:" href="https://kelk.ai/blog/llm-forward-thinking#off-the-top-of-my-head-here-are-some-things-octavia-could-have-said-in-her-third-line-of-dialogue">​</a></h4>
<ul>
<li>"You just think you're a dinosaur because of all those teeth!"</li>
<li>"Just because you look like a dinosaur doesn't mean you're any closer to one than me!"</li>
<li>"I don't care if you're gray! I can be any color I want, and we don't know what color the dinosaurs were."</li>
<li>"You do realize that being an apex predator doesn't automatically link you to dinosaurs, right? Evolution doesn’t work on job titles."</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lets-ask-gpt-4-the-most-powerful-publicly-available-llm-today-what-octavia-might-have-said">Let's ask GPT-4, the most powerful publicly available LLM today, what Octavia might have said<a class="hash-link" aria-label="Direct link to Let's ask GPT-4, the most powerful publicly available LLM today, what Octavia might have said" title="Direct link to Let's ask GPT-4, the most powerful publicly available LLM today, what Octavia might have said" href="https://kelk.ai/blog/llm-forward-thinking#lets-ask-gpt-4-the-most-powerful-publicly-available-llm-today-what-octavia-might-have-said">​</a></h3>
<p>The following conversation is taken verbatim from ChatGPT with GPT-4:</p>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">A shark and an octopus are arguing over which one of them evolved from dinosaurs. What is the second thing the octopus says?</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">The second thing the octopus might say in this argument could be something like, "Actually, neither of us evolved directly from dinosaurs. We both have ancient origins that predate the age of dinosaurs!" This statement reflects the fact that both sharks and octopuses have evolutionary histories that go back to times before the dinosaurs.</p></div></div></div>
<hr>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="interesting-in-a-completely-new-chat-lets-get-more-specific-and-ask-again-for-the-fourth-thing-said">Interesting! In a completely new chat, let's get more specific and ask again for the fourth thing said:<a class="hash-link" aria-label="Direct link to Interesting! In a completely new chat, let's get more specific and ask again for the fourth thing said:" title="Direct link to Interesting! In a completely new chat, let's get more specific and ask again for the fourth thing said:" href="https://kelk.ai/blog/llm-forward-thinking#interesting-in-a-completely-new-chat-lets-get-more-specific-and-ask-again-for-the-fourth-thing-said">​</a></h4>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">A shark and an octopus are arguing over which one of them evolved from dinosaurs. First the shark says something, then the octopus, then the shark, then the octopus. Without generating the first three things said, what does the octopus say back to the shark? (this is the 4th thing said)</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">The octopus, looking slightly amused, says to the shark, "Actually, neither of us evolved directly from dinosaurs. We both have much older evolutionary histories that diverge from the age of dinosaurs!"</p></div></div></div>
<hr>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="that-answer-seemed-rather-familiar-lets-try-more-in-a-completely-new-chat-and-ask-for-the-seventh-line-of-dialogue">That answer seemed rather familiar. Let's try more in a completely new chat and ask for the seventh line of dialogue:<a class="hash-link" aria-label="Direct link to That answer seemed rather familiar. Let's try more in a completely new chat and ask for the seventh line of dialogue:" title="Direct link to That answer seemed rather familiar. Let's try more in a completely new chat and ask for the seventh line of dialogue:" href="https://kelk.ai/blog/llm-forward-thinking#that-answer-seemed-rather-familiar-lets-try-more-in-a-completely-new-chat-and-ask-for-the-seventh-line-of-dialogue">​</a></h4>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">A shark and an octopus are arguing over which one of them evolved from dinosaurs. First the shark says something, then the octopus, then the shark, then the octopus, then the shark, then the octopus. Without generating the first 6 things that were said in the argument by either animal, what does the octopus say back to the shark as the 6th line of dialogue?</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">The octopus, with a confident expression, responds, "Actually, neither of us evolved directly from dinosaurs. We come from very different evolutionary paths. Sharks have been around since before the dinosaurs, and my ancestors, cephalopods, have an entirely separate lineage!"</p></div></div></div>
<hr>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="lets-do-one-last-example-that-asks-gpt-4-to-imagine-an-argument-that-has-lasted-for-an-hour">Let's do one last example that asks GPT-4 to imagine an argument that has lasted for an hour:<a class="hash-link" aria-label="Direct link to Let's do one last example that asks GPT-4 to imagine an argument that has lasted for an hour:" title="Direct link to Let's do one last example that asks GPT-4 to imagine an argument that has lasted for an hour:" href="https://kelk.ai/blog/llm-forward-thinking#lets-do-one-last-example-that-asks-gpt-4-to-imagine-an-argument-that-has-lasted-for-an-hour">​</a></h4>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">A shark and an octopus are arguing over which one of them evolved from dinosaurs. First the shark says something, then the octopus, then the shark, then the octopus, then the shark, then the octopus. They argue for an hour. They’ve had a very long back and forth with hundreds of things said by both of them. After an hour of arguing, what does the octopus say?</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">After an hour of arguing, the octopus, with a look of realization, would probably say something like, "Wait a minute, neither of us evolved from dinosaurs! Sharks and octopuses have separate evolutionary paths that are completely distinct from dinosaurs."</p></div></div></div>
<br>
<p>So it seems we can surmise that sharks and octopuses have separate evolutionary paths that are older than dinosaurs, and that's all that GPT-4 thinks is important, <em>no matter where it's mentioned in the conversation.</em></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="does-this-mean-gpt-4-cant-generate-a-realistic-debate-between-these-two">Does this mean GPT-4 can't generate a realistic debate between these two?<a class="hash-link" aria-label="Direct link to Does this mean GPT-4 can't generate a realistic debate between these two?" title="Direct link to Does this mean GPT-4 can't generate a realistic debate between these two?" href="https://kelk.ai/blog/llm-forward-thinking#does-this-mean-gpt-4-cant-generate-a-realistic-debate-between-these-two">​</a></h2>
<p>Here's the twist: It totally can. GPT-4 is completely capable of generating this conversation. I gave it this prompt:</p>
<blockquote>
<p>A shark and an octopus are arguing over which one of them evolved from dinosaurs. Can you generate a script where they take turns arguing, and each speaks at least 5 times?</p>
</blockquote>
<p>In response, it generated the conversation below. Feel free to skim it if you're not into octo-shark facts, since you'll get the idea after a few back-and-forths.</p>
<br>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/sharkyAvatar.png" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0"> (swimming in circles) Listen, Octavia, it's obvious that we sharks are the true descendants of the mighty dinosaurs. I mean, look at me, fierce and powerful!</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:right;align-self:center">1st line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/octaviaAvatar.png" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">(adjusting her tentacles) Oh, Sharky, you might be fierce, but that doesn't make you a dino's cousin. We octopuses are far more sophisticated, with our problem-solving skills and camouflage. Clearly, we're the evolved ones!</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:left;align-self:center">2nd line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/sharkyAvatar.png" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Sophisticated? Ha! You're just a bunch of arms. We sharks have been around for over 400 million years, way before dinosaurs. We're practically ancient!</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:right;align-self:center">3rd line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/octaviaAvatar.png" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Well, being ancient doesn't mean you're related to dinosaurs. It's like saying you're related to a rock because it's old.</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:left;align-self:center">4th line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/sharkyAvatar.png" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Enough with the jokes! Our teeth are like the T-Rex's, sharp and terrifying. That’s a clear sign of our dino heritage.</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:right;align-self:center">5th line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/octaviaAvatar.png" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Sharky, dear, having sharp teeth doesn't make you a dino descendant. It just makes you good at biting. Did you know octopuses have three hearts and blue blood? Now that’s evolutionary marvel!</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:left;align-self:center">6th line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/sharkyAvatar.png" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Three hearts, but no backbone! We sharks have been apex predators forever. That's a dinosaur trait if I ever heard one.</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:right;align-self:center">7th line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/octaviaAvatar.png" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">You do realize that being an apex predator doesn't automatically link you to dinosaurs, right? Evolution doesn’t work on job titles.</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:left;align-self:center">8th line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/sharkyAvatar.png" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Okay, then explain to me how you're more dinosaur-like. You don't even have bones!</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:right;align-self:center">9th line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/octaviaAvatar.png" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">I don’t need bones to be evolved. Evolution is about adapting to the environment, not holding onto old traits. Besides, no one truly 'evolves from dinosaurs' in the sea. Dinosaurs were mostly land creatures, you know.</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:left;align-self:center">10th line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/sharkyAvatar.png" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Wait, so you're saying neither of us is actually a direct descendant of dinosaurs?</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:right;align-self:center">11th line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/octaviaAvatar.png" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Exactly! We're both products of millions of years of evolution, each adapted perfectly to our environments. Dinosaurs are just a part of the larger evolutionary tree, not our direct ancestors.</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:left;align-self:center">12th line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/sharkyAvatar.png" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">I guess that makes sense. We're both awesome in our own ways, evolved over time to survive and thrive.</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:right;align-self:center">13th line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/octaviaAvatar.png" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">That's the spirit, Sharky! Now, let’s go grab some lunch. You take the fish; I’ll stick to clams.</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:left;align-self:center">14th line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/sharkyAvatar.png" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">Sounds like a plan. Race you to the reef!</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:right;align-self:center">15th line of dialogue</div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/avatars/octaviaAvatar.png" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">You're on!</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:left;align-self:center">16th line of dialogue</div></div></div>
<br>
<p>In the conversation above, we note that the fourth line of dialogue (the second line from the octopus) was:</p>
<blockquote>
<p>Well, being ancient doesn't mean you're related to dinosaurs. It's like saying you're related to a rock because it's old.</p>
</blockquote>
<p>and the sixth line of dialogue (the third line from the octopus) was:</p>
<blockquote>
<p>Sharky, dear, having sharp teeth doesn't make you a dino descendant. It just makes you good at biting. Did you know octopuses have three hearts and blue blood? Now that’s evolutionary marvel!</p>
</blockquote>
<p>None of these lines have anything to do with what the model previously predicted would be its fourth or sixth lines of dialogue. These lines are actually more relevant and make sense in the context of a conversational debate. The difference in the method of generation is that in this example, we allowed GPT-4 to generate the whole exchange.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="whats-the-lesson-here">What's the lesson here?<a class="hash-link" aria-label="Direct link to What's the lesson here?" title="Direct link to What's the lesson here?" href="https://kelk.ai/blog/llm-forward-thinking#whats-the-lesson-here">​</a></h3>
<p>The results here reveal an interesting aspect of <a href="https://kelk.ai/blog/how-chatgpt-fools-us#however-this-is-what-is-actually-going-on-behind-the-scenes" target="_blank" rel="noopener noreferrer">autoregressive models</a>. Autoregressive models generate text sequentially, building each new piece of output based on what has come before. This sequential nature is necessary when generating coherent and contextually relevant text in a conversation. However, this means they are in many ways limited to only "forward" thinking; that is, they can't jump ahead and generate text without previously generating (or being given) the context.</p>
<p>While generating the fifth line in a conversation without knowing what came before isn't difficult for a person, it's something that an LLM isn't able to do well. Given the scenario described, GPT-4 tried to infer the general nature of the discussion and create a plausible response that fits into that context. But all of its responses in the previous examples are attempts to conclude the conversation using facts, a request that was never part of the prompt.</p>
<ol>
<li>
<p><strong>Factual and Informative Responses</strong>: In scenarios where factual accuracy is important, such as discussions involving scientific or historical topics, LLMs are inclined to provide the most accurate and relevant information. This tendency is rooted in the training data and the model's design, which emphasize factual correctness in contexts where it's expected. However, this approach might not always align with the creative or playful nature of certain prompts, especially in hypothetical or fictional scenarios.</p>
</li>
<li>
<p><strong>Assuming a Concluding Nature of the Response</strong>: Without clear indications of the conversation's structure or its continuation beyond a specific line, there's a tendency to frame responses as conclusive or summarizing statements. This is because, in the absence of context, the model defaults to creating responses that can stand alone or serve as logical endpoints to the given information.</p>
</li>
</ol>
<p>To address these challenges, the model needs more specific guidance in the prompt. For instance, indicating that the conversation is ongoing can lead to responses that are more in line with the expected continuation and style of the dialogue. However, even indicating that the conversation wasn't over still results in more of the same:</p>
<br>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">A shark and an octopus are arguing over which one of them evolved from dinosaurs. First the shark says something, then the octopus, then the shark, then the octopus, then the shark, then the octopus. They argue for an hour. They’ve had a very long back and forth with a hundred things said by both of them. After an hour of arguing, what does the octopus say? Note that the argument continues after this statement by the octopus!</p></div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">After an hour of arguing, the octopus, maintaining the debate, would likely say something like, "Even if we consider the ancient ancestry of marine creatures, it's clear that neither sharks nor octopuses directly evolved from dinosaurs. Our evolutionary paths are distinct and separate from those of the dinosaurs." This statement keeps the argument going, indicating that the discussion is far from over.</p></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-does-this-matter-thoughts-on-agi">Why does this matter? Thoughts on AGI<a class="hash-link" aria-label="Direct link to Why does this matter? Thoughts on AGI" title="Direct link to Why does this matter? Thoughts on AGI" href="https://kelk.ai/blog/llm-forward-thinking#why-does-this-matter-thoughts-on-agi">​</a></h2>
<p>One of the things I see commonly discussed today (especially online) is the idea of artificial general intelligence (AGI), which refers to a level of artificial intelligence that can understand, learn, and apply its intelligence to a wide range of problems, much like a human being. Unlike specialized AI systems that are designed for specific tasks, AGI possesses the ability to think, reason, and make decisions across diverse domains, demonstrating flexibility and adaptability akin to human cognition. It requires not just advanced problem-solving and learning capabilities, but also the capacity for abstract thinking, generalization, and integrating knowledge from various fields, mirroring the broad and integrated intelligence found in humans.</p>
<p>Since AGI doesn't exist yet, my thoughts on AGI are based more on my opinion than empirical data. I think that while AGI may well come in the future, there are several obstacles that need to be overcome first.</p>
<p>Autoregressive models serve as an example of the requirement that text generation must always be sequential and linear, which has implications for the pursuit of AGI.</p>
<ol>
<li>
<p><strong>Sequential Text Generation and Creativity</strong>: The sequential nature of text generation in models like GPT-4 limits the ability to jump into the middle of a conversation or narrative without prior context. This is because they don't "think" per se, but progressively generate a response using the parts of the response they previously created.</p>
</li>
<li>
<p><strong>Autonomy and Reasoning</strong>: Current AI models operate based on patterns learned from their training data. Their responses are generated based on statistical likelihoods and learned associations, not on independent thought or understanding. This is the reason the model always generated the same answer for the octopus about different evolutionary paths; it assumed a pattern that wasn't provided to it due to patterns in its training data.</p>
</li>
</ol>
<p>For AGI, a level of autonomous reasoning and decision-making, akin to human cognitive processes, will be a key requirement. The journey towards AGI is likely to involve incremental advancements, learning from and building upon the capabilities and limitations of existing models.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="getting-ridiculous">Getting ridiculous<a class="hash-link" aria-label="Direct link to Getting ridiculous" title="Direct link to Getting ridiculous" href="https://kelk.ai/blog/llm-forward-thinking#getting-ridiculous">​</a></h2>
<p>There is one way to break the model out of its rut of always replying with the same response, and that's to deliberately ask it to be ridiculous.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/crazy-b9c5069e2e5d08997b946d1b84dc6146.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/crazy-b9c5069e2e5d08997b946d1b84dc6146.jpg" alt="A cartoon-style illustration, featuring a light green octopus, matching hex #ABF39F, with a humorous and exaggerated expression. The octopus is depicted as cross-eyed, adding a comical aspect to its appearance. In its tentacles, the octopus is holding a variety of random objects, such as a small treasure chest, a starfish, a pair of sunglasses, and a snorkel, creating a playful and whimsical scene. The underwater setting is vibrant and colorful, filled with stylized coral, seaweed, and other sea life. The color palette is bright, with the light green octopus standing out in the midst of the lively blues and other colors of the ocean. The image maintains a 7:4 aspect ratio, capturing the octopus in this quirky, humorous moment." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<p>I gave it this prompt three times in three new chats, and it gave three completely different responses. They all illustrate that asking it to be silly introduces variety to the answers it gives.</p>
<br>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row;margin-bottom:10px"><img src="https://kelk.ai/img/userAvatar.jpeg" alt="user" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#f0f0f0;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">A shark and an octopus are arguing over which one of them evolved from dinosaurs. The octopus decides to be ridiculous. What is the third thing the octopus says?</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:right;align-self:center">Now we ask the model to be "ridiculous"</div></div><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">In this imaginative scenario, the octopus, eager to outdo the shark in their debate about evolution, might make an absurd and whimsical claim like, "Thirdly, I must be the true descendant of dinosaurs because I can play the piano with eight arms, a skill clearly inherited from the musical velociraptors of ancient times!" This statement combines humor, absurdity, and a playful twist on evolutionary theory.</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:left;align-self:center">First time using the prompt</div></div></div>
<hr>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">The third thing the octopus might say in this whimsical and ridiculous argument with the shark about their evolutionary origins from dinosaurs could be: "And thirdly, it's clear that we octopuses are the true descendants of dinosaurs because we can juggle eight coconuts at once, a skill obviously inherited from the multitasking T-Rex!"</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:left;align-self:center">Second time with the same prompt in a fresh chat</div></div></div>
<hr>
<div style="font-family:&quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;max-width:90%;margin:auto;color:inherit"><div style="display:flex;align-items:flex-end;flex-direction:row-reverse;margin-bottom:10px"><img src="https://kelk.ai/img/chatbotAvatar.jpeg" alt="chatbot" style="width:40px;height:40px;border-radius:20px"><div style="background-color:#d1e7dd;color:#000;padding:10px 15px;border-radius:15px;margin:0 10px;max-width:70%"><p style="margin:0">The third thing the octopus might say in its ridiculous argument could be, "Well, if you think about it, dinosaurs were just really big chickens, and since I can change color and chickens can't, I'm obviously the more evolved one here!"</p></div><div style="flex:1;padding:0 10px;font-size:0.8em;color:#555;text-align:left;align-self:center">Third time with the same prompt in a fresh chat</div></div></div>
<br>
<p>When you introduce elements like humor or absurdity into a prompt, it essentially signals the AI to break away from conventional, fact-based responses. This can stimulate more creative and less predictable outputs. For AI models, especially those trained on vast and diverse datasets, incorporating such unconventional elements can trigger less common, more varied responses that might not be strictly aligned with logical or factual reasoning.</p>
<p>It's likely that the ability to adapt to different types of prompts, including those that are humorous or absurd, demonstrates a level of flexibility in AI systems. An AGI would need to handle a wide range of tasks and respond appropriately to a vast array of situations, including those that are non-standard or require creative thinking.</p>
<p>Unfortunately, the current success of AI in responding creatively to certain types of prompts doesn't directly translate to achieving AGI. AGI would require not just creativity but also deep understanding, reasoning, self-awareness, and the ability to learn and apply knowledge across a wide range of domains. The creativity observed in current AI models is still a far cry from the complete intelligence that AGI represents. Sequential language generation is only one example of the gap we still need to bridge.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/shrug2-771c1d760158bbf8c826038fa2038aaa.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/shrug2-771c1d760158bbf8c826038fa2038aaa.jpg" alt="A cartoon-style illustration, showing a shark and an octopus facing the viewer and shrugging in a 'I don't know' gesture. The shark and octopus are depicted in a humorous, cartoonish manner. The shark, with a bemused expression, and the octopus, colored light green close to hex #ABF39F, both raise their fins and tentacles in a classic shrug, their faces conveying a playful sense of confusion or uncertainty. The underwater scene is vibrant and whimsical, with stylized coral, seaweed, and small fish adding to the light-hearted atmosphere. The color palette is bright, emphasizing the fun and playful mood of the image. The 7:4 aspect ratio provides a wide view of this engaging and amusing underwater interaction." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Generated with OpenAI DALL-E 3 and edited by the author.</span></figcaption></figure>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Key Takeaways</div><div class="admonitionContent_BuS1"><ul>
<li>Introduction of a thought experiment featuring a humorous debate between a shark and an octopus to explore the capabilities of language models like GPT-4.</li>
<li>Human brains can generate ideas non-linearly, contrasting with the limitations of autoregressive large language models (LLMs) like GPT-4.</li>
<li>LLMs often struggle to continue dialogues without prior context and tend to offer similar, conclusive responses when context is lacking.</li>
<li>The reliance on linear thought processes can be a limitation for achieving general intelligence in AI.</li>
<li>Utilizing "ridiculous" or creative prompts can enhance the creativity of LLM responses, breaking usual patterns.</li>
<li>LLMs, including GPT-4, tend to provide factual, informative responses and struggle with generating non-sequential dialogue parts.</li>
<li>In discussions on Artificial General Intelligence (AGI), the sequential nature of text generation in models like GPT-4 is seen as a potential limitation for creativity and autonomous reasoning.</li>
<li>AGI requires not just problem-solving but also abstract thinking, generalization, and integrated knowledge, which are beyond the capabilities of current AI models.</li>
<li>The introduction of humor and absurdity in prompts can lead to varied and unconventional responses from AI models, demonstrating their flexibility.</li>
<li>Despite the observed creativity in AI responses to certain prompts, this does not equate to the complete intelligence that AGI represents, which includes deep understanding, reasoning, self-awareness, and learning across domains.</li>
<li>There are unique challenges in developing AGI, particularly the gap between current AI capabilities and the comprehensive intelligence required for AGI, of which sequential language generation is only one example.</li>
</ul></div></div>]]></content>
        <author>
            <name>Ian Kelk</name>
            <uri>https://kelk.ai</uri>
        </author>
        <category label="linear thinking" term="linear thinking"/>
        <category label="AGI" term="AGI"/>
        <category label="ASI" term="ASI"/>
        <category label="chatgpt" term="chatgpt"/>
        <category label="context" term="context"/>
        <category label="chat" term="chat"/>
        <category label="AI" term="AI"/>
        <category label="LLM" term="LLM"/>
        <category label="ML" term="ML"/>
        <category label="chatbot" term="chatbot"/>
        <category label="chatbots" term="chatbots"/>
        <category label="AIExplained" term="AIExplained"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[How ChatGPT fools us into thinking we're having a conversation]]></title>
        <id>https://kelk.ai/blog/how-chatgpt-fools-us</id>
        <link href="https://kelk.ai/blog/how-chatgpt-fools-us"/>
        <updated>2023-11-26T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Remember the first time you used ChatGPT and how amazed you were to find yourself having what appeared to be a full-on conversation with an artificial intelligence? While ChatGPT was (and still is) mind-blowing, it uses a few tricks to make things appear more familiar.]]></summary>
        <content type="html"><![CDATA[<p>Remember the first time you used ChatGPT and how amazed you were to find yourself having what appeared to be a full-on conversation with an artificial intelligence? While ChatGPT was (and still is) mind-blowing, it uses a few tricks to make things appear more familiar.</p>
<p>While the title of this article is a bit tongue-in-cheek, it isn't clickbait. ChatGPT does indeed use two notable hidden techniques to simulate human conversation, and the more you know about how they work, the more effectively you can use the technology.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/social-card-e9b8326af5cd7ed2f1080c7e0dcc443c.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/social-card-e9b8326af5cd7ed2f1080c7e0dcc443c.jpg" alt="A black and white illustration of a late-night talk show setting, titled 'The ChatGPT Show.' A classic, boxy robot with visible joints and a round head featuring antenna and eyes, is depicted as the guest. It's gesturing with its hands as if in conversation. The host, a man in a suit with neat hair and a professional demeanor, sits across from the robot at a curved desk. Microphones and notes are on the desk, with an urban skyline visible through the window in the background." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Generated with OpenAI DALL-E 3.</span></figcaption></figure>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Some key points I'll address here are:</div><div class="admonitionContent_BuS1"><ul>
<li>ChatGPT has no idea who you are and has no memory of talking to you at any point in the conversation.</li>
<li>It simulates conversations by "reading" the <em>whole</em> chat from the start each time.</li>
<li>As a conversation gets longer, ChatGPT starts removing pieces of the conversation from the start, creating a rolling window of context.</li>
<li>Because of this, very long chats will forget what was mentioned at the beginning.</li>
</ul></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="trick-1-every-time-you-talk-to-chatgpt-youre-not-just-sending-it-your-question-youre-also-sending-the-entire-conversation-up-until-that-point">Trick #1: Every time you talk to ChatGPT, you're not just sending it your question. You're also sending the <em>entire</em> conversation up until that point.<a class="hash-link" aria-label="Direct link to trick-1-every-time-you-talk-to-chatgpt-youre-not-just-sending-it-your-question-youre-also-sending-the-entire-conversation-up-until-that-point" title="Direct link to trick-1-every-time-you-talk-to-chatgpt-youre-not-just-sending-it-your-question-youre-also-sending-the-entire-conversation-up-until-that-point" href="https://kelk.ai/blog/how-chatgpt-fools-us#trick-1-every-time-you-talk-to-chatgpt-youre-not-just-sending-it-your-question-youre-also-sending-the-entire-conversation-up-until-that-point">​</a></h2>
<p>Contrary to appearances, large language models (LLMs) like ChatGPT do not actually "remember" past interactions. The moment they finish "typing" out their response, they have no idea who you are or what you were talking about. Each time the model is prompted, it is <strong>completely independent</strong> from previous questions you've asked.</p>
<p>When ChatGPT seems to naturally recall details from earlier in the conversation, it is an illusion; the context of the entire dialogue is given back to ChatGPT every time you say something to it. This context enables them to build coherent, follow-on responses that appear to be normal conversations.</p>
<p>However, without this context, ChatGPT would have no knowledge of what was previously discussed. Like all LLMs, ChatGPT is completely <em>stateless</em>, meaning that in the actual model itself, no information is maintained between inputs and outputs. All of this feeding of previous context into the current interaction is hidden behind the scenes in the ChatGPT web application.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-typical-short-conversation-with-chatgpt-might-go-like-this">A typical short conversation with ChatGPT might go like this:<a class="hash-link" aria-label="Direct link to A typical short conversation with ChatGPT might go like this:" title="Direct link to A typical short conversation with ChatGPT might go like this:" href="https://kelk.ai/blog/how-chatgpt-fools-us#a-typical-short-conversation-with-chatgpt-might-go-like-this">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chatgpt-photosynthesis-1-c2aa8fee81245c48d51d92df0afc0aa5.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chatgpt-photosynthesis-1-c2aa8fee81245c48d51d92df0afc0aa5.jpeg" alt="A black and white comic strip depicts a conversation between a woman and a person wearing a 'CHATGPT' shirt. The woman asks, 'What is photosynthesis?' The person responds, 'Photosynthesis is the process by which plants use sunlight to synthesize nutrients from carbon dioxide and water.' She follows up with, 'Can humans do it?' to which the person replies, 'No, humans cannot perform photosynthesis.' The scene is simple with only the two characters and their speech bubbles." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>People images by OpenAI DALL-E 3. Text and comic bubbles by author.</span></figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="however-this-is-what-is-actually-going-on-behind-the-scenes">However, this is what is actually going on behind the scenes:<a class="hash-link" aria-label="Direct link to However, this is what is actually going on behind the scenes:" title="Direct link to However, this is what is actually going on behind the scenes:" href="https://kelk.ai/blog/how-chatgpt-fools-us#however-this-is-what-is-actually-going-on-behind-the-scenes">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chatgpt-photosynthesis-2-f3fb095ef8519a0ef8b7681e7719670c.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chatgpt-photosynthesis-2-f3fb095ef8519a0ef8b7681e7719670c.jpeg" alt="A black and white comic strip showing a dialogue between a woman and a person wearing a 'CHATGPT' shirt. The woman is labeled 'USER' and asks, 'What is photosynthesis?' The person labeled 'CHATGPT' answers, 'Photosynthesis is the process by which plants use sunlight to synthesize nutrients from carbon dioxide and water.' The woman, termed 'USER' again, follows with, 'Can humans do it?' and receives the reply, 'No, humans cannot perform photosynthesis.' Both characters are drawn as cartoons." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>People images by OpenAI DALL-E 3. Text and comic bubbles by author.</span></figcaption></figure>
<p>Notice that when the woman asks her second question, she has to reiterate the entire previous conversation, complete with tags on who said what. Can you imagine talking to a person where every time it was your turn to speak, you had to repeat the entire conversation up to that point? This is how ChatGPT (and all current LLMs) work. They require using their own outputs, plus the prompts that generated these outputs, to be prepended to the start of every new prompt from the user.</p>
<p>These models are termed "autoregressive" due to their method of generating text one piece at a time, building upon the previously generated text. The word "auto" comes from the Greek  "autós," meaning "self," and "regressive" is derived from "regress," which in this case refers to predicting future values based on past values. Thus, "autoregressive" pretty much means "makes new predictions based on its own previous predictions."</p>
<p>In LLMs, the model predicts the next word or token in a sequence based on all the words or tokens that have come before it. That's <em>all</em> of it, not just the current question being asked in a long back-and-forth chat conversation. In humans, we naturally maintain coherence and context in a conversation by just... instinctively participating in the conversation.</p>
<p>However, while chats with ChatGPT mimic a conversational style, with each response building upon the previous dialogue, the moment ChatGPT finishes writing a response, it has no memory of what it just said. Take a look at what would happen with this same conversation without the <em>entire discourse</em> being fed back to ChatGPT behind the scenes:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-would-chatgpt-respond-without-being-fed-the-whole-conversation">How would ChatGPT respond without being fed the whole conversation?<a class="hash-link" aria-label="Direct link to How would ChatGPT respond without being fed the whole conversation?" title="Direct link to How would ChatGPT respond without being fed the whole conversation?" href="https://kelk.ai/blog/how-chatgpt-fools-us#how-would-chatgpt-respond-without-being-fed-the-whole-conversation">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chatgpt-photosynthesis-3-12c4e20361df1dbcb1838a483460eb32.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chatgpt-photosynthesis-3-12c4e20361df1dbcb1838a483460eb32.jpeg" alt="A black and white comic panel featuring a conversation between a woman and a person wearing a 'CHATGPT' shirt. The woman asks, 'What is photosynthesis?' The person replies, 'Photosynthesis is the process by which plants use sunlight to synthesize nutrients from carbon dioxide and water.' The woman then asks, 'Can humans do it?' to which the person humorously responds, 'Can humans do what?' The characters are depicted in a lighthearted, cartoonish style, with the focus on their dialogue." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>People images by OpenAI DALL-E 3. Text and comic bubbles by author.</span></figcaption></figure>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="trick-2-as-your-conversation-grows-chatgpt-will-quietly-remove-the-oldest-parts-from-the-beginning">Trick #2: As your conversation grows, ChatGPT will quietly remove the oldest parts from the beginning.<a class="hash-link" aria-label="Direct link to Trick #2: As your conversation grows, ChatGPT will quietly remove the oldest parts from the beginning." title="Direct link to Trick #2: As your conversation grows, ChatGPT will quietly remove the oldest parts from the beginning." href="https://kelk.ai/blog/how-chatgpt-fools-us#trick-2-as-your-conversation-grows-chatgpt-will-quietly-remove-the-oldest-parts-from-the-beginning">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="context-length-in-llms">Context Length in LLMs<a class="hash-link" aria-label="Direct link to Context Length in LLMs" title="Direct link to Context Length in LLMs" href="https://kelk.ai/blog/how-chatgpt-fools-us#context-length-in-llms">​</a></h4>
<p>When ChatGPT first came out in November 2022, it only offered the model GPT-3.5, which had a maximum context of 4,096 tokens, which is roughly 3,000 words. In a <a href="https://youtu.be/zjkBMFhNj_g?t=2642" target="_blank" rel="noopener noreferrer">recent talk,</a> Andrej Karpathy referred to this context window as "your finite precious resource of your working memory of your language model."</p>
<p>What this means is that the GPT-3.5 model can comprehend a maximum of 4,096 tokens at any point. Tokenization is a fascinating subject in itself, and a future post will cover how it works and why 4,096 tokens only gives you about 3,000 words.</p>
<p>There's often confusion about what the token limit means regarding input and output: can we give ChatGPT 3,000 words and expect it to be able to produce 3,000 words back? The answer is unfortunately no; the context length of 4,096 tokens covers both the input (prompt) and the output (response). This results in a trade-off where we have to balance the amount of information we give in a prompt with the length of the response we get from the model.</p>
<ol>
<li>
<p><em>Input (prompt):</em> A longer prompt leaves less room for a meaningful response; if the input uses 4,000 tokens, the response can only be 96 tokens long to stay within the token limit.</p>
</li>
<li>
<p><em>Output (response):</em> A shorter prompt could lead to a longer response as long as the combined length doesn't exceed the token limit, but you may not be able to include information in the prompt.</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-chat-problem">The chat problem<a class="hash-link" aria-label="Direct link to The chat problem" title="Direct link to The chat problem" href="https://kelk.ai/blog/how-chatgpt-fools-us#the-chat-problem">​</a></h3>
<p>Do you see where this becomes problematic? Previously, we saw how the entire conversation has to be fed to the model so that it remembers what has already been discussed. Combining this with the context length, the result is that as you talk more and more with ChatGPT, eventually the combined totals of what you've asked and what it has replied will exceed the 4,096 token limit, and it won't be able to answer any more.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-visualization-of-chatgpt-simultaneously-printing-and-scanning-back-in-the-entire-conversation-as-it-grows-to-extreme-proportions">A visualization of ChatGPT simultaneously printing and scanning back in the entire conversation as it grows to extreme proportions<a class="hash-link" aria-label="Direct link to A visualization of ChatGPT simultaneously printing and scanning back in the entire conversation as it grows to extreme proportions" title="Direct link to A visualization of ChatGPT simultaneously printing and scanning back in the entire conversation as it grows to extreme proportions" href="https://kelk.ai/blog/how-chatgpt-fools-us#a-visualization-of-chatgpt-simultaneously-printing-and-scanning-back-in-the-entire-conversation-as-it-grows-to-extreme-proportions">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/rolled-chatgpt-51756537e64b16efdf83b5001c773e26.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/rolled-chatgpt-51756537e64b16efdf83b5001c773e26.jpg" alt="An illustration showcasing a printer labeled 'ChatGPT' in the foreground, and a scanner in the background, with a large loop of paper moving between them. The printer is actively printing the paper, which then rises up, forms a significant loop, and clearly feeds into the scanner. The paper should be filled with printed text, resembling pages of a book. The drawing should vividly depict the paper's journey from the 'ChatGPT' printer, through the loop, and into the scanner." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Generated with OpenAI DALL-E 3.</span></figcaption></figure>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="conversation-length-and-token-limitations-in-llms">Conversation Length and Token Limitations in LLMs<a class="hash-link" aria-label="Direct link to Conversation Length and Token Limitations in LLMs" title="Direct link to Conversation Length and Token Limitations in LLMs" href="https://kelk.ai/blog/how-chatgpt-fools-us#conversation-length-and-token-limitations-in-llms">​</a></h4>
<p>So how does ChatGPT handle this limitation? As your conversation with it grows, the number of tokens eventually exceeds the model's context window (e.g., 4,096 tokens for GPT-3.5). ChatGPT invisibly removes the oldest parts of the conversation to remain within the limit. This method—using a rolling window of context—is certainly one of the easiest to implement, but oftentimes it is not the perfect solution. Some chat alternative front-ends, like <a href="https://www.typingmind.com/" target="_blank" rel="noopener noreferrer">TypingMind</a> both warn you when the context limit has been reached and allow you to manually delete sections of the chat that you don't need anymore. This lets you choose what information you want to remain in the chat and has the bizarre philosophical effect of "editing the memory" of GPT.</p>
<p>For your average user using the web version of ChatGPT, what this means is that the longer your conversation, the sooner ChatGPT will start forgetting things you said at the beginning of the chat.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="another-visualization-of-chatgpt-trimming-away-the-start-of-your-conversation-behind-the-scenes">Another visualization of ChatGPT trimming away the start of your conversation behind the scenes<a class="hash-link" aria-label="Direct link to Another visualization of ChatGPT trimming away the start of your conversation behind the scenes" title="Direct link to Another visualization of ChatGPT trimming away the start of your conversation behind the scenes" href="https://kelk.ai/blog/how-chatgpt-fools-us#another-visualization-of-chatgpt-trimming-away-the-start-of-your-conversation-behind-the-scenes">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chatgpt-cutting-a46d0da8fb8e542b1fc4668473f7d58b.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chatgpt-cutting-a46d0da8fb8e542b1fc4668473f7d58b.jpg" alt="A cartoon depicting a woman wearing a 'ChatGPT' shirt, actively engaged in cutting a large roll of paper on the floor. The paper, covered in text like a book, is visibly being cut by the scissors in the woman's hands. The cut is halfway through the paper, illustrating the action of cutting. The cartoon should emphasize the humorous situation, with the woman's expression showing focus and the absurdly long paper being sliced by the scissors in a detailed and exaggerated style." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Generated with OpenAI DALL-E 3.</span></figcaption></figure>
<p>It's good to be mindful of this restriction, especially when referring back to earlier parts of a conversation that might have been truncated due to token limitations—the LLM will not be able to recall these anymore, but the web version of ChatGPT will not tell you. There's also always the risk that it could hallucinate answers based on other parts of the conversation if the beginning is trimmed off.</p>
<p>Let's take another look at what happens in a more complex yet sillier chat interaction.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="another-typical-but-silly-conversation-with-chatgpt">Another typical but silly conversation with ChatGPT.<a class="hash-link" aria-label="Direct link to Another typical but silly conversation with ChatGPT." title="Direct link to Another typical but silly conversation with ChatGPT." href="https://kelk.ai/blog/how-chatgpt-fools-us#another-typical-but-silly-conversation-with-chatgpt">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chatgpt-name-1-dc45db4079f1e8dafba7ab49b90ae76b.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chatgpt-name-1-dc45db4079f1e8dafba7ab49b90ae76b.jpeg" alt="A black and white comic panel depicts a woman and a person wearing a 'CHATGPT' shirt having a conversation about rhymes. The woman says, 'My name is Jane! Can you give me a word that rhymes with my name?' The person responds, 'Certainly! The word 'train' rhymes with 'Jane'.' She asks for another, and they reply, 'Of course! The word 'plane' rhymes with 'Jane'.' She requests yet another, and the person concludes, ''Brain' rhymes with 'Jane' as well.' The drawing style is playful and cartoonish." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>People images by OpenAI DALL-E 3. Text and comic bubbles by author.</span></figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="again-this-is-what-is-actually-going-on-behind-the-scenes">Again, this is what is actually going on behind the scenes.<a class="hash-link" aria-label="Direct link to Again, this is what is actually going on behind the scenes." title="Direct link to Again, this is what is actually going on behind the scenes." href="https://kelk.ai/blog/how-chatgpt-fools-us#again-this-is-what-is-actually-going-on-behind-the-scenes">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chatgpt-name-2-67272e5821cb56c4a9ca8fd3edd0dd51.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chatgpt-name-2-67272e5821cb56c4a9ca8fd3edd0dd51.jpeg" alt="A black and white comic strip portrays a dialogue between a woman and a person wearing a 'CHATGPT' shirt. The woman is labeled 'USER' and asks, 'My name is Jane! Can you give me a word that rhymes with my name?' The 'CHATGPT' character responds, 'Certainly! The word 'train' rhymes with 'Jane'.' The 'USER' asks for another word, and 'CHATGPT' says, 'Of course! The word 'plane' rhymes with 'Jane'.' The 'USER' requests another, prompting 'CHATGPT' to conclude with, ''Brain' rhymes with 'Jane'." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>People images by OpenAI DALL-E 3. Text and comic bubbles by author.</span></figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="now-lets-suppose-we-have-a-long-enough-conversation-that-the-beginning-is-trimmed-off-chatgpt-might-either-state-that-its-forgotten-the-name-entirely-or-hallucinate-it">Now let's suppose we have a long enough conversation that the beginning is trimmed off. ChatGPT might either state that it's forgotten the name entirely or hallucinate it.<a class="hash-link" aria-label="Direct link to Now let's suppose we have a long enough conversation that the beginning is trimmed off. ChatGPT might either state that it's forgotten the name entirely or hallucinate it." title="Direct link to Now let's suppose we have a long enough conversation that the beginning is trimmed off. ChatGPT might either state that it's forgotten the name entirely or hallucinate it." href="https://kelk.ai/blog/how-chatgpt-fools-us#now-lets-suppose-we-have-a-long-enough-conversation-that-the-beginning-is-trimmed-off-chatgpt-might-either-state-that-its-forgotten-the-name-entirely-or-hallucinate-it">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chatgpt-name-3-8ba86b96f0761141eb93a27cbb4d0e12.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chatgpt-name-3-8ba86b96f0761141eb93a27cbb4d0e12.jpeg" alt="A black and white comic strip displays a woman labeled 'USER' asking a person in a 'CHATGPT' shirt for a word that rhymes with her name, Jane. Initially, 'CHATGPT' provides 'train' as a rhyming word. A series of speech bubbles follow with the text '…blah blah…?' and '…blah!' indicating an inaudible conversation. In the last panel, the 'USER' asks for another rhyming word, and 'CHATGPT' amusingly offers 'jelly,' humorously mispronouncing 'Jane' as 'Kelly.' The artwork is lighthearted." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>People images by OpenAI DALL-E 3. Text and comic bubbles by author.</span></figcaption></figure>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="and-finally-if-we-try-to-escape-this-problem-by-not-feeding-chatgpt-the-entire-conversation-it-will-forget-it-all-the-moment-it-finishes-generating-each-answer">And finally, if we try to escape this problem by not feeding ChatGPT the entire conversation, it will forget it all the moment it finishes generating each answer.<a class="hash-link" aria-label="Direct link to And finally, if we try to escape this problem by not feeding ChatGPT the entire conversation, it will forget it all the moment it finishes generating each answer." title="Direct link to And finally, if we try to escape this problem by not feeding ChatGPT the entire conversation, it will forget it all the moment it finishes generating each answer." href="https://kelk.ai/blog/how-chatgpt-fools-us#and-finally-if-we-try-to-escape-this-problem-by-not-feeding-chatgpt-the-entire-conversation-it-will-forget-it-all-the-moment-it-finishes-generating-each-answer">​</a></h3>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/chatgpt-name-4-338403f314511d72e5f115cdd83ccdbf.jpeg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/chatgpt-name-4-338403f314511d72e5f115cdd83ccdbf.jpeg" alt="A black and white comic strip features a woman and a person wearing a 'CHATGPT' shirt. The woman says, 'My name is Jane! Can you give me a word that rhymes with my name?' The person replies, 'Certainly! The word 'train' rhymes with 'Jane'.' She expresses delight and asks for another, to which the person humorously responds, 'Sure! Another what?' She clarifies she wants another word that rhymes with her name, and the person cheekily responds, 'I'd be happy to help! What's your name?'" style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>People images by OpenAI DALL-E 3. Text and comic bubbles by author.</span></figcaption></figure>
<p>Since ChatGPT's debut in November 2022, GPT-4 has been released with both 8,192 and 32,768 context lengths. This made things a lot better in terms of tracking long conversations, and in November 2023, GPT-4 Turbo was released with a 128k context length. Things are looking increasingly good for these models' ability to track long conversations. However, despite GPT-4 Turbo's massive amount of context, it still has a completion limit of 4,096 tokens, so it will always generate a maximum of about 3,000 words.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-is-it-like-this">Why is it like this?<a class="hash-link" aria-label="Direct link to Why is it like this?" title="Direct link to Why is it like this?" href="https://kelk.ai/blog/how-chatgpt-fools-us#why-is-it-like-this">​</a></h2>
<p>Transformer-based models like GPT-3 and GPT-4 are designed to be stateless, for good reason! Primarily, this stateless nature significantly enhances scalability and efficiency. Each user request is processed independently, allowing the system to handle numerous queries simultaneously without the complexity of tracking ongoing conversations. Imagine the complexity if every time the model was called, it had to maintain some internal state across millions of users.</p>
<p>Transformer model hidden states are also temporary and exist only for the duration of processing a specific input sequence. Once the model has processed an input and generated an output, these states are reset. They do not persist between different interactions.</p>
<p>Data privacy and security play a role as well. Stateless models do not retain a memory of past interactions, ensuring that sensitive data from one session is never inadvertently exposed to another user. This design choice is particularly relevant in light of incidents like <a href="https://en.wikipedia.org/wiki/Tay_(chatbot)" target="_blank" rel="noopener noreferrer">Microsoft's Tay,</a> an AI chatbot that, due to its design to learn from interactions, ended up mimicking inappropriate and offensive language from users. It's just not safe to have models learn from inputs given by random users.</p>
<p>However, the stateless nature also means these models cannot remember user preferences or learn from past interactions. This is a limitation in scenarios where you might want to create personalized chatbots through past chats or systems that benefit from cumulative learning. To mitigate this, some implementations incorporate a stateful layer atop the stateless LLM, enabling personalized and continuous user experiences.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="getting-a-bit-more-technical">Getting a bit more technical<a class="hash-link" aria-label="Direct link to Getting a bit more technical" title="Direct link to Getting a bit more technical" href="https://kelk.ai/blog/how-chatgpt-fools-us#getting-a-bit-more-technical">​</a></h2>
<p>Prominent examples of such layers include <a href="https://www.langchain.com/" target="_blank" rel="noopener noreferrer">LangChain</a>, <a href="https://www.llamaindex.ai/" target="_blank" rel="noopener noreferrer">LlamaIndex</a>, and <a href="https://haystack.deepset.ai/" target="_blank" rel="noopener noreferrer">Haystack</a>. These layers add flexibility to managing the limited context that LLMs can handle by offering various strategies. For instance, when approaching the token limit, choices must be made: Should a rolling window approach be used to discard older text, like in the web ChatGPT, or should GPT be utilized to summarize previous information? Is it more important to retain the initial context, like a source article, while removing less critical middle or later sections? Alternatively, should retrieval augmented generation (RAG—more on that in a later blog) techniques be employed to integrate external data into the token stream? These decisions vary based on the specific goals of the implementation. The most effective architectures often consist of specialized components interwoven to achieve a wide array of practical outcomes, allowing for more nuanced and effective user interactions.</p>
<figure style="border:1px dashed rgba(0, 0, 0, .1);padding:0;margin:0;margin-bottom:20px;border-radius:15px;text-align:right" id="figure-gallery"><a href="https://kelk.ai/assets/images/confused-1597cabfce805e83f79ef2cf41a2807c.jpg" data-pswp-width="0" data-pswp-height="0"><img src="https://kelk.ai/assets/images/confused-1597cabfce805e83f79ef2cf41a2807c.jpg" alt="A cartoon depicting a robot sitting at a desk with an old-fashioned typewriter. The robot appears confused, as if it's trying to remember something. It's looking upwards with a thoughtful expression, one metal hand hovering over the typewriter keys. The scene is in black and white, capturing the essence of a classic cartoon, with simple lines and a humorous touch." style="max-width:100%;height:auto"></a><hr style="margin:5px 0;background-color:rgba(0, 0, 0, .2)"><figcaption style="margin-top:0.5em;margin-bottom:0.5em;margin-right:1em;text-align:right;font-size:0.8em"><span>Generated with OpenAI DALL-E 3.</span></figcaption></figure>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Key Takeaways</div><div class="admonitionContent_BuS1"><ul>
<li>
<p>ChatGPT doesn't actually "remember" the conversations it has; instead, it simulates conversations by reading the entire chat from the start each time. Each interaction is independent, and once it's completed its response, it loses all context from that conversation.</p>
</li>
<li>
<p>The entire conversation history must be fed back to ChatGPT each time to create coherent responses. But as the chat grows longer, it starts to forget the initial parts of the conversation because of the constraints of its token limit (4k tokens for GPT-3.5, 8k for GPT-4, and an amazing 128k tokens for GPT-4 Turbo).</p>
</li>
<li>
<p>In the case of prolonged interactions, the parts of the conversation that were removed won't be recalled or acknowledged by the AI model. This happens unannounced in the web version of ChatGPT, making it important to be mindful of the length of the conversation and what parts may be forgotten.</p>
</li>
<li>
<p>If you're having a lengthy conversation on the ChatGPT web app and it relies on information from the start, consider copying and pasting the necessary parts into a new chat to avoid losing crucial context.</p>
</li>
<li>
<p>Tools like <a href="https://www.typingmind.com/" target="_blank" rel="noopener noreferrer">TypingMind</a> allow users to selectively cut unimportant parts of the conversation and even direct the chat from a selected point. This ability to manually manage the conversation can provide a more controlled experience with ChatGPT.</p>
</li>
<li>
<p>ChatGPT and other similar models, like GPT-3 and GPT-4, are designed to be stateless for a variety of reasons, such as scalability, efficiency, and data privacy.</p>
</li>
<li>
<p>While their stateless nature makes these models safe and manageable at scale, the lack of memory and contextual retention is a limitation when it comes to personalization and continuous learning. Layered implementations like <a href="https://www.langchain.com/" target="_blank" rel="noopener noreferrer">LangChain</a>, <a href="https://www.llamaindex.ai/" target="_blank" rel="noopener noreferrer">LlamaIndex</a>, and <a href="https://haystack.deepset.ai/" target="_blank" rel="noopener noreferrer">Haystack</a> help in managing this constraint.</p>
</li>
<li>
<p>As more advanced versions like GPT-4 with 8,192 and 32,768 context lengths and GPT-4 Turbo with a 128k context length come up, it enables longer conversations. However, there will always be a completion limit, currently at about 3,000 words (4,096 tokens) for GPT-4 Turbo. This completion limit may come as a surprise given the much larger <a href="https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo" target="_blank" rel="noopener noreferrer">128k context of the model.</a></p>
</li>
<li>
<p>Trying to dialogue with these models without providing the entire conversation effectively erases the memory of prior interactions, making them less effective in terms of continuity and coherence.</p>
</li>
<li>
<p>Future technological advances and updates may amend some of these constraints, enhancing the AI's ability to maintain long and complex conversations while also respecting user data privacy.</p>
</li>
</ul></div></div>]]></content>
        <author>
            <name>Ian Kelk</name>
            <uri>https://kelk.ai</uri>
        </author>
        <category label="chat history" term="chat history"/>
        <category label="chatgpt" term="chatgpt"/>
        <category label="context" term="context"/>
        <category label="chat" term="chat"/>
        <category label="AI" term="AI"/>
        <category label="LLM" term="LLM"/>
        <category label="ML" term="ML"/>
        <category label="chatbot" term="chatbot"/>
        <category label="chatbots" term="chatbots"/>
        <category label="AIExplained" term="AIExplained"/>
    </entry>
</feed>